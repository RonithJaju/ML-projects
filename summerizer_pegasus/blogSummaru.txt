 The Grand Tour is a classic visualization technique for high-dimensional point clouds . Unlike modern nonlinear projection methods such as t-SNE and UMAP, it is fundamentally a linear method . We show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to us .  Deep neural networks often confine their nonlinearity to a small set of operations . Our proposed method better preserves context by providing more consistency . It should be possible to know how the visualization  would change, if the data had been different in a particular way .  The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1 . The intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen in Rn\mathbb{R}^nRn, where nnn is the number of neurons in the layer .  Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7 . If we knew ahead of time to be looking for class-specific error rates, this chart works well .  A significant change happened in only a subset of data, but all points in the visualization move dramatically . For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms .  Each linear projection from nnn dimensions to 222 dimensions can be represented by nnn 2-dimensional vectors . These are the destinations of an input that is classified with 100% confidence to any one particular class . Users can intuitively set up new linear projections by dragging around user-interface handles .  The distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector . If the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much .  Images from the testing set keep oscillating while most images from training converges to the corresponding class corner . In epoch 99, we can clearly see a difference in distribution between these two sets . This signals that the model overfits the training set .  We claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities . This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations .  We show how the Grand Tour can also elucidate the behavior of adversarial examples as they are processed by a neural network . For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s .  The Grand Tour uses a single animated view . When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature .  The axis mode is a special case of data point mode . The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle) they are signaling to the system that they wished that the corresponding data point had been projected to the location where the UI element was dropped, rather than where it was dragged .  eie_iei​ is a row vector whose ii-th entry is 111 (and 000s elsewhere) and ei~:=ei⋅GT\tilde{e_i} := e_i \cdot GTei​~~​: =ei​’s ‘i’ is the i-th row of GTGTGT .    Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points c~\tilde{c}c~ to   c~(new):=(c~+Δ~) := (c~) + \tilde {c} +   +  c~ (c) +  c)  We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers . Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.0 .