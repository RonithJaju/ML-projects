{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6878295961844862ad19fdb307eeb9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b834ecb457e7460e95794f06ff8f9b26",
              "IPY_MODEL_37cf1022eaef4f6ca03203c555dcd40d",
              "IPY_MODEL_494e8049b9f0491fa1550ed786a069c6"
            ],
            "layout": "IPY_MODEL_9305aa2700314c41bf9608c2a3d1c419"
          }
        },
        "b834ecb457e7460e95794f06ff8f9b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5339785cee504b039fe5ee46253b6f40",
            "placeholder": "​",
            "style": "IPY_MODEL_35bff0c3f4444fe1a6dd18b963c4ce6e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "37cf1022eaef4f6ca03203c555dcd40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae1b8a886d743d29f93a50421a9eea6",
            "max": 87,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12852e1fa85b4366b6e9e30b68acfae6",
            "value": 87
          }
        },
        "494e8049b9f0491fa1550ed786a069c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a2620940d3452a9e344f5c21a2809c",
            "placeholder": "​",
            "style": "IPY_MODEL_f9502a6a9d444a8e8eb096b553c28a58",
            "value": " 87.0/87.0 [00:00&lt;00:00, 1.97kB/s]"
          }
        },
        "9305aa2700314c41bf9608c2a3d1c419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5339785cee504b039fe5ee46253b6f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35bff0c3f4444fe1a6dd18b963c4ce6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ae1b8a886d743d29f93a50421a9eea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12852e1fa85b4366b6e9e30b68acfae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6a2620940d3452a9e344f5c21a2809c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9502a6a9d444a8e8eb096b553c28a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43b7d952c8c547fdaeb2092298078ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43ed67387c48447189a1a99e43b5bc4d",
              "IPY_MODEL_1073c137a9ac461fa82b4b2ffda975df",
              "IPY_MODEL_d2484b1d7f6e45eca358a2fa0476e55f"
            ],
            "layout": "IPY_MODEL_34f511f39be0429c8581723b052c1b1d"
          }
        },
        "43ed67387c48447189a1a99e43b5bc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98545a1a1aa46f5b436241bcc4eaae9",
            "placeholder": "​",
            "style": "IPY_MODEL_c86ebc2fbf3f4e5b8caea0747411ad23",
            "value": "spiece.model: 100%"
          }
        },
        "1073c137a9ac461fa82b4b2ffda975df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a359e77d9e45bfbe2eacff88330ba4",
            "max": 1912529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b61eebce5a1941c58f86368a38515d5c",
            "value": 1912529
          }
        },
        "d2484b1d7f6e45eca358a2fa0476e55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc77a838905044e0ae08646a7f15dbc2",
            "placeholder": "​",
            "style": "IPY_MODEL_d59935584362487bb2dbc46b8292b785",
            "value": " 1.91M/1.91M [00:00&lt;00:00, 2.23MB/s]"
          }
        },
        "34f511f39be0429c8581723b052c1b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98545a1a1aa46f5b436241bcc4eaae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86ebc2fbf3f4e5b8caea0747411ad23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a359e77d9e45bfbe2eacff88330ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61eebce5a1941c58f86368a38515d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc77a838905044e0ae08646a7f15dbc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59935584362487bb2dbc46b8292b785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384b8a797fec482c9256b7a59ac80b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de15877dbd2743b7bb8f7845f2024a94",
              "IPY_MODEL_b21c6b681c374645a2090a5a9a702c3e",
              "IPY_MODEL_050d25095ac24adda6b67e297dc07082"
            ],
            "layout": "IPY_MODEL_797c36bda59647c2ae30d2f1ea213d1b"
          }
        },
        "de15877dbd2743b7bb8f7845f2024a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc88b43c284b405c86dea8e5b6478b92",
            "placeholder": "​",
            "style": "IPY_MODEL_7b5ff7375c724ab09e8e5958d26c4aab",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b21c6b681c374645a2090a5a9a702c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259ce277f92b411fbc869e4bcd26a7be",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1e1f7ff8e9041f1a83cbbcc88512e53",
            "value": 65
          }
        },
        "050d25095ac24adda6b67e297dc07082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d3396e024244ac93d11eab1fbb4087",
            "placeholder": "​",
            "style": "IPY_MODEL_cf1ce4181c0346bd901e3a0a34f25258",
            "value": " 65.0/65.0 [00:00&lt;00:00, 995B/s]"
          }
        },
        "797c36bda59647c2ae30d2f1ea213d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc88b43c284b405c86dea8e5b6478b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5ff7375c724ab09e8e5958d26c4aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "259ce277f92b411fbc869e4bcd26a7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e1f7ff8e9041f1a83cbbcc88512e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d3396e024244ac93d11eab1fbb4087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1ce4181c0346bd901e3a0a34f25258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b99f0319be54fd5a6b978d8ab45a260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3369a8a086cd47afb0856aa66b66e731",
              "IPY_MODEL_88a7514624b64e5eb81517806301dd46",
              "IPY_MODEL_956ccc1600de44a8a0a212c2b7384ab8"
            ],
            "layout": "IPY_MODEL_806ee989ef9e45d5b7663a3a5f0fbdc5"
          }
        },
        "3369a8a086cd47afb0856aa66b66e731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7a89bb009f40a4b56b475527730bea",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca3685d1dfd4fdc92b0b063bb8828c2",
            "value": "tokenizer.json: 100%"
          }
        },
        "88a7514624b64e5eb81517806301dd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66218f27f4c946edb90acddede969113",
            "max": 3520083,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_727861c321e240c5a57c42558e37afb9",
            "value": 3520083
          }
        },
        "956ccc1600de44a8a0a212c2b7384ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71bd2bb3d1af48bc83b848900301cd50",
            "placeholder": "​",
            "style": "IPY_MODEL_65d1485034db4e08b1487e07d9f753c3",
            "value": " 3.52M/3.52M [00:01&lt;00:00, 3.33MB/s]"
          }
        },
        "806ee989ef9e45d5b7663a3a5f0fbdc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7a89bb009f40a4b56b475527730bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca3685d1dfd4fdc92b0b063bb8828c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66218f27f4c946edb90acddede969113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "727861c321e240c5a57c42558e37afb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71bd2bb3d1af48bc83b848900301cd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d1485034db4e08b1487e07d9f753c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee5ad7c5ffa4b01a180bcdf043d76cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f102a360b00640ba8a10578d24368e38",
              "IPY_MODEL_18cb7d85c85a48739a680965b5c9980e",
              "IPY_MODEL_88805064e1d041f7a1f71430e1a0e42c"
            ],
            "layout": "IPY_MODEL_b7c67abc1b634b1783830d95e967d405"
          }
        },
        "f102a360b00640ba8a10578d24368e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86b6ac9a8c645cc8221cac4c347a3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_9f9e691da28d4b73bc465b83914a13b5",
            "value": "config.json: 100%"
          }
        },
        "18cb7d85c85a48739a680965b5c9980e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02327527e8d484cab92ccc19f01bf80",
            "max": 1392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3350909b39f6480b99fd263f531e8447",
            "value": 1392
          }
        },
        "88805064e1d041f7a1f71430e1a0e42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc2ed4b8011425faf94bd1c4e1db293",
            "placeholder": "​",
            "style": "IPY_MODEL_2795667dd13044369d10f0a771393951",
            "value": " 1.39k/1.39k [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "b7c67abc1b634b1783830d95e967d405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86b6ac9a8c645cc8221cac4c347a3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f9e691da28d4b73bc465b83914a13b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c02327527e8d484cab92ccc19f01bf80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3350909b39f6480b99fd263f531e8447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc2ed4b8011425faf94bd1c4e1db293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2795667dd13044369d10f0a771393951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e4d7e48c65445439f13c886efcd4d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_457c3b09aaf34ba38c4017845eb79e0a",
              "IPY_MODEL_2d41cb92ac4f4938b01400f435549c68",
              "IPY_MODEL_c040fafeaeda4c2fb587af8e1aae6585"
            ],
            "layout": "IPY_MODEL_b139ad9654c342cb8cc09632f424a9dc"
          }
        },
        "457c3b09aaf34ba38c4017845eb79e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f08e12bf17bb457cbcf8ba3193c928c1",
            "placeholder": "​",
            "style": "IPY_MODEL_bf00a2d99ac64ee093e6a49d5eb7c103",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "2d41cb92ac4f4938b01400f435549c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d41a564fda4e459ff4b2aa052c1917",
            "max": 2275329241,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49b740a27e524184b70ba15dfff33e6e",
            "value": 2275329241
          }
        },
        "c040fafeaeda4c2fb587af8e1aae6585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef7432ed9ee44ce683471d96ddd270be",
            "placeholder": "​",
            "style": "IPY_MODEL_f39d34edb7a04f0ebeb552a4f5b83a5a",
            "value": " 2.28G/2.28G [00:17&lt;00:00, 159MB/s]"
          }
        },
        "b139ad9654c342cb8cc09632f424a9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08e12bf17bb457cbcf8ba3193c928c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf00a2d99ac64ee093e6a49d5eb7c103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5d41a564fda4e459ff4b2aa052c1917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b740a27e524184b70ba15dfff33e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef7432ed9ee44ce683471d96ddd270be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f39d34edb7a04f0ebeb552a4f5b83a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba8d3423e9347a7a36b34e0c653fad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d239df5e170d4145b212c91571e972fc",
              "IPY_MODEL_e1c2cac63f254131b1a397a6696414f1",
              "IPY_MODEL_f06b812d6a104dc08f8f0412051980ac"
            ],
            "layout": "IPY_MODEL_ff561583d0ca44d2b85c69b30641ce74"
          }
        },
        "d239df5e170d4145b212c91571e972fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec22187a874f4fe0bffdafef3df10d66",
            "placeholder": "​",
            "style": "IPY_MODEL_71768559e8e24d60be4530af7331c670",
            "value": "generation_config.json: 100%"
          }
        },
        "e1c2cac63f254131b1a397a6696414f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd37d6a077564e08b29aa047b815853e",
            "max": 259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccfdb85f0f5b468a817bd57cefa37d93",
            "value": 259
          }
        },
        "f06b812d6a104dc08f8f0412051980ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a7eb0cfd2e4bb6bfc378d8fdac0b8c",
            "placeholder": "​",
            "style": "IPY_MODEL_502d654f5f8d425c91c129d8d71c3a1a",
            "value": " 259/259 [00:00&lt;00:00, 6.51kB/s]"
          }
        },
        "ff561583d0ca44d2b85c69b30641ce74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec22187a874f4fe0bffdafef3df10d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71768559e8e24d60be4530af7331c670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd37d6a077564e08b29aa047b815853e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfdb85f0f5b468a817bd57cefa37d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5a7eb0cfd2e4bb6bfc378d8fdac0b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502d654f5f8d425c91c129d8d71c3a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40d0cde005cb447c8e59c7a60a5e50ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40b0947a268540e38b6897276ef24b7a",
              "IPY_MODEL_255f8f0558e041a18a06c66dcadbb5de",
              "IPY_MODEL_2c1fc1941aa14bbc9ea6dd86d2185452"
            ],
            "layout": "IPY_MODEL_248030d826444564a3e32f7a01cbff3f"
          }
        },
        "40b0947a268540e38b6897276ef24b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c2794c1af441bd831bf66d0e890381",
            "placeholder": "​",
            "style": "IPY_MODEL_d0bf75cbd52840dea419e55308143294",
            "value": "config.json: 100%"
          }
        },
        "255f8f0558e041a18a06c66dcadbb5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40c260a59f24e41ac63226f42f5eb43",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_286c2952f7494f7bb2c5db4c1f6079e7",
            "value": 1802
          }
        },
        "2c1fc1941aa14bbc9ea6dd86d2185452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ea93e09db64954887ab6ca2e5b5bcd",
            "placeholder": "​",
            "style": "IPY_MODEL_dc40289efcf74bef8012bac2f2ead002",
            "value": " 1.80k/1.80k [00:00&lt;00:00, 109kB/s]"
          }
        },
        "248030d826444564a3e32f7a01cbff3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c2794c1af441bd831bf66d0e890381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bf75cbd52840dea419e55308143294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40c260a59f24e41ac63226f42f5eb43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286c2952f7494f7bb2c5db4c1f6079e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ea93e09db64954887ab6ca2e5b5bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc40289efcf74bef8012bac2f2ead002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144c27c846f1415eb6831db06b8a6d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d61e002a49bc4082b7d0fdd22baa4ccb",
              "IPY_MODEL_e3a3a15edeea42bf95560a7f591feda7",
              "IPY_MODEL_dbdc65fa9a8f47fd81ec3966e34d1889"
            ],
            "layout": "IPY_MODEL_3f38671c7e04420bb2f21b6e2beeb344"
          }
        },
        "d61e002a49bc4082b7d0fdd22baa4ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bd96125b5e34b83b33b637f8600510a",
            "placeholder": "​",
            "style": "IPY_MODEL_e53a222114894bd8ab6cb9855082dfe1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e3a3a15edeea42bf95560a7f591feda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f8e533e7b0486f809636d6ba3c72ce",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f0fe79530d6446b810975e7d673b5aa",
            "value": 1222317369
          }
        },
        "dbdc65fa9a8f47fd81ec3966e34d1889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06405d418514319be21466ca234cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_892bb146754b4f24b2fbcd489acff221",
            "value": " 1.22G/1.22G [00:09&lt;00:00, 105MB/s]"
          }
        },
        "3f38671c7e04420bb2f21b6e2beeb344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd96125b5e34b83b33b637f8600510a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53a222114894bd8ab6cb9855082dfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f8e533e7b0486f809636d6ba3c72ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0fe79530d6446b810975e7d673b5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a06405d418514319be21466ca234cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892bb146754b4f24b2fbcd489acff221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f728d84ad600496faf178eeddec81a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51491e7dce734895ae134fa1edb558da",
              "IPY_MODEL_643acf4ba8f14e9fa56d67791c355fa0",
              "IPY_MODEL_9e54bad4ae6b463491db4242fa6ff4e5"
            ],
            "layout": "IPY_MODEL_215c77cdc03043f59a88f2f010414af8"
          }
        },
        "51491e7dce734895ae134fa1edb558da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4fd92c009cc41a0b8766b8fe97bf733",
            "placeholder": "​",
            "style": "IPY_MODEL_d52b8ee1d1d645f0a54cf02fc10899b8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "643acf4ba8f14e9fa56d67791c355fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d247a9e2974ad58df095806de05e5f",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9b3a32765ce4604b0755d120be6b4ec",
            "value": 26
          }
        },
        "9e54bad4ae6b463491db4242fa6ff4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49f780699bd14c71980eddc54a01acc1",
            "placeholder": "​",
            "style": "IPY_MODEL_257e57345dfc4b6bb79d1c8cc3751f66",
            "value": " 26.0/26.0 [00:00&lt;00:00, 465B/s]"
          }
        },
        "215c77cdc03043f59a88f2f010414af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fd92c009cc41a0b8766b8fe97bf733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52b8ee1d1d645f0a54cf02fc10899b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d247a9e2974ad58df095806de05e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b3a32765ce4604b0755d120be6b4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49f780699bd14c71980eddc54a01acc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257e57345dfc4b6bb79d1c8cc3751f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74084b9d551f45e58076aa070ec85dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36bfc3b6167d4a5a9a82fae797243341",
              "IPY_MODEL_405932d0f54f4930b1091d68083c7e5e",
              "IPY_MODEL_9ecb3b50db624c0a8753572c908c3254"
            ],
            "layout": "IPY_MODEL_6ef541f21de249c6990dd6c795443467"
          }
        },
        "36bfc3b6167d4a5a9a82fae797243341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0502b407ff58476d9479ef7c17c37e0b",
            "placeholder": "​",
            "style": "IPY_MODEL_493d360dd2a4430abab2bac5635c2c33",
            "value": "vocab.json: 100%"
          }
        },
        "405932d0f54f4930b1091d68083c7e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22db6637147240ab9cf8beb7fee80ce7",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65a5e60bca7c4d8f8664e5614c723443",
            "value": 898822
          }
        },
        "9ecb3b50db624c0a8753572c908c3254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756c0fc1321849768f7c9ae0ba8ada79",
            "placeholder": "​",
            "style": "IPY_MODEL_f268437d514b4e5c85d4d323b6771da9",
            "value": " 899k/899k [00:00&lt;00:00, 1.29MB/s]"
          }
        },
        "6ef541f21de249c6990dd6c795443467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0502b407ff58476d9479ef7c17c37e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "493d360dd2a4430abab2bac5635c2c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22db6637147240ab9cf8beb7fee80ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a5e60bca7c4d8f8664e5614c723443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "756c0fc1321849768f7c9ae0ba8ada79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f268437d514b4e5c85d4d323b6771da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727f33d089864f1e9d171c1482a17b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3f468c24888407eadcf2c49e8829e4a",
              "IPY_MODEL_86bd9223cf964ed99e8a2590cda9444f",
              "IPY_MODEL_c57bf550c29b40768a969bba7824268b"
            ],
            "layout": "IPY_MODEL_3261f084a19f4133b81ffa552bb54daf"
          }
        },
        "b3f468c24888407eadcf2c49e8829e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e5e74ceb314e35806ceaf42f0a91d4",
            "placeholder": "​",
            "style": "IPY_MODEL_7140de18d89a423e95b8f5c80787c43d",
            "value": "merges.txt: 100%"
          }
        },
        "86bd9223cf964ed99e8a2590cda9444f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830b98263e524651ba1f341a6f2dd514",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88e565b6c06f430c948a2653e9c643bf",
            "value": 456318
          }
        },
        "c57bf550c29b40768a969bba7824268b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66fd003f3e684896a882cef31219dcb7",
            "placeholder": "​",
            "style": "IPY_MODEL_f74d4f9e0f7146099e0f516bd4ac6956",
            "value": " 456k/456k [00:00&lt;00:00, 23.6MB/s]"
          }
        },
        "3261f084a19f4133b81ffa552bb54daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e5e74ceb314e35806ceaf42f0a91d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7140de18d89a423e95b8f5c80787c43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830b98263e524651ba1f341a6f2dd514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e565b6c06f430c948a2653e9c643bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66fd003f3e684896a882cef31219dcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74d4f9e0f7146099e0f516bd4ac6956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trying put Pegasus Summerizer"
      ],
      "metadata": {
        "id": "jT-vOnOfpU4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Dependencies"
      ],
      "metadata": {
        "id": "yZ4eKAIriBMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install PyTorch\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j1KDw9qiizk",
        "outputId": "4f310c60-0338-45a2-e216-bffdf63da497"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install Huggingface transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDiex9yaiPn7",
        "outputId": "d0f898d7-92fb-4528-972d-0268e294de69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing dependencies, load model\n"
      ],
      "metadata": {
        "id": "HhkJb3pcjUOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
      ],
      "metadata": {
        "id": "HMHWjk1ujDgx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load tokenizer\n",
        "tokenizer= PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "6878295961844862ad19fdb307eeb9f3",
            "b834ecb457e7460e95794f06ff8f9b26",
            "37cf1022eaef4f6ca03203c555dcd40d",
            "494e8049b9f0491fa1550ed786a069c6",
            "9305aa2700314c41bf9608c2a3d1c419",
            "5339785cee504b039fe5ee46253b6f40",
            "35bff0c3f4444fe1a6dd18b963c4ce6e",
            "5ae1b8a886d743d29f93a50421a9eea6",
            "12852e1fa85b4366b6e9e30b68acfae6",
            "b6a2620940d3452a9e344f5c21a2809c",
            "f9502a6a9d444a8e8eb096b553c28a58",
            "43b7d952c8c547fdaeb2092298078ca7",
            "43ed67387c48447189a1a99e43b5bc4d",
            "1073c137a9ac461fa82b4b2ffda975df",
            "d2484b1d7f6e45eca358a2fa0476e55f",
            "34f511f39be0429c8581723b052c1b1d",
            "e98545a1a1aa46f5b436241bcc4eaae9",
            "c86ebc2fbf3f4e5b8caea0747411ad23",
            "57a359e77d9e45bfbe2eacff88330ba4",
            "b61eebce5a1941c58f86368a38515d5c",
            "cc77a838905044e0ae08646a7f15dbc2",
            "d59935584362487bb2dbc46b8292b785",
            "384b8a797fec482c9256b7a59ac80b25",
            "de15877dbd2743b7bb8f7845f2024a94",
            "b21c6b681c374645a2090a5a9a702c3e",
            "050d25095ac24adda6b67e297dc07082",
            "797c36bda59647c2ae30d2f1ea213d1b",
            "dc88b43c284b405c86dea8e5b6478b92",
            "7b5ff7375c724ab09e8e5958d26c4aab",
            "259ce277f92b411fbc869e4bcd26a7be",
            "c1e1f7ff8e9041f1a83cbbcc88512e53",
            "d9d3396e024244ac93d11eab1fbb4087",
            "cf1ce4181c0346bd901e3a0a34f25258",
            "6b99f0319be54fd5a6b978d8ab45a260",
            "3369a8a086cd47afb0856aa66b66e731",
            "88a7514624b64e5eb81517806301dd46",
            "956ccc1600de44a8a0a212c2b7384ab8",
            "806ee989ef9e45d5b7663a3a5f0fbdc5",
            "0e7a89bb009f40a4b56b475527730bea",
            "0ca3685d1dfd4fdc92b0b063bb8828c2",
            "66218f27f4c946edb90acddede969113",
            "727861c321e240c5a57c42558e37afb9",
            "71bd2bb3d1af48bc83b848900301cd50",
            "65d1485034db4e08b1487e07d9f753c3",
            "dee5ad7c5ffa4b01a180bcdf043d76cb",
            "f102a360b00640ba8a10578d24368e38",
            "18cb7d85c85a48739a680965b5c9980e",
            "88805064e1d041f7a1f71430e1a0e42c",
            "b7c67abc1b634b1783830d95e967d405",
            "f86b6ac9a8c645cc8221cac4c347a3c4",
            "9f9e691da28d4b73bc465b83914a13b5",
            "c02327527e8d484cab92ccc19f01bf80",
            "3350909b39f6480b99fd263f531e8447",
            "5cc2ed4b8011425faf94bd1c4e1db293",
            "2795667dd13044369d10f0a771393951"
          ]
        },
        "id": "tfvdz2FEj2hJ",
        "outputId": "d2ca7d93-4393-4c0d-f3da-29f9bb7b6b57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6878295961844862ad19fdb307eeb9f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43b7d952c8c547fdaeb2092298078ca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "384b8a797fec482c9256b7a59ac80b25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b99f0319be54fd5a6b978d8ab45a260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dee5ad7c5ffa4b01a180bcdf043d76cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#load model\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "3e4d7e48c65445439f13c886efcd4d32",
            "457c3b09aaf34ba38c4017845eb79e0a",
            "2d41cb92ac4f4938b01400f435549c68",
            "c040fafeaeda4c2fb587af8e1aae6585",
            "b139ad9654c342cb8cc09632f424a9dc",
            "f08e12bf17bb457cbcf8ba3193c928c1",
            "bf00a2d99ac64ee093e6a49d5eb7c103",
            "d5d41a564fda4e459ff4b2aa052c1917",
            "49b740a27e524184b70ba15dfff33e6e",
            "ef7432ed9ee44ce683471d96ddd270be",
            "f39d34edb7a04f0ebeb552a4f5b83a5a",
            "6ba8d3423e9347a7a36b34e0c653fad6",
            "d239df5e170d4145b212c91571e972fc",
            "e1c2cac63f254131b1a397a6696414f1",
            "f06b812d6a104dc08f8f0412051980ac",
            "ff561583d0ca44d2b85c69b30641ce74",
            "ec22187a874f4fe0bffdafef3df10d66",
            "71768559e8e24d60be4530af7331c670",
            "dd37d6a077564e08b29aa047b815853e",
            "ccfdb85f0f5b468a817bd57cefa37d93",
            "f5a7eb0cfd2e4bb6bfc378d8fdac0b8c",
            "502d654f5f8d425c91c129d8d71c3a1a"
          ]
        },
        "id": "WmdejWqbkouy",
        "outputId": "2117e830-4ceb-4e3b-a66b-38dc905953c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e4d7e48c65445439f13c886efcd4d32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba8d3423e9347a7a36b34e0c653fad6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform Abstractive Summerization"
      ],
      "metadata": {
        "id": "JgWi_8GRkyFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "text from 'https://cloud.google.com/discover/what-is-deep-learning'"
      ],
      "metadata": {
        "id": "7Oi_KLzMlJkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\" How does deep learning work?\n",
        "Deep learning works by using artificial neural networks to learn from data. Neural networks are made up of layers of interconnected nodes, and each node is responsible for learning a specific feature of the data.  Building on our previous example with images – in an image recognition network, the first layer of nodes might learn to identify edges, the second layer might learn to identify shapes, and the third layer might learn to identify objects.\n",
        "\n",
        "As the network learns, the weights on the connections between the nodes are adjusted so that the network can better classify the data. This process is called training, and it can be done using a variety of techniques, such as supervised learning, unsupervised learning, and reinforcement learning.\n",
        "\n",
        "Once a neural network has been trained, it can be used to make predictions with new data it’s received.\n",
        "\n",
        "Deep learning vs. machine learning\n",
        "Both deep learning and machine learning are branches of artificial intelligence, with machine learning being a broader term encompassing various techniques, including deep learning. Both machine learning and deep learning algorithms can be trained on labeled or unlabeled data, depending on the task and algorithm.\n",
        "\n",
        "Machine learning and deep learning are both applicable to tasks such as image recognition, speech recognition, and natural language processing. However, deep learning often outperforms traditional machine learning in complex pattern recognition tasks like image classification and object detection due to its ability to learn hierarchical representations of data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5x5zXq-ZkcVp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turning text to tokens\n",
        "tokens=tokenizer(text, padding=\"longest\" , truncation= True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "CBU0s5LnlMdD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zNfeXGmMllsO",
        "outputId": "946fd720-c816-4ef3-8817-6abe102b7824"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  722,   358,  1355,   761,   201,   152,  7496,   761,   659,   141,\n",
              "           303,  4958, 14849,  3296,   112,   543,   135,   335,   107, 45077,\n",
              "          3296,   127,   266,   164,   113,  4427,   113, 24305, 11406,   108,\n",
              "           111,   276,  9537,   117,  1470,   118,   761,   114,   739,  1048,\n",
              "           113,   109,   335,   107,  3671,   124,   150,  1331,   587,   122,\n",
              "          1055,   212,   115,   142,   805,  3771,   952,   108,   109,   211,\n",
              "          2865,   113, 11406,   382,   543,   112,  1956,  5198,   108,   109,\n",
              "           453,  2865,   382,   543,   112,  1956,  4664,   108,   111,   109,\n",
              "           776,  2865,   382,   543,   112,  1956,  3195,   107,   398,   109,\n",
              "           952, 23153,   108,   109, 11835,   124,   109,  3649,   317,   109,\n",
              "         11406,   127,  7460,   167,   120,   109,   952,   137,   340, 27648,\n",
              "           109,   335,   107,   182,   366,   117,   568,   569,   108,   111,\n",
              "           126,   137,   129,   479,   303,   114,   809,   113,  1739,   108,\n",
              "           253,   130, 15561,   761,   108, 53744,   761,   108,   111, 19189,\n",
              "           761,   107,  1603,   114, 14849,   952,   148,   174,  2492,   108,\n",
              "           126,   137,   129,   263,   112,   193, 10192,   122,   177,   335,\n",
              "           126,   123,   116,   915,   107,  7496,   761,  2875,   107,  1157,\n",
              "           761,  2595,  1355,   761,   111,  1157,   761,   127,  6106,   113,\n",
              "          4958,  3941,   108,   122,  1157,   761,   270,   114,  7792,  1286,\n",
              "         25109,   623,  1739,   108,   330,  1355,   761,   107,  2595,  1157,\n",
              "           761,   111,  1355,   761,  8970,   137,   129,  2492,   124, 11559,\n",
              "           132,  1596, 53541,   335,   108,  2212,   124,   109,  1778,   111,\n",
              "          7680,   107,  3838,   761,   111,  1355,   761,   127,   302,  4056,\n",
              "           112,  2722,   253,   130,   805,  3771,   108,  3442,  3771,   108,\n",
              "           111,   710,  1261,  2196,   107,   611,   108,  1355,   761,   432,\n",
              "         68474,  1113,  1157,   761,   115,  1482,  2293,  3771,  2722,   172,\n",
              "           805, 10526,   111,  2951,  6254,   640,   112,   203,   986,   112,\n",
              "           543, 35022, 13872,   113,   335,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{**tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bxqfcz_ImVXV",
        "outputId": "953f97b8-1cfa-4a10-e317-e7072cfb1071"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  722,   358,  1355,   761,   201,   152,  7496,   761,   659,   141,\n",
              "            303,  4958, 14849,  3296,   112,   543,   135,   335,   107, 45077,\n",
              "           3296,   127,   266,   164,   113,  4427,   113, 24305, 11406,   108,\n",
              "            111,   276,  9537,   117,  1470,   118,   761,   114,   739,  1048,\n",
              "            113,   109,   335,   107,  3671,   124,   150,  1331,   587,   122,\n",
              "           1055,   212,   115,   142,   805,  3771,   952,   108,   109,   211,\n",
              "           2865,   113, 11406,   382,   543,   112,  1956,  5198,   108,   109,\n",
              "            453,  2865,   382,   543,   112,  1956,  4664,   108,   111,   109,\n",
              "            776,  2865,   382,   543,   112,  1956,  3195,   107,   398,   109,\n",
              "            952, 23153,   108,   109, 11835,   124,   109,  3649,   317,   109,\n",
              "          11406,   127,  7460,   167,   120,   109,   952,   137,   340, 27648,\n",
              "            109,   335,   107,   182,   366,   117,   568,   569,   108,   111,\n",
              "            126,   137,   129,   479,   303,   114,   809,   113,  1739,   108,\n",
              "            253,   130, 15561,   761,   108, 53744,   761,   108,   111, 19189,\n",
              "            761,   107,  1603,   114, 14849,   952,   148,   174,  2492,   108,\n",
              "            126,   137,   129,   263,   112,   193, 10192,   122,   177,   335,\n",
              "            126,   123,   116,   915,   107,  7496,   761,  2875,   107,  1157,\n",
              "            761,  2595,  1355,   761,   111,  1157,   761,   127,  6106,   113,\n",
              "           4958,  3941,   108,   122,  1157,   761,   270,   114,  7792,  1286,\n",
              "          25109,   623,  1739,   108,   330,  1355,   761,   107,  2595,  1157,\n",
              "            761,   111,  1355,   761,  8970,   137,   129,  2492,   124, 11559,\n",
              "            132,  1596, 53541,   335,   108,  2212,   124,   109,  1778,   111,\n",
              "           7680,   107,  3838,   761,   111,  1355,   761,   127,   302,  4056,\n",
              "            112,  2722,   253,   130,   805,  3771,   108,  3442,  3771,   108,\n",
              "            111,   710,  1261,  2196,   107,   611,   108,  1355,   761,   432,\n",
              "          68474,  1113,  1157,   761,   115,  1482,  2293,  3771,  2722,   172,\n",
              "            805, 10526,   111,  2951,  6254,   640,   112,   203,   986,   112,\n",
              "            543, 35022, 13872,   113,   335,   107,     1]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summerize\n",
        "\n",
        "summary=model.generate(**tokens,min_length=50)"
      ],
      "metadata": {
        "id": "RkIyJPw3l3op"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary in tokens\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXwnRTDcmZzB",
        "outputId": "bef0231e-7663-4ffa-fed5-f384f8929e43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0, 7496,  761,  117,  114, 4444,  113, 4958, 3941,  120,  117,  263,\n",
              "          112, 1976, 8970,  112,  543,  135,  335,  108,  253,  130,  805, 3771,\n",
              "          132, 2951, 6254,  107, 1157,  761,  127, 6106,  113, 4958, 3941,  108,\n",
              "          111,  302, 1355,  761,  111, 1157,  761,  127,  263,  112, 1976, 8970,\n",
              "          112,  543,  135,  335,  108,  253,  130,  805, 3771,  132, 2951, 6254,\n",
              "          107,    1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode the summary\n",
        "tokenizer.decode(summary[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XlgnEFufmxia",
        "outputId": "a72cd4ad-5fdd-4ea5-c5df-bff91aea6483"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad>Deep learning is a branch of artificial intelligence that is used to train algorithms to learn from data, such as image recognition or object detection. machine learning are branches of artificial intelligence, and both deep learning and machine learning are used to train algorithms to learn from data, such as image recognition or object detection.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Web Scraping blogs and summerizing using hugging face transformer"
      ],
      "metadata": {
        "id": "V_OZrJDKpk7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Dependencies"
      ],
      "metadata": {
        "id": "fs5MrX1suNxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from transformers import pipeline\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "ZbL2uTy7pqSH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summerizer = pipeline('summarization')\n",
        "#can use t5-11b model too but its size is 45GB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "40d0cde005cb447c8e59c7a60a5e50ae",
            "40b0947a268540e38b6897276ef24b7a",
            "255f8f0558e041a18a06c66dcadbb5de",
            "2c1fc1941aa14bbc9ea6dd86d2185452",
            "248030d826444564a3e32f7a01cbff3f",
            "f3c2794c1af441bd831bf66d0e890381",
            "d0bf75cbd52840dea419e55308143294",
            "e40c260a59f24e41ac63226f42f5eb43",
            "286c2952f7494f7bb2c5db4c1f6079e7",
            "c5ea93e09db64954887ab6ca2e5b5bcd",
            "dc40289efcf74bef8012bac2f2ead002",
            "144c27c846f1415eb6831db06b8a6d80",
            "d61e002a49bc4082b7d0fdd22baa4ccb",
            "e3a3a15edeea42bf95560a7f591feda7",
            "dbdc65fa9a8f47fd81ec3966e34d1889",
            "3f38671c7e04420bb2f21b6e2beeb344",
            "0bd96125b5e34b83b33b637f8600510a",
            "e53a222114894bd8ab6cb9855082dfe1",
            "76f8e533e7b0486f809636d6ba3c72ce",
            "2f0fe79530d6446b810975e7d673b5aa",
            "a06405d418514319be21466ca234cb25",
            "892bb146754b4f24b2fbcd489acff221",
            "f728d84ad600496faf178eeddec81a68",
            "51491e7dce734895ae134fa1edb558da",
            "643acf4ba8f14e9fa56d67791c355fa0",
            "9e54bad4ae6b463491db4242fa6ff4e5",
            "215c77cdc03043f59a88f2f010414af8",
            "d4fd92c009cc41a0b8766b8fe97bf733",
            "d52b8ee1d1d645f0a54cf02fc10899b8",
            "90d247a9e2974ad58df095806de05e5f",
            "f9b3a32765ce4604b0755d120be6b4ec",
            "49f780699bd14c71980eddc54a01acc1",
            "257e57345dfc4b6bb79d1c8cc3751f66",
            "74084b9d551f45e58076aa070ec85dbf",
            "36bfc3b6167d4a5a9a82fae797243341",
            "405932d0f54f4930b1091d68083c7e5e",
            "9ecb3b50db624c0a8753572c908c3254",
            "6ef541f21de249c6990dd6c795443467",
            "0502b407ff58476d9479ef7c17c37e0b",
            "493d360dd2a4430abab2bac5635c2c33",
            "22db6637147240ab9cf8beb7fee80ce7",
            "65a5e60bca7c4d8f8664e5614c723443",
            "756c0fc1321849768f7c9ae0ba8ada79",
            "f268437d514b4e5c85d4d323b6771da9",
            "727f33d089864f1e9d171c1482a17b36",
            "b3f468c24888407eadcf2c49e8829e4a",
            "86bd9223cf964ed99e8a2590cda9444f",
            "c57bf550c29b40768a969bba7824268b",
            "3261f084a19f4133b81ffa552bb54daf",
            "98e5e74ceb314e35806ceaf42f0a91d4",
            "7140de18d89a423e95b8f5c80787c43d",
            "830b98263e524651ba1f341a6f2dd514",
            "88e565b6c06f430c948a2653e9c643bf",
            "66fd003f3e684896a882cef31219dcb7",
            "f74d4f9e0f7146099e0f516bd4ac6956"
          ]
        },
        "id": "x4q0GKbEuAi6",
        "outputId": "70003d68-f821-44c1-d544-e4d86c91e86f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d0cde005cb447c8e59c7a60a5e50ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "144c27c846f1415eb6831db06b8a6d80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f728d84ad600496faf178eeddec81a68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74084b9d551f45e58076aa070ec85dbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "727f33d089864f1e9d171c1482a17b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Blog Post from Medium"
      ],
      "metadata": {
        "id": "0eFD3Z2zvDu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL=r'https://distill.pub/2020/grand-tour/'"
      ],
      "metadata": {
        "id": "alW1wnBouvhN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(URL)"
      ],
      "metadata": {
        "id": "D0OHtww2wB3R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "collapsed": true,
        "id": "a614pEy4wGe6",
        "outputId": "e585366a-ae2e-4be6-c2ad-5c3c1d118278"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge,chrome=1\"><script>\\nwindow.addEventListener(\\'WebComponentsReady\\', function() {\\n  console.warn(\\'WebComponentsReady\\');\\n  const loaderTag = document.createElement(\\'script\\');\\n  loaderTag.src = \\'https://distill.pub/template.v2.js\\';\\n  document.head.insertBefore(loaderTag, document.head.firstChild);\\n});\\n</script><script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.0.17/webcomponents-loader.js\"></script>\\n\\n\\n<style id=\"distill-prerendered-styles\" type=\"text/css\">/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\nhtml {\\n  font-size: 14px;\\n\\tline-height: 1.6em;\\n  /* font-family: \"Libre Franklin\", \"Helvetica Neue\", sans-serif; */\\n  font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Oxygen, Ubuntu, Cantarell, \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", Arial, sans-serif;\\n  /*, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\";*/\\n  text-size-adjust: 100%;\\n  -ms-text-size-adjust: 100%;\\n  -webkit-text-size-adjust: 100%;\\n}\\n\\n@media(min-width: 768px) {\\n  html {\\n    font-size: 16px;\\n  }\\n}\\n\\nbody {\\n  margin: 0;\\n}\\n\\na {\\n  color: #004276;\\n}\\n\\nfigure {\\n  margin: 0;\\n}\\n\\ntable {\\n\\tborder-collapse: collapse;\\n\\tborder-spacing: 0;\\n}\\n\\ntable th {\\n\\ttext-align: left;\\n}\\n\\ntable thead {\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.05);\\n}\\n\\ntable thead th {\\n  padding-bottom: 0.5em;\\n}\\n\\ntable tbody :first-child td {\\n  padding-top: 0.5em;\\n}\\n\\npre {\\n  overflow: auto;\\n  max-width: 100%;\\n}\\n\\np {\\n  margin-top: 0;\\n  margin-bottom: 1em;\\n}\\n\\nsup, sub {\\n  vertical-align: baseline;\\n  position: relative;\\n  top: -0.4em;\\n  line-height: 1em;\\n}\\n\\nsub {\\n  top: 0.4em;\\n}\\n\\n.kicker,\\n.marker {\\n  font-size: 15px;\\n  font-weight: 600;\\n  color: rgba(0, 0, 0, 0.5);\\n}\\n\\n\\n/* Headline */\\n\\n@media(min-width: 1024px) {\\n  d-title h1 span {\\n    display: block;\\n  }\\n}\\n\\n/* Figure */\\n\\nfigure {\\n  position: relative;\\n  margin-bottom: 2.5em;\\n  margin-top: 1.5em;\\n}\\n\\nfigcaption+figure {\\n\\n}\\n\\nfigure img {\\n  width: 100%;\\n}\\n\\nfigure svg text,\\nfigure svg tspan {\\n}\\n\\nfigcaption,\\n.figcaption {\\n  color: rgba(0, 0, 0, 0.6);\\n  font-size: 12px;\\n  line-height: 1.5em;\\n}\\n\\n@media(min-width: 1024px) {\\nfigcaption,\\n.figcaption {\\n    font-size: 13px;\\n  }\\n}\\n\\nfigure.external img {\\n  background: white;\\n  border: 1px solid rgba(0, 0, 0, 0.1);\\n  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);\\n  padding: 18px;\\n  box-sizing: border-box;\\n}\\n\\nfigcaption a {\\n  color: rgba(0, 0, 0, 0.6);\\n}\\n\\nfigcaption b,\\nfigcaption strong, {\\n  font-weight: 600;\\n  color: rgba(0, 0, 0, 1.0);\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\n@supports not (display: grid) {\\n  .base-grid,\\n  distill-header,\\n  d-title,\\n  d-abstract,\\n  d-article,\\n  d-appendix,\\n  distill-appendix,\\n  d-byline,\\n  d-footnote-list,\\n  d-citation-list,\\n  distill-footer {\\n    display: block;\\n    padding: 8px;\\n  }\\n}\\n\\n.base-grid,\\ndistill-header,\\nd-title,\\nd-abstract,\\nd-article,\\nd-appendix,\\ndistill-appendix,\\nd-byline,\\nd-footnote-list,\\nd-citation-list,\\ndistill-footer {\\n  display: grid;\\n  justify-items: stretch;\\n  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];\\n  grid-column-gap: 8px;\\n}\\n\\n.grid {\\n  display: grid;\\n  grid-column-gap: 8px;\\n}\\n\\n@media(min-width: 768px) {\\n  .base-grid,\\n  distill-header,\\n  d-title,\\n  d-abstract,\\n  d-article,\\n  d-appendix,\\n  distill-appendix,\\n  d-byline,\\n  d-footnote-list,\\n  d-citation-list,\\n  distill-footer {\\n    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];\\n    grid-column-gap: 16px;\\n  }\\n\\n  .grid {\\n    grid-column-gap: 16px;\\n  }\\n}\\n\\n@media(min-width: 1000px) {\\n  .base-grid,\\n  distill-header,\\n  d-title,\\n  d-abstract,\\n  d-article,\\n  d-appendix,\\n  distill-appendix,\\n  d-byline,\\n  d-footnote-list,\\n  d-citation-list,\\n  distill-footer {\\n    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];\\n    grid-column-gap: 16px;\\n  }\\n\\n  .grid {\\n    grid-column-gap: 16px;\\n  }\\n}\\n\\n@media(min-width: 1180px) {\\n  .base-grid,\\n  distill-header,\\n  d-title,\\n  d-abstract,\\n  d-article,\\n  d-appendix,\\n  distill-appendix,\\n  d-byline,\\n  d-footnote-list,\\n  d-citation-list,\\n  distill-footer {\\n    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];\\n    grid-column-gap: 32px;\\n  }\\n\\n  .grid {\\n    grid-column-gap: 32px;\\n  }\\n}\\n\\n\\n\\n\\n.base-grid {\\n  grid-column: screen;\\n}\\n\\n/* .l-body,\\nd-article > *  {\\n  grid-column: text;\\n}\\n\\n.l-page,\\nd-title > *,\\nd-figure {\\n  grid-column: page;\\n} */\\n\\n.l-gutter {\\n  grid-column: gutter;\\n}\\n\\n.l-text,\\n.l-body {\\n  grid-column: text;\\n}\\n\\n.l-page {\\n  grid-column: page;\\n}\\n\\n.l-body-outset {\\n  grid-column: middle;\\n}\\n\\n.l-page-outset {\\n  grid-column: page;\\n}\\n\\n.l-screen {\\n  grid-column: screen;\\n}\\n\\n.l-screen-inset {\\n  grid-column: screen;\\n  padding-left: 16px;\\n  padding-left: 16px;\\n}\\n\\n\\n/* Aside */\\n\\nd-article aside {\\n  grid-column: gutter;\\n  font-size: 12px;\\n  line-height: 1.6em;\\n  color: rgba(0, 0, 0, 0.6)\\n}\\n\\n@media(min-width: 768px) {\\n  aside {\\n    grid-column: gutter;\\n  }\\n\\n  .side {\\n    grid-column: gutter;\\n  }\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\nd-title {\\n  padding: 2rem 0 1.5rem;\\n  contain: layout style;\\n  overflow-x: hidden;\\n}\\n\\n@media(min-width: 768px) {\\n  d-title {\\n    padding: 4rem 0 1.5rem;\\n  }\\n}\\n\\nd-title h1 {\\n  grid-column: text;\\n  font-size: 40px;\\n  font-weight: 700;\\n  line-height: 1.1em;\\n  margin: 0 0 0.5rem;\\n}\\n\\n@media(min-width: 768px) {\\n  d-title h1 {\\n    font-size: 50px;\\n  }\\n}\\n\\nd-title p {\\n  font-weight: 300;\\n  font-size: 1.2rem;\\n  line-height: 1.55em;\\n  grid-column: text;\\n}\\n\\nd-title .status {\\n  margin-top: 0px;\\n  font-size: 12px;\\n  color: #009688;\\n  opacity: 0.8;\\n  grid-column: kicker;\\n}\\n\\nd-title .status span {\\n  line-height: 1;\\n  display: inline-block;\\n  padding: 6px 0;\\n  border-bottom: 1px solid #80cbc4;\\n  font-size: 11px;\\n  text-transform: uppercase;\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\nd-byline {\\n  contain: style;\\n  overflow: hidden;\\n  border-top: 1px solid rgba(0, 0, 0, 0.1);\\n  font-size: 0.8rem;\\n  line-height: 1.8em;\\n  padding: 1.5rem 0;\\n  min-height: 1.8em;\\n}\\n\\n\\nd-byline .byline {\\n  grid-template-columns: 1fr 1fr;\\n  grid-column: text;\\n}\\n\\n@media(min-width: 768px) {\\n  d-byline .byline {\\n    grid-template-columns: 1fr 1fr 1fr 1fr;\\n  }\\n}\\n\\nd-byline .authors-affiliations {\\n  grid-column-end: span 2;\\n  grid-template-columns: 1fr 1fr;\\n  margin-bottom: 1em;\\n}\\n\\n@media(min-width: 768px) {\\n  d-byline .authors-affiliations {\\n    margin-bottom: 0;\\n  }\\n}\\n\\nd-byline h3 {\\n  font-size: 0.6rem;\\n  font-weight: 400;\\n  color: rgba(0, 0, 0, 0.5);\\n  margin: 0;\\n  text-transform: uppercase;\\n}\\n\\nd-byline p {\\n  margin: 0;\\n}\\n\\nd-byline a,\\nd-article d-byline a {\\n  color: rgba(0, 0, 0, 0.8);\\n  text-decoration: none;\\n  border-bottom: none;\\n}\\n\\nd-article d-byline a:hover {\\n  text-decoration: underline;\\n  border-bottom: none;\\n}\\n\\nd-byline p.author {\\n  font-weight: 500;\\n}\\n\\nd-byline .affiliations {\\n\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\nd-article {\\n  contain: layout style;\\n  overflow-x: hidden;\\n  border-top: 1px solid rgba(0, 0, 0, 0.1);\\n  padding-top: 2rem;\\n  color: rgba(0, 0, 0, 0.8);\\n}\\n\\nd-article > * {\\n  grid-column: text;\\n}\\n\\n@media(min-width: 768px) {\\n  d-article {\\n    font-size: 16px;\\n  }\\n}\\n\\n@media(min-width: 1024px) {\\n  d-article {\\n    font-size: 1.06rem;\\n    line-height: 1.7em;\\n  }\\n}\\n\\n\\n/* H2 */\\n\\n\\nd-article .marker {\\n  text-decoration: none;\\n  border: none;\\n  counter-reset: section;\\n  grid-column: kicker;\\n  line-height: 1.7em;\\n}\\n\\nd-article .marker:hover {\\n  border: none;\\n}\\n\\nd-article .marker span {\\n  padding: 0 3px 4px;\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.2);\\n  position: relative;\\n  top: 4px;\\n}\\n\\nd-article .marker:hover span {\\n  color: rgba(0, 0, 0, 0.7);\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.7);\\n}\\n\\nd-article h2 {\\n  font-weight: 600;\\n  font-size: 24px;\\n  line-height: 1.25em;\\n  margin: 2rem 0 1.5rem 0;\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.1);\\n  padding-bottom: 1rem;\\n}\\n\\n@media(min-width: 1024px) {\\n  d-article h2 {\\n    font-size: 36px;\\n  }\\n}\\n\\n/* H3 */\\n\\nd-article h3 {\\n  font-weight: 700;\\n  font-size: 18px;\\n  line-height: 1.4em;\\n  margin-bottom: 1em;\\n  margin-top: 2em;\\n}\\n\\n@media(min-width: 1024px) {\\n  d-article h3 {\\n    font-size: 20px;\\n  }\\n}\\n\\n/* H4 */\\n\\nd-article h4 {\\n  font-weight: 600;\\n  text-transform: uppercase;\\n  font-size: 14px;\\n  line-height: 1.4em;\\n}\\n\\nd-article a {\\n  color: inherit;\\n}\\n\\nd-article p,\\nd-article ul,\\nd-article ol,\\nd-article blockquote {\\n  margin-top: 0;\\n  margin-bottom: 1em;\\n  margin-left: 0;\\n  margin-right: 0;\\n}\\n\\nd-article blockquote {\\n  border-left: 2px solid rgba(0, 0, 0, 0.2);\\n  padding-left: 2em;\\n  font-style: italic;\\n  color: rgba(0, 0, 0, 0.6);\\n}\\n\\nd-article a {\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.4);\\n  text-decoration: none;\\n}\\n\\nd-article a:hover {\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.8);\\n}\\n\\nd-article .link {\\n  text-decoration: underline;\\n  cursor: pointer;\\n}\\n\\nd-article ul,\\nd-article ol {\\n  padding-left: 24px;\\n}\\n\\nd-article li {\\n  margin-bottom: 1em;\\n  margin-left: 0;\\n  padding-left: 0;\\n}\\n\\nd-article li:last-child {\\n  margin-bottom: 0;\\n}\\n\\nd-article pre {\\n  font-size: 14px;\\n  margin-bottom: 20px;\\n}\\n\\nd-article hr {\\n  grid-column: screen;\\n  width: 100%;\\n  border: none;\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.1);\\n  margin-top: 60px;\\n  margin-bottom: 60px;\\n}\\n\\nd-article section {\\n  margin-top: 60px;\\n  margin-bottom: 60px;\\n}\\n\\nd-article span.equation-mimic {\\n  font-family: georgia;\\n  font-size: 115%;\\n  font-style: italic;\\n}\\n\\nd-article > d-code,\\nd-article section > d-code  {\\n  display: block;\\n}\\n\\nd-article > d-math[block],\\nd-article section > d-math[block]  {\\n  display: block;\\n}\\n\\n@media (max-width: 768px) {\\n  d-article > d-code,\\n  d-article section > d-code,\\n  d-article > d-math[block],\\n  d-article section > d-math[block] {\\n      overflow-x: scroll;\\n      -ms-overflow-style: none;  // IE 10+\\n      overflow: -moz-scrollbars-none;  // Firefox\\n  }\\n\\n  d-article > d-code::-webkit-scrollbar,\\n  d-article section > d-code::-webkit-scrollbar,\\n  d-article > d-math[block]::-webkit-scrollbar,\\n  d-article section > d-math[block]::-webkit-scrollbar {\\n    display: none;  // Safari and Chrome\\n  }\\n}\\n\\nd-article .citation {\\n  color: #668;\\n  cursor: pointer;\\n}\\n\\nd-include {\\n  width: auto;\\n  display: block;\\n}\\n\\nd-figure {\\n  contain: layout style;\\n}\\n\\n/* KaTeX */\\n\\n.katex, .katex-prerendered {\\n  contain: style;\\n  display: inline-block;\\n}\\n\\n/* Tables */\\n\\nd-article table {\\n  border-collapse: collapse;\\n  margin-bottom: 1.5rem;\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.2);\\n}\\n\\nd-article table th {\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.2);\\n}\\n\\nd-article table td {\\n  border-bottom: 1px solid rgba(0, 0, 0, 0.05);\\n}\\n\\nd-article table tr:last-of-type td {\\n  border-bottom: none;\\n}\\n\\nd-article table th,\\nd-article table td {\\n  font-size: 15px;\\n  padding: 2px 8px;\\n}\\n\\nd-article table tbody :first-child td {\\n  padding-top: 2px;\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\nspan.katex-display {\\n  text-align: left;\\n  padding: 8px 0 8px 0;\\n  margin: 0.5em 0 0.5em 1em;\\n}\\n\\nspan.katex {\\n  -webkit-font-smoothing: antialiased;\\n  color: rgba(0, 0, 0, 0.8);\\n  font-size: 1.18em;\\n}\\n/*\\n * Copyright 2018 The Distill Template Authors\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\n@media print {\\n\\n  @page {\\n    size: 8in 11in;\\n    @bottom-right {\\n      content: counter(page) \" of \" counter(pages);\\n    }\\n  }\\n\\n  html {\\n    /* no general margins -- CSS Grid takes care of those */\\n  }\\n\\n  p, code {\\n    page-break-inside: avoid;\\n  }\\n\\n  h2, h3 {\\n    page-break-after: avoid;\\n  }\\n\\n  d-header {\\n    visibility: hidden;\\n  }\\n\\n  d-footer {\\n    display: none!important;\\n  }\\n\\n}\\n</style>\\n<!-- <script src=\"js/_distill/template.v2.js\"></script> -->\\n\\n  <!-- bootstrap -->\\n<!-- <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> -->\\n<link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css\" integrity=\"sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB\" crossorigin=\"anonymous\">\\n<script src=\"https://code.jquery.com/jquery-3.3.1.slim.min.js\" integrity=\"sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\" crossorigin=\"anonymous\"></script>\\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js\" integrity=\"sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\" crossorigin=\"anonymous\"></script>\\n<script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js\" integrity=\"sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T\" crossorigin=\"anonymous\"></script>\\n\\n<script src=\"js/lib/webgl_utils/webgl-utils.js\"></script>\\n<script src=\"js/lib/webgl_utils/initShaders2.js\"></script>\\n<script src=\"js/lib/webgl_utils/MV.js\"></script>\\n<script src=\"js/lib/numeric-1.2.6.js\"></script>\\n<script src=\"js/lib/math.js\"></script>\\n<script src=\"js/lib/lz-string.js\"></script>\\n<script src=\"js/lib/d3/v5/d3.js\"></script>\\n\\n<script src=\"js/modules/utils.js\"></script>\\n<script src=\"js/modules/constants.js\"></script>\\n<script src=\"js/modules/GrandTour.js\"></script>\\n\\n<script src=\"js/modules/TeaserRenderer.js\"></script>\\n<script src=\"js/modules/TeaserOverlay.js\"></script>\\n\\n<script src=\"js/modules/SoftmaxComparisonRenderer.js\"></script>\\n<script src=\"js/modules/SoftmaxComparisonOverlay.js\"></script>\\n\\n<!-- <script src=\"js/modules/ConfusionMatrixRenderer.js\"></script> -->\\n\\n<script src=\"js/modules/TesseractRenderer.js\"></script>\\n<script src=\"js/modules/TesseractOverlay.js\"></script>\\n\\n<!-- <script src=\"js/modules/NeuralNetRenderer.js\"></script> -->\\n<script src=\"js/modules/NeuralNetOverlay.js\"></script>\\n\\n<script src=\"js/modules/SmallMultipleRenderer.js\"></script>\\n<script src=\"js/modules/SmallMultipleOverlay.js\"></script>\\n<script src=\"js/sm0.js\"></script>\\n\\n<script src=\"js/modules/LayerTransitionRenderer.js\"></script>\\n<script src=\"js/modules/LayerTransitionOverlay.js\"></script>\\n\\n<script src=\"js/modules/LossHistoryRenderer.js\"></script>\\n\\n\\n<script>\\n  utils.cacheAll(constants.preloadUrls);\\n\\n  //Note: safari does not support window.requestIdleCallback\\n  if(window.requestIdleCallback){ \\n    for (let url of constants.layerTransitionUrls[\\'fashion-mnist\\']){\\n      window.requestIdleCallback(()=>{utils.cacheAll([url,] )});\\n    }\\n    for (let url of constants.adversarialUrls){\\n      window.requestIdleCallback(()=>{utils.cacheAll([url,] )});\\n    }\\n  }\\n  \\n  \\n  // window.requestIdleCallback(()=>{utils.cacheAll(constants.adversarialUrls)});\\n  // window.requestIdleCallback(()=>{utils.cacheAll(constants.layerTransitionUrls[\\'fashion-mnist\\'])});\\n  // window.requestIdleCallback(()=>{utils.cacheAll(constants.layerTransitionUrls[\\'mnist\\'])});\\n  // window.requestIdleCallback(()=>{utils.cacheAll(constants.layerTransitionUrls[\\'cifar10\\'])});\\n  // \\n\\n  let allViews = [];// teaser, nn2, sm0, nngt, tesseract, se, dm1, nngt2, lt2, lta];\\n</script>\\n\\n<link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.2.0/css/all.css\" integrity=\"sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ\" crossorigin=\"anonymous\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"css/style.css\">\\n<link rel=\"stylesheet\" media=\"screen and (max-width: 1024px)\" href=\"css/small-screen.css\">\\n\\n<style>\\n.nav{\\n  display: block;\\n}\\n</style>\\n\\n<title>Visualizing Neural Networks with the Grand Tour</title>\\n\\n<link rel=\"stylesheet\" href=\"https://distill.pub/third-party/katex/katex.min.css\" crossorigin=\"anonymous\">\\n    \\n    <link rel=\"icon\" type=\"image/png\" href=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=\\n\">\\n    <link href=\"/rss.xml\" rel=\"alternate\" type=\"application/rss+xml\" title=\"Articles from Distill\">\\n  \\n    <title>Visualizing Neural Networks with the Grand Tour</title>\\n    \\n    <link rel=\"canonical\" href=\"https://distill.pub/2020/grand-tour\">\\n    \\n    <!--  https://schema.org/Article -->\\n    <meta property=\"description\" itemprop=\"description\" content=\"By focusing on linear dimensionality reduction, we show how to visualize many dynamic phenomena in neural networks.\">\\n    <meta property=\"article:published\" itemprop=\"datePublished\" content=\"2020-03-16\">\\n    <meta property=\"article:created\" itemprop=\"dateCreated\" content=\"2020-03-16\">\\n    \\n    <meta property=\"article:modified\" itemprop=\"dateModified\" content=\"2020-05-27T16:57:31.000Z\">\\n    \\n    <meta property=\"article:author\" content=\"Mingwei Li\">\\n    <meta property=\"article:author\" content=\"Zhenge Zhao\">\\n    <meta property=\"article:author\" content=\"Carlos Scheidegger\">\\n    <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->\\n    <meta property=\"og:type\" content=\"article\">\\n    <meta property=\"og:title\" content=\"Visualizing Neural Networks with the Grand Tour\">\\n    <meta property=\"og:description\" content=\"By focusing on linear dimensionality reduction, we show how to visualize many dynamic phenomena in neural networks.\">\\n    <meta property=\"og:url\" content=\"https://distill.pub/2020/grand-tour\">\\n    <meta property=\"og:image\" content=\"https://distill.pub/2020/grand-tour/thumbnail.jpg\">\\n    <meta property=\"og:locale\" content=\"en_US\">\\n    <meta property=\"og:site_name\" content=\"Distill\">\\n  \\n    <!--  https://dev.twitter.com/cards/types/summary -->\\n    <meta name=\"twitter:card\" content=\"summary_large_image\">\\n    <meta name=\"twitter:title\" content=\"Visualizing Neural Networks with the Grand Tour\">\\n    <meta name=\"twitter:description\" content=\"By focusing on linear dimensionality reduction, we show how to visualize many dynamic phenomena in neural networks.\">\\n    <meta name=\"twitter:url\" content=\"https://distill.pub/2020/grand-tour\">\\n    <meta name=\"twitter:image\" content=\"https://distill.pub/2020/grand-tour/thumbnail.jpg\">\\n    <meta name=\"twitter:image:width\" content=\"560\">\\n    <meta name=\"twitter:image:height\" content=\"295\">\\n  \\n      <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->\\n    <meta name=\"citation_title\" content=\"Visualizing Neural Networks with the Grand Tour\">\\n    <meta name=\"citation_fulltext_html_url\" content=\"https://distill.pub/2020/grand-tour\">\\n    <meta name=\"citation_volume\" content=\"5\">\\n    <meta name=\"citation_issue\" content=\"3\">\\n    <meta name=\"citation_firstpage\" content=\"e25\">\\n    <meta name=\"citation_doi\" content=\"10.23915/distill.00025\">\\n    <meta name=\"citation_journal_title\" content=\"Distill\">\\n    <meta name=\"citation_journal_abbrev\" content=\"Distill\">\\n    <meta name=\"citation_issn\" content=\"2476-0757\">\\n    <meta name=\"citation_fulltext_world_readable\" content=\"\">\\n    <meta name=\"citation_online_date\" content=\"2020/03/16\">\\n    <meta name=\"citation_publication_date\" content=\"2020/03/16\">\\n    <meta name=\"citation_author\" content=\"Li, Mingwei\">\\n    <meta name=\"citation_author_institution\" content=\"University of Arizona\">\\n    <meta name=\"citation_author\" content=\"Zhao, Zhenge\">\\n    <meta name=\"citation_author_institution\" content=\"University of Arizona\">\\n    <meta name=\"citation_author\" content=\"Scheidegger, Carlos\">\\n    <meta name=\"citation_author_institution\" content=\"University of Arizona\">\\n    <meta name=\"citation_reference\" content=\"citation_title=The grand tour: a tool for viewing multidimensional data;citation_author=Daniel Asimov;citation_publication_date=1985;citation_journal_title=SIAM journal on scientific and statistical computing;citation_volume=6;citation_number=1;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Visualizing data using t-SNE;citation_author=Laurens van der Maaten;citation_author=Geoffrey Hinton;citation_publication_date=2008;citation_journal_title=Journal of machine learning research;citation_volume=9;citation_number=Nov;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Umap: Uniform manifold approximation and projection for dimension reduction;citation_author=Leland McInnes;citation_author=John Healy;citation_publication_date=2018;citation_arxiv_id=1802.03426;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Intriguing properties of neural networks;citation_author=Christian Szegedy;citation_author=Wojciech Zaremba;citation_author=Ilya Sutskever;citation_author=Joan Bruna;citation_author=Dumitru Erhan;citation_author=Ian Goodfellow;citation_author=Rob Fergus;citation_publication_date=2013;citation_arxiv_id=1312.6199;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=ImageNet Large Scale Visual Recognition Challenge;citation_author=Olga Russakovsky;citation_author=Jia Deng;citation_author=Hao Su;citation_author=Jonathan Krause;citation_author=Sanjeev Satheesh;citation_author=Sean Ma;citation_author=Zhiheng Huang;citation_author=Andrej Karpathy;citation_author=Aditya Khosla;citation_author=Michael Bernstein;citation_author=Alexander C. Berg;citation_author=Li Fei-Fei;citation_publication_date=2015;citation_journal_title=International Journal of Computer Vision (IJCV);citation_volume=115;citation_number=3;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=The mythos of model interpretability;citation_author=Zachary C Lipton;citation_publication_date=2016;citation_arxiv_id=1606.03490;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Visualizing dataflow graphs of deep learning models in tensorflow;citation_author=Kanit Wongsuphasawat;citation_author=Daniel Smilkov;citation_author=James Wexler;citation_author=Jimbo Wilson;citation_author=Dandelion Mane;citation_author=Doug Fritz;citation_author=Dilip Krishnan;citation_author=Fernanda B Viegas;citation_author=Martin Wattenberg;citation_publication_date=2018;citation_journal_title=IEEE transactions on visualization and computer graphics;citation_volume=24;citation_number=1;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=An algebraic process for visualization design;citation_author=Gordon Kindlmann;citation_author=Carlos Scheidegger;citation_publication_date=2014;citation_journal_title=IEEE transactions on visualization and computer graphics;citation_volume=20;citation_number=12;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Feature visualization;citation_author=Chris Olah;citation_author=Alexander Mordvintsev;citation_author=Ludwig Schubert;citation_publication_date=2017;citation_journal_title=Distill;citation_volume=2;citation_number=11;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=MNIST handwritten digit database;citation_author=Yann LeCun;citation_author=Corinna Cortes;citation_publication_date=2010;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms;citation_author=Han Xiao;citation_author=Kashif Rasul;citation_author=Roland Vollgraf;citation_publication_date=2017;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Learning multiple layers of features from tiny images;citation_author=Alex Krizhevsky;citation_author=Geoffrey Hinton;citation_author= others;citation_publication_date=2009;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Rectified linear units improve restricted boltzmann machines;citation_author=Vinod Nair;citation_author=Geoffrey E Hinton;citation_publication_date=2010;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Visualizing time-dependent data using dynamic t-SNE;citation_author=Paulo E Rauber;citation_author=Alexandre X Falcao;citation_author=Alexandru C Telea;citation_publication_date=2016;citation_journal_title=Proc. EuroVis Short Papers;citation_volume=2;citation_number=5;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=How to use t-sne effectively;citation_author=Martin Wattenberg;citation_author=Fernanda Viegas;citation_author=Ian Johnson;citation_publication_date=2016;citation_journal_title=Distill;citation_volume=1;citation_number=10;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=We Recommend a Singular Value Decomposition;citation_author=David Austin;citation_publication_date=2009;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=The singular values of convolutional layers;citation_author=Hanie Sedghi;citation_author=Vineet Gupta;citation_author=Philip M Long;citation_publication_date=2018;citation_arxiv_id=1805.10408;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Explaining and harnessing adversarial examples;citation_author=Ian J Goodfellow;citation_author=Jonathon Shlens;citation_author=Christian Szegedy;citation_publication_date=2014;citation_arxiv_id=1412.6572;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Animation, small multiples, and the effect of mental map preservation in dynamic graphs;citation_author=Daniel Archambault;citation_author=Helen Purchase;citation_author=Bruno Pinaud;citation_publication_date=2010;citation_journal_title=IEEE Transactions on Visualization and Computer Graphics;citation_volume=17;citation_number=4;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Animation: can it facilitate?;citation_author=Barbara Tversky;citation_author=Julie Bauer Morrison;citation_author=Mireille Betrancourt;citation_publication_date=2002;citation_journal_title=International journal of human-computer studies;citation_volume=57;citation_number=4;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Highway networks;citation_author=Rupesh Kumar Srivastava;citation_author=Klaus Greff;citation_author=Jurgen Schmidhuber;citation_publication_date=2015;citation_arxiv_id=1505.00387;\">\\n    <meta name=\"citation_reference\" content=\"citation_title=Going deeper with convolutions;citation_author=Christian Szegedy;citation_author=Wei Liu;citation_author=Yangqing Jia;citation_author=Pierre Sermanet;citation_author=Scott Reed;citation_author=Dragomir Anguelov;citation_author=Dumitru Erhan;citation_author=Vincent Vanhoucke;citation_author=Andrew Rabinovich;citation_publication_date=2015;\">\\n</head>\\n\\n<body distill-prerendered=\"\">\\n\\n<distill-header></distill-header>\\n<d-front-matter>\\n<script id=\"distill-front-matter\" type=\"text/json\">{\\n    \"title\": \"Visualizing Neural Networks with the Grand Tour\",\\n    \"description\": \"By focusing on linear dimensionality reduction, we show how to visualize many dynamic phenomena in neural networks.\",\\n    \"authors\": [\\n      {\\n        \"author\":\"Mingwei Li\",\\n        \"authorURL\":\"http://hdc.cs.arizona.edu/~mwli/\",\\n        \"affiliation\":\"University of Arizona\",\\n        \"affiliationURL\":\"https://www.cs.arizona.edu/\"\\n      },\\n      {\\n        \"author\":\"Zhenge Zhao\",\\n        \"authorURL\":\"https://zhengezhao.wordpress.com/\",\\n        \"affiliation\":\"University of Arizona\",\\n        \"affiliationURL\":\"https://www.cs.arizona.edu/\"\\n      },\\n      {\\n        \"author\":\"Carlos Scheidegger\",\\n        \"authorURL\":\"https://cscheid.net/\",\\n        \"affiliation\":\"University of Arizona\",\\n        \"affiliationURL\":\"https://www.cs.arizona.edu/\"\\n      }\\n    ],\\n    \"katex\": {\\n      \"delimiters\": [\\n        {\"left\": \"$\", \"right\": \"$\", \"display\": false}\\n      ]\\n    }\\n  }\\n</script>\\n</d-front-matter>\\n\\n\\n<!-- <nav class=\\'options navbar navbar-expand-lg navbar-dark bg-dark\\'>\\n  <div class=\"collapse navbar-collapse\" id=\"\">\\n    <ul class=\"navbar-nav mr-auto\">\\n      \\n      <li class=\"nav-item active\">\\n        <a class=\"nav-link\" href=\"#\">Dataset:</a>\\n      </li>\\n\\n      <li class=\"nav-item dropdown\">\\n        <a class=\"nav-link dropdown-toggle\" href=\"#\" id=\"dataset-option\" role=\"button\" data-toggle=\"dropdown\" aria-haspopup=\"true\" aria-expanded=\"false\">\\n          mnist\\n        </a>\\n        <div class=\"dropdown-menu bg-dark\" aria-labelledby=\"navbarDropdown\">\\n          <a class=\"dropdown-item bg-dark\" onclick=\"utils.setDataset(\\'mnist\\')\">mnist</a>\\n          <a class=\"dropdown-item bg-dark\" onclick=\"utils.setDataset(\\'fashion-mnist\\')\">fashion-mnist</a>\\n          <a class=\"dropdown-item bg-dark\" onclick=\"utils.setDataset(\\'cifar10\\')\">cifar10</a>\\n        </div>\\n      </li>\\n    </ul>\\n  </div>\\n</nav> -->\\n\\n<d-title>\\n\\n<h1>Visualizing Neural Networks with the Grand Tour</h1>\\n<p></p>\\n\\n<!-- <div class=\\'base-grid\\' id=\"teaser-container\">style=\"background-color:rgb(247, 247, 247);\" -->\\n<d-figure class=\"teaser\">\\n  <canvas id=\"teaser\" class=\"\"></canvas>\\n</d-figure>\\n<script src=\"js/teaser.js\"></script>\\n<!-- </div> -->\\n\\n<!-- <div class=\\'base-grid\\'> -->\\n<figcaption class=\"teaser\" style=\"margin-bottom: 0;\">The Grand Tour<d-cite key=\"asimov1985grand\"></d-cite> in action. This visualization shows the behavior of the final 10-dimensional layer\\n    of a neural network as it is trained on the MNIST dataset. With this technique, it is possible to see interesting training behavior. For example, the network appears to learn to classify digits \\n  <span style=\"color: #ff7f0e; cursor: pointer;\" onmouseover=\"teaser.overlay.onSelectLegend(1);\" onmouseout=\"teaser.overlay.restoreAlpha()\">1 \\n  </span> \\n  and \\n  <span style=\"color: #7f7f7f; cursor: pointer;\" onmouseover=\"teaser.overlay.onSelectLegend(7);\" onmouseout=\"teaser.overlay.restoreAlpha()\">7\\n  </span> \\n  in an almost discontinuous manner, after training epochs \\n  <a onclick=\"teaser.gt.setMatrix(DIGIT17_MATRIX); teaser.playFromEpoch(13);\">14</a>\\n  and \\n  <a onclick=\"teaser.gt.setMatrix(DIGIT17_MATRIX); teaser.playFromEpoch(19);\">21</a> \\n  respectively.\\n</figcaption>\\n<!-- </div> -->\\n\\n</d-title>\\n\\n<script>\\n  let c = utils.CLEAR_COLOR.map(d=>d*255);\\n  d3.selectAll(\\'.flex-item\\')\\n  .style(\\'background\\', d3.rgb(...c))\\n</script>\\n\\n<d-byline>\\n  <div class=\"byline grid\">\\n    <div class=\"authors-affiliations grid\">\\n      <h3>Authors</h3>\\n      <h3>Affiliations</h3>\\n      \\n        <p class=\"author\">\\n          \\n            <a class=\"name\" href=\"http://hdc.cs.arizona.edu/~mwli/\">Mingwei Li</a>\\n        </p>\\n        <p class=\"affiliation\">\\n        <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\\n        </p>\\n      \\n        <p class=\"author\">\\n          \\n            <a class=\"name\" href=\"https://zhengezhao.wordpress.com/\">Zhenge Zhao</a>\\n        </p>\\n        <p class=\"affiliation\">\\n        <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\\n        </p>\\n      \\n        <p class=\"author\">\\n          \\n            <a class=\"name\" href=\"https://cscheid.net/\">Carlos Scheidegger</a>\\n        </p>\\n        <p class=\"affiliation\">\\n        <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\\n        </p>\\n      \\n    </div>\\n    <div>\\n      <h3>Published</h3>\\n      \\n        <p>March 16, 2020</p> \\n    </div>\\n    <div>\\n      <h3>DOI</h3>\\n      \\n        <p><a href=\"https://doi.org/10.23915/distill.00025\">10.23915/distill.00025</a></p>\\n    </div>\\n  </div>\\n</d-byline><d-article>\\n\\n<p>\\n  The Grand Tour<d-cite key=\"asimov1985grand\"></d-cite> is a classic visualization technique for high-dimensional point clouds that <em>projects</em> a high-dimensional dataset into two dimensions.\\n\\n  Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer.\\n\\n  Unlike modern nonlinear projection methods such as t-SNE<d-cite key=\"maaten2008visualizing\"></d-cite> and UMAP<d-cite key=\"mcinnes2018umap\"></d-cite>, the Grand Tour is fundamentally a <em>linear</em> method.\\n\\n  In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.\\n  \\n  Concretely, we present three use cases of interest: visualizing the training process as the network weights change, visualizing the layer-to-layer behavior as the data goes through the network and visualizing both how adversarial examples<d-cite key=\"szegedy2013intriguing\"></d-cite> are crafted and how they fool a neural network.\\n</p>\\n\\n<h2>Introduction</h2>\\n\\n<p>\\n  Deep neural networks often achieve best-in-class performance in supervised learning contests such as the ImageNet Large Scale Visual Recognition Challenge (ILSVRC)<d-cite key=\"ILSVRC15\"></d-cite>.\\n  \\n  Unfortunately, their decision process is notoriously hard to interpret<d-cite key=\"lipton2016mythos\"></d-cite>, and their training process is often hard to debug<d-cite key=\"wongsuphasawat2018visualizing\"></d-cite>.\\n  \\n  In this article, we present a method to visualize the responses of a neural network which leverages properties of deep neural networks and properties of the <em>Grand Tour</em>.\\n\\n  Notably, our method enables us to more directly reason about the relationship between <em>changes in the data</em> and <em>changes in the resulting visualization</em><d-cite key=\"kindlmann2014algebraic\"></d-cite>.\\n\\n  As we will show, this data-visual correspondence is central to the method we present, especially when compared to other non-linear projection methods like UMAP and t-SNE.\\n</p>\\n<p></p>\\n\\n<p>\\n  To understand a neural network, we often try to observe its action on input examples (both real and synthesized)<d-cite key=\"olah2017feature\"></d-cite>.\\n  \\n  These kinds of visualizations are useful to elucidate the activation patterns of a neural network for a single example, but they might offer less insight about the relationship between different examples, different states of the network as it’s being trained, or how the data in the example flows through the different layers of a single network.\\n  \\n  Therefore, we instead aim to enable visualizations of the <em>context around</em> our objects of interest: what is the difference between the present training epoch and the next one? How does the classification of a network converge (or diverge) as the image is fed through the network?\\n\\n  Linear methods are attractive because they are particularly easy to reason about.\\n\\n  The Grand Tour works by generating a random, smoothly changing rotation of the dataset, and then projecting the data to the two-dimensional screen: both are linear processes.\\n\\n  Although deep neural networks are clearly not linear processes, they often confine their nonlinearity to a small set of operations, enabling us to still reason about their behavior.\\n\\n  Our proposed method better preserves context by providing more\\n  consistency: it should be possible to know <em>how the visualization\\n  would change, if the data had been different in a particular\\n  way</em>.\\n</p>\\n\\n<h2>Working Examples</h2>\\n\\n<p>\\n  To illustrate the technique we will present, we trained deep neural\\n  network models (DNNs) with 3 common image classification datasets:\\n  MNIST\\n  <d-footnote>\\n    MNIST<d-cite key=\"lecun2010mnist\"></d-cite> contains grayscale images of 10 handwritten digits\\n    <img class=\"img-center\" style=\"width: 70%;\" src=\"figs/mnist.png\">\\n    Image credit to <a href=\"https://en.wikipedia.org/wiki/File:MnistExamples.png\">https://en.wikipedia.org/wiki/File:MnistExamples.png</a> \\n  </d-footnote>,\\n  fashion-MNIST\\n  <d-footnote>\\n    Fashion-MNIST<d-cite key=\"xiao2017fashion\"></d-cite> contains grayscale images of 10 types of fashion items:\\n    <img class=\"img-center\" style=\"width: 70%;\" src=\"figs/fashion-mnist.png\">\\n    <!-- Image credit to <a href=\"https://github.com/zalandoresearch/fashion-mnist\">https://github.com/zalandoresearch/fashion-mnist</a>  -->\\n    Image credit to <a href=\"https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925\">https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925</a> \\n\\n  </d-footnote>\\n\\n  and CIFAR-10\\n  <d-footnote>\\n    CIFAR-10<d-cite key=\"krizhevsky2009cifar10\"></d-cite> contains RGB images of 10 classes of objects\\n    <img class=\"img-center\" style=\"width: 70%;\" src=\"figs/cifar-10.png\">\\n    Image credit to <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html</a> \\n  </d-footnote>. \\n  While our architecture is simpler and smaller than current DNNs, it’s still indicative of modern networks, and is complex enough to demonstrate both our proposed techniques and shortcomings of typical approaches.\\n</p>\\n\\n<p>\\n  The following figure presents a simple functional diagram of the neural network we will use throughout the article. The neural network is a sequence of linear (both convolutional<d-footnote>\\n    A convolution calculates weighted sums of regions in the input. \\n    In neural networks, the learnable weights in convolutional layers are referred to as the kernel.\\n    For example\\n    <img src=\"figs/conv.gif\" style=\"width:70%\" class=\"img-center\">\\n    Image credit to <a href=\"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9\">https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9</a>.<br>\\n    See also <a href=\"https://github.com/vdumoulin/conv_arithmetic\">Convolution arithmetic</a>.\\n  </d-footnote> and fully-connected<d-footnote>\\n    A fully-connected layer computes output neurons as weighted sum of input neurons. In matrix form, it is a matrix that linearly transforms the input vector into the output vector.\\n  </d-footnote>), max-pooling, and ReLU<d-footnote>\\n    First introduced by Nair and Hinton<d-cite key=\"nair2010relu\"></d-cite>, ReLU calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0,x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span> for each entry in a vector input. Graphically, it is a hinge at the origin: <img src=\"figs/relu.png\" style=\"width:60%\" class=\"img-center\">\\n    Image credit to <a href=\"https://pytorch.org/docs/stable/nn.html#relu\">https://pytorch.org/docs/stable/nn.html#relu</a>\\n  </d-footnote> layers, culminating in a softmax<d-footnote>\\n    Softmax function calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>S</mi><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><msub><mi>y</mi><mi>i</mi></msub></msup></mrow><mrow><msubsup><mi mathvariant=\"normal\">Σ</mi><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msub><mi>y</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">S(y_i)=\\\\frac{e^{y_i}}{\\\\Sigma_{j=1}^{N} e^{y_j}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.91098em;\"></span><span class=\"strut bottom\" style=\"height:1.6268249999999997em;vertical-align:-0.7158449999999998em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.6069750000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">Σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8328928571428571em;\"><span style=\"top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mathrm mtight\">1</span></span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.46117142857142857em;\"></span></span></span></span></span><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7789785714285715em;\"><span style=\"top:-2.9714357142857146em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathit mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5091600000000001em;\"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathit mtight\">i</span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7158449999999998em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> for each entry (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span>) in a vector input (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span>). For example, <img src=\"figs/softmax.png\" style=\"width:75%\" class=\"img-center\">\\n    Image credit to <a href=\"https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\">https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/</a>\\n  </d-footnote> layer.\\n</p>\\n\\n<d-figure class=\"nn2\"> <!-- style=\"grid-column: page;\" -->\\n  <svg id=\"nn2\" height=\"300\" style=\"width: 100%; height: 300px;\"></svg>\\n  <script src=\"js/nn2.js\"></script>\\n</d-figure>\\n<figcaption>Neural network opened. The colored blocks are building-block functions (i.e. neural network layers), the gray-scale heatmaps are either the input image or intermediate activation vectors after some layers.</figcaption>\\n   \\n<p>\\n  Even though neural networks are capable of incredible feats of classification, deep down, they really are just pipelines of relatively simple functions.\\n  For images, the input is a 2D array of scalar values for gray scale images or RGB triples for colored images.\\n  When needed, one can always flatten the 2D array into an equivalent (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi><mo>⋅</mo><mi>h</mi><mo>⋅</mo><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">w \\\\cdot h \\\\cdot c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">h</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">c</span></span></span></span></span>) -dimensional vector.\\n  Similarly, the intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen as vectors in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\\\mathbb{R}^n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68889em;\"></span><span class=\"strut bottom\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span>, where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> is the number of neurons in the layer. \\n  The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1.\\n  This vector view of data in neural network not only allows us represent complex data in a mathematically compact form, but also hints us on how to visualize them in a better way.\\n</p>\\n\\n<p>\\n  Most of the simple functions fall into two categories: they are either linear transformations of their inputs (like fully-connected layers or convolutional layers), or relatively simple non-linear functions that work component-wise (like sigmoid activations<d-footnote>\\n    Sigmoid calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>S</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">S(x)=\\\\frac{e^{x}}{e^{x}+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.91098em;\"></span><span class=\"strut bottom\" style=\"height:1.314311em;vertical-align:-0.403331em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">x</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathrm mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> for each entry (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span>) in a vector input. Graphically, it is an S-shaped curve.\\n    <img src=\"figs/sigmoid.png\" style=\"width:60%\" class=\"img-center\">\\n    Image credit to <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\">https://en.wikipedia.org/wiki/Sigmoid_function</a>\\n  </d-footnote> \\n  or ReLU activations).\\n  Some operations, notably max-pooling<d-footnote>\\n    Max-pooling calculates maximum of a region in the input. For example\\n    <!-- <img src=\"figs/maxpool.png\" style=\"width:60%\" class=\"img-center\">\\n    Image credit to <a href=\"https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\">https://computersciencewiki.org/index.php/Max-pooling_/_Pooling</a> -->\\n    <img src=\"figs/maxpool.gif\" style=\"width:70%\" class=\"img-center\">\\n    Image credit to <a href=\"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9\">https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9</a>\\n  </d-footnote> and softmax, do not fall into either categories. We will come back to this later.\\n</p>\\n\\n<p>\\n  The above figure helps us look at a single image at a time; however, it does not provide much context to understand the relationship between layers, between different examples, or between different class labels. For that, researchers often turn to more sophisticated visualizations.\\n</p>\\n\\n\\n<h2>Using Visualization to Understand DNNs</h2>\\n\\n<p>\\n  Let’s start by considering the problem of visualizing the training process of a DNN.\\n  When training neural networks, we optimize parameters in the function to minimize a scalar-valued loss function, typically through some form of gradient descent.\\n  We want the loss to keep decreasing, so we monitor the whole history of training and testing losses over rounds of training (or “epochs”), to make sure that the loss decreases over time. \\n  The following figure shows a line plot of the training loss for the MNIST classifier.\\n</p>\\n\\n<d-figure class=\"lh\" style=\"\">\\n  <svg id=\"lh\" height=\"300\" style=\"width: 100%; height: 300px;\"></svg>\\n  <script src=\"js/lh.js\"></script>\\n</d-figure>\\n\\n<p>\\n  Although its general trend meets our expectation as the loss steadily decreases, we see something strange around epochs 14 and 21: the curve goes almost flat before starting to drop again.\\n  What happened? What caused that?\\n</p>\\n\\n<d-figure class=\"lh-per-class\" style=\"\">\\n  <svg id=\"lh-per-class\" height=\"300\" style=\"width: 100%; height: 300px;\"></svg>\\n  <script src=\"js/lh-per-class.js\"></script>\\n</d-figure>\\n\\n<p>\\n  If we separate input examples by their true labels/classes and plot the <em>per-class</em> loss like above, we see that the two drops were caused by the classses 1 and 7; the model learns different classes at very different times in the training process. \\n  Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7.\\n  If we knew ahead of time to be looking for class-specific error rates, then this chart works well. But what if we didn’t really know what to look for?\\n</p>\\n\\n<p>\\n  In that case, we could consider visualizations of neuron activations (e.g. in the last softmax layer) for <em>all</em> examples at once, looking\\n  to find patterns like class-specific behavior, and other patterns besides.\\n  Should there be only two neurons in that layer, a simple two-dimensional scatter plot would work.\\n  However, the points in the softmax layer for our example datasets are 10 dimensional (and in larger-scale classification problems this number can be much larger).\\n  We need to either show two dimensions at a time (which does not scale well as the number of possible charts grows quadratically),\\n  or we can use <em>dimensionality reduction</em> to map the data into a two dimensional space and show them in a single plot. \\n</p>\\n\\n<i id=\"sm0-a\"></i>\\n<h3>The State-of-the-art Dimensionality Reduction is Non-linear</h3>\\n<p>\\n  Modern dimensionality reduction techniques such as t-SNE and UMAP are capable of impressive feats of summarization, providing two-dimensional images where similar points tend to be clustered together very effectively.\\n  However, these methods are not particularly good to understand the behavior of neuron activations at a fine scale.\\n  Consider the aforementioned intriguing feature about the different learning rate that the MNIST classifier has on digit 1 and 7: the network did not learn to recognize digit 1 until epoch 14, digit 7 until epoch 21.\\n  We compute t-SNE, Dynamic t-SNE<d-cite key=\"rauber2016visualizing\"></d-cite>, and UMAP projections of the epochs where the phenomenon we described happens.\\n  Consider now the task of identifying this class-specific behavior during training. As a reminder, in this case, the strange behavior happens with digits 1 and 7, around epochs 14 and 21 respectively.\\n  While the behavior is not particularly subtle&amp;emdash;digit goes from misclassified to correctly classified&amp;emdash; it is quite hard to notice it in any of the plots below. \\n  Only on careful inspection we can notice that (for example) in the UMAP plot, the digit 1 which clustered in the bottom in epoch 13 becomes a new tentacle-like feature in epoch 14. \\n</p>\\n<d-figure id=\"smallmultiple1\" class=\"smallmultiple\" style=\"\">\\n  <canvas id=\"sm1\" class=\"smallmultiple\" width=\"100\" height=\"200\"></canvas>\\n  <script>\\n  // let sm1 = createSmallMultiple(\\'#smallmultiple1\\', \\n  //   [13,14,15, 20,21,22], [\\'t-SNE\\', \\'Dynamic t-SNE\\', \\'UMAP\\'], \\n  //   \\'mnist\\', true, highlight_digits);\\n  let sm1 = createSmallMultiple(\\'#smallmultiple1\\', \\n    [13,14,15, 20,21,22], [\\'t-SNE\\', \\'Dynamic t-SNE\\', \\'UMAP\\'], \\n    \\'mnist\\', true);\\n</script>\\n</d-figure>\\n<figcaption>Softmax activations of the MNIST classifier with non-linear dimensionality reduction. Use the buttons on the right to highlight digits 1 and 7 in the plot, or drag rectangles around the charts to select particular point subsets to highlight in the other charts.</figcaption>\\n\\n<p>\\n  One reason that non-linear embeddings fail in elucidating this phenomenon is that, for the particular change in the data, the fail the principle of <em>data-visual correspondence</em> <d-cite key=\"kindlmann2014algebraic\"></d-cite>. More concretely, the principle states that specific visualization tasks should be modeled as functions that change the data; the visualization sends this change from data to visuals, and\\n  we can study the extent to which the visualization changes are easily perceptible.\\n  Ideally, we want the changes in data and visualization to <em>match in magnitude</em>: a barely noticeable change in visualization should be due to the smallest possible change in data, and a salient change in visualization should reflect a significant one in data.\\n  Here, a significant change happened in only a <em>subset</em> of data (e.g. all points of digit 1 from epoch 13 to 14), but <em>all</em> points in the visualization move dramatically.\\n  For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms.\\n  This property is not ideal for visualization because it fails the data-visual correspondence, making it hard to <em>infer</em> the underlying change in data from the change in the visualization.\\n</p>\\n\\n<p>\\n  Non-linear embeddings that have non-convex objectives also tend to be sensitive to initial conditions.\\n  For example, in MNIST, although the neural network starts to stabilize on epoch 30, t-SNE and UMAP still generate quite different projections between epochs 30, 31 and 32 (in fact, all the way to 99).\\n  Temporal regularization techniques (such as Dynamic t-SNE) mitigate these consistency issues, but still suffer from other interpretability issues<d-cite key=\"wattenberg2016use\"></d-cite>. \\n</p>\\n\\n<d-figure id=\"smallmultiple2\" class=\"smallmultiple\" style=\"\">\\n  <canvas id=\"sm2\" class=\"smallmultiple\" width=\"100\" height=\"200\"></canvas>\\n  <script>let sm2 = createSmallMultiple(\\'#smallmultiple2\\', [1,5,10,15,20,30,31,32], [\\'t-SNE\\', \\'Dynamic t-SNE\\', \\'UMAP\\', \\'Linear\\'], \\'mnist\\', true, ()=>{})</script>\\n</d-figure>\\n\\n<p>\\n  Now, let’s consider another task, that of identifying classes which the neural network tends to confuse.\\n  For this example, we will use the Fashion-MNIST dataset and classifier, and consider the confusion among sandals, sneakers and ankle boots.\\n  If we know ahead of time that these three classes are likely to confuse the classifier, then we can directly design an appropriate linear projection, as can be seen in the last row of the following figure (we found this particular projection using both the Grand Tour and the direct manipulation technique we later describe). The pattern in this case is quite salient, forming a triangle.\\n  T-SNE, in contrast, incorrectly separates the class clusters (possibly because of an inappropriately-chosen hyperparameter).\\n  UMAP successfully isolates the three classes, but even in this case it’s not possible to distinguish between three-way confusion for the classifier in epochs 5 and 10 (portrayed in a linear method by the presence of points near the center of the triangle), and multiple two-way confusions in later epochs (evidences by an “empty” center).\\n</p>\\n\\n<d-figure id=\"smallmultiple3\" class=\"smallmultiple\" style=\"\">\\n  <canvas id=\"sm3\" class=\"smallmultiple\" width=\"100\" height=\"200\"></canvas>\\n  <script>\\n  sm3 = createSmallMultiple(\\'#smallmultiple3\\', \\n    [2,5,10,20,50,99], [\\'t-SNE\\', \\'UMAP\\', \\'Linear\\'], \\n    \\'fashion-mnist\\', true, \\n    highlight_shoes_button, \\n    highlight_shoes,\\n  );\\n  </script>\\n</d-figure>\\n<figcaption>Three-way confusion in fashion-MNIST. Notice that in contrast to non-linear methods, a carefully-constructed linear projection can offer a better visualization of the classifier behavior.</figcaption>\\n\\n<h2>Linear Methods to the Rescue</h2>\\n\\n<p>\\n  When given the chance, then, we should prefer methods for which changes in the data produce predictable, visually salient changes in the result, and linear dimensionality reductions often have this property.\\n  Here, we revisit the linear projections described above in an interface where the user can easily navigate between different training epochs.\\n  In addition, we introduce another useful capability which is only available to linear methods, that of direct manipulation.\\n  Each linear projection from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> dimensions to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">2</span></span></span></span></span> dimensions can be represented by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> 2-dimensional vectors which have an intuitive interpretation: they are the vectors that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> canonical basis vector in the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span>-dimensional space will be projected to.\\n  In the context of projecting the final classification layer, this is especially simple to interpret: they are the destinations of an input that is classified with 100% confidence to any one particular class.\\n  If we provide the user with the ability to change these vectors by dragging around user-interface handles, then users can intuitively set up new linear projections.\\n</p>\\n\\n<p>  \\n  This setup provides additional nice properties that explain the salient patterns in the previous illustrations.\\n  For example, because projections are linear and the coefficients of vectors in the classification layer sum to one, classification outputs that are halfway confident between two classes are projected to vectors that are halfway between the class handles.\\n</p>\\n\\n<d-figure class=\"nngt\" style=\"\">\\n  <canvas id=\"nngt\" class=\"grandtour\"></canvas>\\n  <script src=\"js/nngt.js\"></script>\\n</d-figure>\\n<figcaption>\\n  From\\n  <a onclick=\"nngt.gt.setMatrix(DIGIT17_MATRIX)\">this linear projection</a>, we can easily identify the learning of \\n  <span style=\"color: #ff7f0e;\">digit 1</span> on \\n  <a onclick=\"nngt.setEpochIndex(13)\">epoch 14</a> and \\n  <span style=\"color: #7f7f7f;\">digit 7</span> on \\n  <a onclick=\"nngt.setEpochIndex(19)\">epoch 21</a>.\\n</figcaption>\\n\\n<p>\\n  This particular property is illustrated clearly in the Fashion-MNIST example below.\\n  The model confuses sandals, sneakers and ankle boots, as data points form a triangular shape in the softmax layer.\\n</p>\\n\\n<d-figure class=\"nngt-single-epoch-2\" style=\"\">\\n  <canvas id=\"nngt-single-epoch-2\" class=\"grandtour\"></canvas>\\n  <script src=\"js/se2.js\"></script>\\n</d-figure>\\n<figcaption>\\n  This <a onclick=\"\\n    se2.gt.setMatrix(SSA_MATRIX);\\n    se2.overlay.onSelectLegend(d3.range(10));\\n    se2.overlay.selectedClasses = new Set();\\n  \">linear projection</a> clearly shows model’s confusion among\\n  <span style=\"color: #8c564b;\">sandals</span>,\\n  <span style=\"color: #7f7f7f;\">sneakers</span>, and\\n  <span style=\"color: #17becf;\">ankle boots</span>.\\n  Similarly, <a onclick=\"\\n    se2.gt.setMatrix(PCS_MATRIX);\\n    se2.overlay.onSelectLegend(d3.range(10));\\n    se2.overlay.selectedClasses = new Set();\\n  \">this projection</a> shows the true three-way confusion about\\n  <span style=\"color: #2ca02c;\">pullovers</span>,\\n  <span style=\"color: #9467bd;\">coats</span>, and\\n  <span style=\"color: #e377c2;\">shirts</span>.\\n  (The <span style=\"color: #e377c2;\">shirts</span> are also get confused with \\n  <span style=\"color: #1f77b4;\">t-shirts/tops</span>. )\\n  Both projections are found by direct manipulations.\\n  <br>\\n</figcaption>\\n\\n<p>\\n  Examples falling between classes indicate that the model has trouble distinguishing the two, such as sandals vs. sneakers, and sneakers vs. ankle boot classes. \\n  Note, however, that this does not happen as much for sandals vs. ankle boots: not many examples fall between these two classes. \\n  Moreover, most data points are projected close to the edge of the triangle. \\n  This tells us that most confusions happen between two out of the three classes, they are really two-way confusions.\\n\\n  Within the same dataset, we can also see pullovers, coats and shirts filling a triangular <em>plane</em>.\\n  This is different from the sandal-sneaker-ankle-boot case, as examples not only fall on the boundary of a triangle, but also in its interior: a true three-way confusion. \\n\\n  Similarly, in the CIFAR-10 dataset we can see confusion between dogs and cats, airplanes and ships.\\n  The mixing pattern in CIFAR-10 is not as clear as in fashion-MNIST, because many more examples are misclassified.\\n</p>\\n\\n\\n<d-figure class=\"nngt-single-epoch-3\" style=\"\">\\n  <canvas id=\"nngt-single-epoch-3\" class=\"grandtour\"></canvas>\\n  <script src=\"js/se3.js\"></script>\\n</d-figure>\\n<figcaption>\\n  This <a onclick=\"\\n    se3.gt.setMatrix(CD_MATRIX);\\n    se3.overlay.onSelectLegend(d3.range(10));\\n    se3.overlay.selectedClasses = new Set();\\n  \">linear projection</a> clearly shows model’s confusion between\\n  <span style=\"color: #d62728; \">cats</span> and\\n  <span style=\"color: #8c564b;\">dogs</span>.\\n  Similarly, <a onclick=\"\\n    se3.gt.setMatrix(AS_MATRIX);\\n    se3.overlay.onSelectLegend(d3.range(10));\\n    se3.overlay.selectedClasses = new Set();\\n  \">this projection</a> shows the confusion about\\n  <span style=\"color: #1f77b4;\">airplanes</span> and\\n  <span style=\"color: #bcbd22;\">ships</span>.\\n  Both projections are found by direct manipulations.\\n</figcaption>\\n\\n<h2>The Grand Tour</h2>\\n\\n<p>\\n  In the previous section, we took advantage of the fact that we knew which classes to visualize.\\n  That meant it was easy to design linear projections for the particular tasks at hand.\\n  But what if we don’t know ahead of time which projection to choose from, because we don’t quite know what to look for?\\n  Principal Component Analysis (PCA) is the quintessential linear dimensionality reduction method,\\n  choosing to project the data so as to preserve the most variance possible. \\n  However, the distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector.<d-footnote>We are assuming a class-balanced training dataset. Nevertheless, if the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much either.</d-footnote>\\n  As a result, even though PCA projections are interpretable and consistent through training epochs, the first two principal components of softmax activations are not substantially better than the third.\\n  So which of them should we choose?\\n  Instead of PCA, we propose to visualize this data by smoothly animating random projections, using a technique called the Grand Tour<d-cite key=\"asimov1985grand\"></d-cite>.\\n</p>\\n\\n<p>\\nStarting with a random velocity, it smoothly rotates data points around the origin in high dimensional space, and then projects it down to 2D for display. \\nHere are some examples of how Grand Tour acts on some (low-dimensional) objects:\\n</p>\\n<ul>\\n<li>On a square, the Grand Tour rotates it with a constant angular velocity.</li> \\n<li>On a cube, the Grand Tour rotates it in 3D, and its 2D projection let us see every facet of the cube. </li>\\n<li>On a 4D cube (a <em>tesseract</em>), the rotation happens in 4D and the 2D view shows every possible projection.</li>\\n</ul>\\n<d-figure class=\"tesseract\" style=\"\">\\n<canvas id=\"tesseract\" style=\"width: 100%; height: 150px;\"></canvas>\\n<figcaption>Grand tours of a square, a cube and a tesseract</figcaption>\\n<script src=\"js/tesseract.js\"></script>\\n</d-figure>\\n\\n<h3>The Grand Tour of the Softmax Layer</h3>\\n<p>\\n  We first look at the Grand Tour of the softmax layer. \\n  The softmax layer is relatively easy to understand because its axes have strong semantics. As we described earlier, the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th axis corresponds to network’s <em>confidence</em> about predicting that the given input belongs to the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th class. \\n</p>\\n\\n<i id=\"nngt-single-epoch-a\"></i>\\n\\n<d-figure class=\"nngt-single-epoch-1\" style=\"\">\\n  <canvas id=\"nngt-single-epoch-1\" class=\"grandtour\"></canvas>\\n  <script src=\"js/se1.js\"></script>\\n</d-figure>\\n<figcaption>\\n  The Grand Tour of softmax layer in the last (99<sup>th</sup>) epoch, with \\n  <a onclick=\"utils.setDataset(\\'mnist\\');\">MNIST</a>, \\n  <a onclick=\"utils.setDataset(\\'fashion-mnist\\');\">fashion-MNIST</a> or \\n  <a onclick=\"utils.setDataset(\\'cifar10\\');\">CIFAR-10</a> dataset.\\n</figcaption>\\n\\n<p>\\n  The Grand Tour of the softmax layer lets us qualitatively assess the performance of our model.\\n  In the particular case of this article, since we used comparable architectures for three datasets, this also allows us to gauge the relative difficulty of classifying each dataset. \\n  We can see that data points are most confidently classified for the MNIST dataset, where the digits are close to one of the ten corners of the softmax space. For Fashion-MNIST or CIFAR-10, the separation is not as clean, and more points appear <em>inside</em> the volume.\\n</p>\\n\\n<h3>The Grand Tour of Training Dynamics</h3>\\n\\n<p>\\n  Linear projection methods naturally give a formulation that is independent of the input points, allowing us to keep the projection fixed while the\\n  data changes.\\n  To recap our working example, we trained each of the neural networks for 99 epochs and recorded the entire history of neuron activations on a subset of training and testing examples. We can use the Grand Tour, then, to visualize the actual training process of these networks.\\n</p>\\n\\n<p>\\n  In the beginning when the neural networks are randomly initialized, all examples are placed around the center of the softmax space, with equal weights to each class. \\n  Through training, examples move to class vectors in the softmax space. The Grand Tour also lets us\\n  compare visualizations of the training and testing data, giving us a qualitative assessment of over-fitting. \\n  In the MNIST dataset, the trajectory of testing images through training is consistent with the training set. \\n  Data points went directly toward the corner of its true class and all classes are stabilized after about 50 epochs.\\n  On the other hand, in CIFAR-10 there is an <em>inconsistency</em> between the training and testing sets. Images from the testing set keep oscillating while most images from training converges to the corresponding class corner. \\n  In epoch 99, we can clearly see a difference in distribution between these two sets.\\n  This signals that the model overfits the training set and thus does not generalize well to the testing set. \\n</p>\\n\\n<d-figure class=\"nngt2\" style=\"\">\\n  <canvas id=\"nngt2\" class=\"grandtour\"></canvas>\\n  <script src=\"js/nngt2.js\"></script>\\n</d-figure>\\n<figcaption>\\n  With <a onclick=\"\\n    utils.setDataset(\\'cifar10\\'); \\n    nngt2.gt.setMatrix(TT_MATRIX); \\n    nngt2.setEpochIndex(99);\\n    nngt2.shouldAutoNextEpoch = true; //set to true then click play button to pause it.\\n    nngt2.overlay.playButton.on(\\'click\\')();\\n    \">\\n  this view of CIFAR-10</a>&nbsp;, \\n  the color of points are more mixed in testing (right) than training (left) set, showing an over-fitting in the training process.\\n  Compare \\n  <a onclick=\"utils.setDataset(\\'cifar10\\');\">CIFAR-10</a> \\n  with \\n  <a onclick=\"utils.setDataset(\\'mnist\\');\">MNIST</a>\\n  or <a onclick=\"utils.setDataset(\\'fashion-mnist\\');\">fashion-MNIST</a>, \\n  where there is less difference between training and testing sets.\\n</figcaption>\\n\\n\\n\\n\\n\\n<h3 name=\"layer-dynamics\">The Grand Tour of Layer Dynamics</h3>\\n\\n<p>\\n  Given the presented techniques of the Grand Tour and direct manipulations on the axes, we can in theory visualize and manipulate any intermediate layer of a neural network by itself.  Nevertheless, this is not a very satisfying approach, for two reasons:\\n  </p><ul>\\n    <li>\\n      In the same way that we’ve kept the projection fixed as the training data changed, we would like to “keep the projection fixed”, as the data moves through the layers in the neural network. However, this is not straightforward. For example, different layers in a neural network have different dimensions. How do we connect rotations of one layer to rotations of the other?\\n    </li>\\n    <li>\\n      The class “axis handles” in the softmax layer convenient, but that’s only practical when the dimensionality of the layer is relatively small.\\n      With hundreds of dimensions, for example, there would be too many axis handles to naturally interact with.\\n      In addition, hidden layers do not have as clear semantics as the softmax layer, so manipulating them would not be as intuitive.\\n    </li>\\n  </ul>\\n<p></p>\\n\\n<p>\\n  To address the first problem, we will need to pay closer attention to the way in which layers transform the data that they are given.  \\n  To see how a linear transformation can be visualized in a particularly ineffective way, consider the following (very simple) weights (represented by a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span>) which take a 2-dimensional hidden layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span> and produce activations in another 2-dimensional layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>. The weights simply negate two activations in 2D:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn><mo separator=\"true\">,</mo><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\n    A = \\\\begin{bmatrix}\\n    -1, 0 \\\\\\\\\\n    0, -1\\n    \\\\end{bmatrix}\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.45em;\"></span><span class=\"strut bottom\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span><span class=\"mrel\">=</span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord mathrm\">1</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord\">−</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></span>\\n  Imagine that we wish to visualize the behavior of network as the data moves from layer to layer. One way to interpolate the source <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> and destination <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mi>A</mi><mo>(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>)</mo><mo>=</mo><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1 = A(x_0) = -x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\">A</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> of this action <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> is by a simple linear interpolation\\n\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo>)</mo><mo>⋅</mo><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi><mo>⋅</mo><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mn>2</mn><mi>t</mi><mo>)</mo><mo>⋅</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\n  x_t = (1-t) \\\\cdot x_0 + t \\\\cdot x_1 = (1-2t) \\\\cdot x_0    \\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">t</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">t</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathrm\">2</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span></span>\\n  for <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo>]</mo><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">t \\\\in [0,1].</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">t</span><span class=\"mrel\">∈</span><span class=\"mopen\">[</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">]</span><span class=\"mord mathrm\">.</span></span></span></span></span>\\n\\n  Effectively, this strategy reuses the linear projection coefficients from one layer to the next. This is a natural thought, since they have the same dimension.\\n  However, notice the following: the transformation given by A is a simple rotation of the data. Every linear transformation of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span> could be encoded simply as a linear transformation of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>, if only that transformation operated on the negative values of the entries.\\n  In addition, since the Grand Tour has a rotation itself built-in, for every configuration that gives a certain picture of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>, there exists a <em>different</em> configuration that would yield the same picture for layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>, by taking the action of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> into account.\\n  In effect, the naive interpolation fails the principle of data-visual correspondence: a simple change in data (negation in 2D/180 degree rotation) results in a drastic change in visualization (all points cross the origin).\\n</p>\\n\\n<p>\\n  This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations.\\n  We should seek to explicitly articulate what are purely representational artifacts that we should discard, and what are the real features a visualization we should <em>distill</em> from the representation.\\n  Here, we claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities.\\n  As we will show, the Grand Tour is particularly attractive in this case because it is can be made to be invariant to rotations in data.\\n  As a result, the rotational components in the linear transformations of a neural network will be explicitly made invisible.\\n</p>\\n\\n<p>\\n  Concretely, we achieve this by taking advantage of a central theorem of linear algebra. \\n  The <em>Singular Value Decomposition</em> (SVD) theorem shows that <em>any</em> linear transformation can be decomposed into a sequence of very simple operations: a rotation, a scaling, and another rotation<d-cite key=\"austin2009svd\"></d-cite>. \\n\\n  Applying a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> to a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span> is then equivalent to applying those simple operations: <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>A</mi><mo>=</mo><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">x A = x U \\\\Sigma V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\">A</span><span class=\"mrel\">=</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>.\\n  But remember that the Grand Tour works by rotating the dataset and then projecting it to 2D.\\n  Combined, these two facts mean that as far as the Grand Tour is concerned, visualizing a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span> is the same as visualizing <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">x U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span>, and visualizing a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">x U \\\\Sigma V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span> is the same as visualizing <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">x U \\\\Sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span></span></span></span></span>. \\n  This means that any linear transformation seen by the Grand Tour is equivalent to the transition between <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">x U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">x U \\\\Sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span></span></span></span></span> - a simple (coordinate-wise) scaling. \\n  This is explicitly saying that any linear operation (whose matrix is represented in standard bases) is a scaling operation with appropriately chosen orthonormal bases on both sides.\\n  So the Grand Tour provides a natural, elegant and computationally efficient way to <em>align</em> visualizations of activations separated by fully-connected (linear) layers.<d-footnote>Convolutional layers are also linear. One can instantly see that by forming the linear transformations between flattened feature maps, or by taking the circulant structure of convolutional layers directly into account<d-cite key=\"sedghi2018singular\"></d-cite></d-footnote>\\n</p>\\n\\n<p>\\n  (For the following portion, we reduce the number of data points to 500 and epochs to 50, in order to reduce the amount of data transmitted in a web-based demonstration.)\\n  With the linear algebra structure at hand, now we are able to trace behaviors and patterns from the softmax back to previous layers.\\n  In fashion-MNIST, for example, we observe a separation of shoes (sandals, sneakers and ankle boots as a group) from all other classes in the softmax layer. \\n  Tracing it back to earlier layers, we can see that this separation happened as early as <a onclick=\"lt2Figure.onscreen()\">layer 5</a>:\\n</p>\\n<d-figure class=\"lt2\" style=\"\">\\n  <canvas id=\"lt2\" class=\"layertransition\"></canvas>\\n  <script src=\"js/lt2.js\"></script>\\n</d-figure>\\n<figcaption>With layers aligned, it is easy to see the early separation of shoes from <a onclick=\"\\nlt2.onDatasetChange(\\'fashion-mnist\\');\\nlt2Figure.onscreen();\\nlt2.overlay.layerPlayButton.on(\\'click\\')();\\n\">this view</a>.</figcaption>\\n\\n<h3>The Grand Tour of Adversarial Dynamics</h3>\\n<p>\\n  As a final application scenario, we show how the Grand Tour can also elucidate the behavior of adversarial examples<d-cite key=\"szegedy2013intriguing\"></d-cite> as they are processed by a neural network.\\n  For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s.\\n  Previously, we either animated the training dynamics or the layer dynamics.\\n  We fix a well-trained neural network, and visualize the training process of adversarial examples, since they are often themselves generated by an optimization process. Here, we used the Fast Gradient Sign method.<d-cite key=\"goodfellow2014explaining\"></d-cite>\\n  Again, because the Grand Tour is a linear method, the change in the positions of the adversarial examples over time can be faithfully attributed to changes in how the neural network perceives the images, rather than potential artifacts of the visualization.\\n  Let us examine how adversarial examples evolved to fool the network:\\n</p>\\n<d-figure class=\"lta\" style=\"\">\\n  <canvas id=\"lta\" class=\"layertransition\"></canvas>\\n  <script src=\"js/lta.js\"></script>\\n</d-figure>\\n<figcaption>\\n  From <a onclick=\"ltaFigure.onscreen()\">this view of softmax</a>, we can see how  \\n  <span style=\"color: #444444\">adversarial examples</span> \\n  evolved from <span style=\"color: #bcbd22\">8s</span> \\n  into <span style=\"color: #1f77b4\">0s</span>.\\n  In the corresponding <a onclick=\"ltaFigure.onscreen(); lta.overlay.onLayerSliderInput(10);\">pre-softmax</a> however, these adversarial examples stop around the decision boundary of two classes. \\n  Show data as <a onclick=\"lta.setMode(\\'image\\')\">images</a> to see the actual images generated in each step, or <a onclick=\"lta.setMode(\\'point\\')\">dots</a> colored by labels.\\n</figcaption>\\n\\n<p>\\n  Through this adversarial training, the network eventually claims, with high confidence, that the inputs given are all 0s.\\n  If we stay in the softmax layer and slide though the adversarial training steps in the plot, we can see adversarial examples move from a high score for class 8 to a high score for class 0.\\n  Although all adversarial examples are classified as the target class (digit 0s) eventually, some of them detoured somewhere close to the centroid of the space (around the 25th epoch) and then moved towards the target. \\n  Comparing the actual images of the two groups, we see those that those “detouring” images tend to be noisier.\\n</p>\\n<p>\\n  More interesting, however, is what happens in the intermediate layers.\\n  In pre-softmax, for example, we see that these <span style=\"color: #444444; font-weight: 550;\">fake 0s</span> behave differently from the <span style=\"color: #1f77b4; font-weight: 550;\">genuine 0s</span>: they live closer to the decision boundary of two classes and form a plane by themselves. \\n</p>\\n\\n<h2>Discussion</h2>\\n\\n<h3>Limitations of the Grand Tour</h3>\\n<p>\\n  Early on, we compared several state-of-the-art dimensionality reduction techniques with the Grand Tour, showing that non-linear methods do not have as many desirable properties as the Grand Tour for understanding the behavior of neural networks. \\n  However, the state-of-the-art non-linear methods come with their own strength. \\n  Whenever geometry is concerned, like the case of understanding multi-way confusions in the softmax layer, linear methods are more interpretable because they preserve certain geometrical structures of data in the projection. \\n  When topology is the main focus, such as when we want to cluster the data or we need dimensionality reduction for downstream models that are less sensitive to geometry, we might choose non-linear methods such as UMAP or t-SNE for they have more freedom in projecting the data, and will generally make better use of the fewer dimensions available. \\n</p>\\n\\n<h3>The Power of Animation and Direct Manipulation</h3>\\n<p>\\n  When comparing linear projections with non-linear dimensionality reductions, we used small multiples to contrast training epochs and dimensionality reduction methods.\\n  The Grand Tour, on the other hand, uses a single animated view.\\n  When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature, aside. \\n  from specific settings such as dynamic graph drawing <d-cite key=\"archambault2010animation\"></d-cite>, or concerns about incomparable contents <d-cite key=\"tversky2002animation\"></d-cite> between small multiples and animated plots.\\n  Regardless of these concerns, in our scenarios, the use of animation comes naturally from the direct manipulation and the existence of a continuum of rotations for the Grand Tour to operate in.\\n</p>\\n\\n<h3>Non-sequential Models</h3>\\n<p>\\n  In our work we have used models that are purely “sequential”, in the sense that the layers can be put in numerical ordering, and that the activations for\\n  the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>-th layer are a function exclusively of the activations at the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span>-th layer. \\n  In recent DNN architectures, however, it is common to have non-sequential parts such as highway <d-cite key=\"srivastava2015highway\"></d-cite> branches or dedicated branches for different tasks <d-cite key=\"szegedy2015going\"></d-cite>. \\n  With our technique, one can visualize neuron activations on each such branch, but additional research is required to incorporate multiple branches directly.\\n</p>\\n\\n\\n<h3>Scaling to Larger Models</h3>\\n<p>\\n  Modern architectures are also wide. Especially when convolutional layers are concerned, one could run into issues with scalability if we see such layers as a large sparse matrix acting on flattened multi-channel images.\\n  For the sake of simplicity, in this article we brute-forced the computation of the alignment of such convolutional layers by writing out their explicit matrix representation. \\n  However, the singular value decomposition of multi-channel 2D convolutions can be computed efficiently <d-cite key=\"sedghi2018singular\"></d-cite>, which can be then be directly used for alignment, as we described above.\\n</p>\\n\\n<script>\\nfunction toggle(event, id){\\n  let caller = d3.select(event.target); //DOM that received the event\\n  let callerIsActive = caller.classed(\\'clickable-active\\');\\n\\n  let selection = d3.select(id); //DOM to be toggled\\n  let isHidden = selection.classed(\\'hidden\\');\\n\\n  selection.classed(\\'hidden\\', !isHidden);\\n  caller.classed(\\'clickable-active\\', !callerIsActive); //change the indicator (+/- sign) besides the caller\\n}\\n</script>\\n\\n\\n<h2 class=\"clickable\" onclick=\"toggle(event, \\'#div-technical-details\\')\"><a name=\"technical-details\"></a>\\nTechnical Details\\n</h2>\\n<div id=\"div-technical-details\" class=\"hidden\">\\n\\nThis section presents the technical details necessary to implement the direct manipulation of axis handles and data points, as well as how to implement the projection consistency technique for layer transitions.\\n\\n<h3>Notation</h3>\\n\\n<p>\\n  In this section, our notational convention is that data points are represented as row vectors.\\n  An entire dataset is laid out as a matrix, where each row is a data point, and each column represents a different feature/dimension.\\n  As a result, when a linear transformation is applied to the data, the row vectors (and the data matrix overall) are left-multiplied by the transformation matrix.\\n  This has a side benefit that when applying matrix multiplications in a chain, the formula reads from left to right and aligns with a commutative diagram.\\n  For example, when a data matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span></span></span></span></span> is multiplied by a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span> to generate <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span>, in formula we write <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi><mi>M</mi><mo>=</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">XM = Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span>, the letters have the same order in diagram:\\n</p>\\n\\n<span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi><msup><mo><mo>↦</mo></mo><mi>M</mi></msup><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">\\n    X \\n    \\\\overset{M}{\\\\mapsto}\\n    Y\\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.2893310000000002em;\"></span><span class=\"strut bottom\" style=\"height:1.3003310000000001em;vertical-align:-0.011em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2893310000000002em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span></span>\\n\\nFurthermore, if the SVD of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span> is <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>=</mo><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">M = U \\\\Sigma V^{T}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span></span>, we have <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup><mo>=</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">X U \\\\Sigma V^{T} = Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span>, and the diagram\\n<span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi><msup><mo><mo>↦</mo></mo><mi>U</mi></msup><msup><mo><mo>↦</mo></mo><mi mathvariant=\"normal\">Σ</mi></msup><msup><mo><mo>↦</mo></mo><msup><mi>V</mi><mi>T</mi></msup></msup><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">\\n    X \\n    \\\\overset{U}{\\\\mapsto} \\n    \\\\overset{\\\\Sigma}{\\\\mapsto} \\n    \\\\overset{V^T}{\\\\mapsto} Y\\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.4543650000000001em;\"></span><span class=\"strut bottom\" style=\"height:1.465365em;vertical-align:-0.011em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2893310000000002em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2893310000000002em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">Σ</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.4543650000000001em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9190928571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span></span>\\nnicely aligns with the formula.\\n\\n<h3 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-direct-manipulation\\')\">\\nDirect Manipulation\\n</h3>\\n<div id=\"div-direct-manipulation\" class=\"\">\\n\\n<p>\\n  The direct manipulations we presented earlier provide explicit control over the possible projections for the data points.\\n  We provide two modes: directly manipulating class axes (the “axis mode”), or directly manipulating a group of data points through their centroid (the “data point mode”).\\n  Based on the dimensionality and axis semantics, as discussed in <a href=\"#layer-dynamics\">Layer Dynamics</a>, we may prefer one mode than the other.\\n  \\n  We will see that the axis mode is a special case of data point mode, because we can view an axis handle as a particular “fictitious” point in the dataset.\\n  Because of its simplicity, we will first introduce the axis mode.\\n</p>\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-axis-mode\\')\">\\n  The Axis Mode\\n</h4>\\n<div id=\"div-axis-mode\" class=\"\">\\n\\n  <p>\\n    The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle), they are signaling to the system that they wished that the corresponding\\n    data point had been projected to the location where the UI element was dropped, rather than where it was dragged from.\\n    In our case the overall projection is a rotation (originally determined by the Grand Tour), and an arbitrary user manipulation might not necessarily generate a new projection that is also a rotation. Our goal, then, is to find a new rotation which satisfies the user request and is close to the previous state of the Grand Tour projection, so that the resulting state satisfies the user request.\\n\\n  In a nutshell, when user drags the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> axis handle by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(dx, dy)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span>, we add them to the first two entries of the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of the Grand Tour matrix, and then perform <a href=\"https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\">Gram-Schmidt orthonormalization</a> on the rows of the new matrix.\\n  <d-footnote>\\n    Rows have to be reordered such that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row is considered first in the Gram-Schmidt procedure.\\n  </d-footnote>\\n</p>\\n\\n<p>\\n  Before we see in detail why this works well, let us formalize the process of the Grand Tour on a standard basis vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span>. \\n  As shown in the diagram below, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> goes through an orthogonal Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> to produce a rotated version of itself, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>. \\n  Then, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>π</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\\\pi_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> is a function that keeps only the first two entries of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> and gives the 2D coordinate of the handle to be shown in the plot, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i, y_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\\n</p>\\n\\n<span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><msup><mo><mo>↦</mo></mo><mrow><mi>G</mi><mi>T</mi></mrow></msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><msup><mo><mo>↦</mo></mo><msub><mi>π</mi><mn>2</mn></msub></msup><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\n  e_i \\\\overset{GT}{\\\\mapsto} \\\\tilde{e_i} \\\\overset{\\\\pi_2}{\\\\mapsto} (x_i, y_i)\\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.2893310000000002em;\"></span><span class=\"strut bottom\" style=\"height:1.5393310000000002em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2893310000000002em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">G</span><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1234920000000002em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7220999999999997em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\\n<p>\\n  When user drags an axis handle on the screen canvas, they induce a delta change <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Δ</mi><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\Delta = (dx, dy)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Δ</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span> on the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">xy</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span>-plane. \\n  The coordinate of the handle becomes:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo separator=\"true\">,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo><mo>:</mo><mo>=</mo><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i^{(new)}, y_i^{(new)})&nbsp;:= (x_i+dx, y_i+dy)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.321664em;vertical-align:-0.276864em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span></span>\\n  Note that <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> are the first two coordinates of the axis handle in high dimensions after the Grand Tour rotation, so a delta change on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i, y_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> induces a delta change <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{\\\\Delta}&nbsp;:= (dx, dy, 0, 0, \\\\cdots)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"minner\">⋯</span><span class=\"mclose\">)</span></span></span></span></span> on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><msup><mo><mo>↦</mo></mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i} \\\\overset{\\\\tilde{\\\\Delta}}{\\\\mapsto} \\\\tilde{e_i} + \\\\tilde{\\\\Delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.455133em;\"></span><span class=\"strut bottom\" style=\"height:1.605133em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.455133em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">Δ</span></span></span><span style=\"top:-3.3023300000000004em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span><span class=\"mtight\">~</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span></span>\\n</p>\\n<p>\\n  To find a nearby Grand Tour rotation that respects this change, first note that <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> is exactly the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of orthogonal Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> \\n  <d-footnote>\\n    Recall that the convention is that vectors are in row form and linear transformations are matrices that are multiplied on the right.\\n    So <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> is a row vector whose <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th entry is <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">1</span></span></span></span></span> (and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">0</span></span></span></span></span>s elsewhere) and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><msub><mi>e</mi><mi>i</mi></msub><mo>⋅</mo><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}&nbsp;:= e_i \\\\cdot GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> is the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th row of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span>\\n  </d-footnote>. \\n  Naturally, we want the new matrix to be the original <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> with its <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row replaced by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}+\\\\tilde{\\\\Delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, i.e. we should add <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">dx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">dy</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span> to the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(i,1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">i</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">)</span></span></span></span></span>-th entry and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(i,2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">i</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">2</span><span class=\"mclose\">)</span></span></span></span></span>-th entry of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> respectively:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mo>←</mo><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT} \\\\leftarrow GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span>\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>←</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>d</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT}_{i,1} \\\\leftarrow GT_{i,1} + dx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.269438em;vertical-align:-0.286108em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span></span></span></span></span></span>\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>←</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>+</mo><mi>d</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT}_{i,2} \\\\leftarrow GT_{i,2} + dy</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.269438em;vertical-align:-0.286108em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span></span>\\n  However, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span> is not orthogonal for arbitrary <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(dx, dy)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span>.\\n  In order to find an approximation to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span> that is orthogonal, we apply <a href=\"https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\">Gram-Schmidt orthonormalization</a> on the rows of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\widetilde{GT}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span>, with the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row considered first in the Gram-Schmidt process:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msup><mi>T</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mtext>GramSchmidt</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">GT^{(new)}&nbsp;:= \\\\textsf{GramSchmidt}(\\\\widetilde{GT})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.23333em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">GramSchmidt</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\\n  Note that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row is normalized to a unit vector during the Gram-Schmidt, so the resulting position of the handle is \\n  <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}^{(new)} = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.19576em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>\\n  which may not be exactly the same as <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}+\\\\tilde{\\\\Delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, as the following figure shows\\n  <d-footnote>\\n    However, for any <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{\\\\Delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:0.9201899999999998em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, the norm of the difference is bounded above by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">||\\\\tilde{\\\\Delta}||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span></span></span>, as the following figure proves.\\n    <img src=\"figs/direct-manipulation-rotation-2d-proof.png\" style=\"width: 100%\" class=\"img-center\">\\n  </d-footnote>\\n &nbsp;.\\n</p>\\n<img src=\"figs/direct-manipulation-rotation-2d.png\" style=\"width: 40%\" class=\"img-center\">\\n\\n\\n</div> <!-- div-axis-mode -->\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-data-point-mode\\')\">\\n  The Data Point Mode\\n</h4>\\n<div id=\"div-data-point-mode\" class=\"\">\\n<p>\\n  We now explain how we directly manipulate data points. \\n  Technically speaking, this method only considers one point at a time.\\n  For a group of points, we compute their centroid and directly manipulate this single point with this method.\\n  Thinking more carefully about the process in axis mode gives us a way to drag any single point.\\n  Recall that in axis mode, we added user’s manipulation <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{\\\\Delta}&nbsp;:= (dx, dy, 0, 0, \\\\cdots)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"minner\">⋯</span><span class=\"mclose\">)</span></span></span></span></span> to the position of the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> axis handle <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>.\\n  This induces a delta change in the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of the Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span>.\\n  Next, as the first step in Gram-Schmidt, we normalized this row: \\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msubsup><mi>T</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>:</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mi>i</mi></msub><mo>)</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\n    GT_i^{(new)}&nbsp;:= \\\\textsf{normalize}(\\\\widetilde{GT}_i) = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.321664em;vertical-align:-0.276864em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg width=\"100%\" height=\"0.3em\" viewBox=\"0 0 1033 286\" preserveAspectRatio=\"none\">\\n<path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\\n-8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\\n 31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\\nc1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\\n 181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\\n  These two steps make the axis handle move from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}^{(new)}&nbsp;:= \\\\textsf{normalize}(\\\\tilde{e_i}+\\\\tilde{\\\\Delta})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.19576em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\\n</p>\\n<p>\\n  Looking at the geometry of this movement, the “add-delta-then-normalize” on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> is equivalent to a <em>rotation</em> from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> towards <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}^{(new)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.0957599999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span>, illustrated in the figure below. \\n  This geometric interpretation can be directly generalized to any arbitrary data point.\\n</p>\\n<img src=\"figs/direct-manipulation-rotation-3d.png\" style=\"width: 65%\" class=\"img-center\">\\n<p>\\n  The figure shows the case in 3D, but in higher dimensional space it is essentially the same, since the two vectors <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{e_i}+\\\\tilde{\\\\Delta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span> only span a 2-subspace.\\n  Now we have a nice geometric intuition about direct manipulation: dragging a point induces a <em>simple rotation</em>\\n  <d-footnote><a href=\"https://en.wikipedia.org/wiki/Rotations_in_4-dimensional_Euclidean_space#Simple_rotations\">Simple rotations</a> are rotations with only one <a href=\"https://en.wikipedia.org/wiki/Plane_of_rotation#Simple_rotations\">plane of rotation</a>.</d-footnote>\\n  in high dimensional space.\\n  This intuition is precisely how we implemented our direct manipulation on arbitrary data points, which we will specify as below.\\n</p>\\n<p>\\n  Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{c}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.6678599999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span> to \\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo><mo>⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">/</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">\\n    \\\\tilde{c}^{(new)}&nbsp;:= (\\\\tilde{c} + \\\\tilde{\\\\Delta}) \\\\cdot ||\\\\tilde{c}|| / ||\\\\tilde{c} + \\\\tilde{\\\\Delta}||\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.938em;\"></span><span class=\"strut bottom\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">/</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span></span></span></span>\\n</p>\\n<img src=\"figs/direct-manipulation-rotation-2d-perp.png\" style=\"width: 40%\" class=\"img-center\">\\n<p>\\n  First, the angle of rotation can be found by their cosine similarity:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mtext>arccos</mtext><mo>(</mo><mfrac><mrow><mo>⟨</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>⟩</mo></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac><mo>)</mo></mrow><annotation encoding=\"application/x-tex\"> \\\\theta = \\\\textrm{arccos}(\\n    \\\\frac{\\\\langle \\\\tilde{c}, \\\\tilde{c}^{(new)} \\\\rangle}{||\\\\tilde{c}|| \\\\cdot ||\\\\tilde{c}^{(new)}||}\\n  )</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.565em;\"></span><span class=\"strut bottom\" style=\"height:2.519em;vertical-align:-0.954em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathrm\">arccos</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mbin\">⋅</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mopen\">⟨</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">⟩</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\\n  Next, to find the matrix form of the rotation, we need a convenient basis.\\n  Let <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span> be a change of (orthonormal) basis matrix in which the first two rows form the 2-subspace <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\\n  For example, we can let its first row to be <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textsf{normalize}(\\\\tilde{c})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, second row to be its orthonormal complement <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>normalize</mtext><mo>(</mo><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.3461079999999999em;vertical-align:-0.30130799999999996em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.398692em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2197999999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, and the remaining rows complete the whole space:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>:</mo><mo>=</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>−</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>⋅</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>θ</mi><mfrac><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\n  \\\\tilde{c}^{(new)}_{\\\\perp} \\n &nbsp;:= \\\\tilde{c} - ||\\\\tilde{c}|| \\\\cdot cos \\\\theta \\\\frac{\\\\tilde{c}^{(new)}}{||\\\\tilde{c}^{(new)}||}\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.565em;\"></span><span class=\"strut bottom\" style=\"height:2.519em;vertical-align:-0.954em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.3986920000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3013079999999999em;\"></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">−</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">c</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">s</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>\\n\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi><mo>:</mo><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>⋯</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>)</mo><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>⋯</mo><mtext>normalize</mtext><mo>(</mo><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>P</mi></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\n    Q&nbsp;:=\\n    \\\\begin{bmatrix}\\n    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}) \\\\cdots \\\\\\\\\\n    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp}) \\\\cdots \\\\\\\\\\n    P\\n    \\\\end{bmatrix}\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:2.1524em;\"></span><span class=\"strut bottom\" style=\"height:3.8048em;vertical-align:-1.6523999999999999em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1524em;\"><span style=\"top:-4.3572em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"minner\">⋯</span></span></span><span style=\"top:-2.9524em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.398692em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2197999999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"minner\">⋯</span></span></span><span style=\"top:-1.7524000000000002em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6523999999999999em;\"></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"></span></span></span></span></span></span></span></span></span></span></span>\\n  where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span></span></span></span></span> completes the remaining space.\\n\\n  Making use of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span>, we can find the matrix that rotates the plane <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> by the angle <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span>:\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ρ</mi><mo>=</mo><msup><mi>Q</mi><mi>T</mi></msup><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>cos</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>sin</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mi>sin</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>cos</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi mathvariant=\"normal\">⋮</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi mathvariant=\"normal\">⋮</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>I</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mi>Q</mi><mo>=</mo><mo>:</mo><msup><mi>Q</mi><mi>T</mi></msup><msub><mi>R</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>(</mo><mi>θ</mi><mo>)</mo><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">\\n    \\\\rho = Q^T\\n    \\\\begin{bmatrix}\\n    \\\\cos \\\\theta&amp; \\\\sin \\\\theta&amp;  0&amp;  0&amp; \\\\cdots\\\\\\\\\\n    -\\\\sin \\\\theta&amp; \\\\cos \\\\theta&amp;  0&amp;  0&amp; \\\\cdots\\\\\\\\\\n    0&amp; 0&amp;  \\\\\\\\ \\n    \\\\vdots&amp; \\\\vdots&amp; &amp; I&amp; \\\\\\\\\\n    \\\\end{bmatrix}\\n    Q\\n    =: Q^T R_{1,2}(\\\\theta) Q\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:3.2800000000000007em;\"></span><span class=\"strut bottom\" style=\"height:6.0600000000000005em;vertical-align:-2.7799999999999994em;\"></span><span class=\"base\"><span class=\"mord mathit\">ρ</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.254em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-2.2049800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-2.8059800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-3.4069800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-4.00798em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-5.2540000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">cos</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mop\">sin</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">⋮</span></span></span><span style=\"top:-0.5800000000000007em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7799999999999994em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">sin</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">cos</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">⋮</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999996em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999996em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.780000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">I</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999992em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span></span></span><span style=\"top:-1.780000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999992em;\"></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.254em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-2.2049800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-2.8059800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-3.4069800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-4.00798em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-5.2540000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"></span></span></span></span></span></span><span class=\"mord mathit\">Q</span><span class=\"mrel\">=</span><span class=\"mrel\">:</span><span class=\"mord\"><span class=\"mord mathit\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mord mathit\">Q</span></span></span></span></span></span>\\n  The new Grand Tour matrix is the matrix product of the original <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\\\\rho</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">ρ</span></span></span></span></span>:\\n  <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msup><mi>T</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mi>G</mi><mi>T</mi><mo>⋅</mo><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\\n    GT^{(new)}&nbsp;:= GT \\\\cdot \\\\rho\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">ρ</span></span></span></span></span>\\n  Now we should be able to see the connection between axis mode and data point mode.\\n  In data point mode, finding <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span> can be done by Gram-Schmidt: Let the first basis be <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{c}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.6678599999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, find the orthogonal component of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\\\tilde{c}^{(new)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span> in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, repeatedly take a random vector, find its orthogonal component to the span of the current basis vectors and add it to the basis set. \\n  In axis mode, the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span>-row-first Gram-Schmidt does the rotation and change of basis in one step.\\n</p>\\n</div> <!-- div-data-point-mode -->\\n\\n</div> <!-- div-direct-manipulation -->\\n\\n\\n<h3 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-align-representation\\')\">\\n  <!-- Aligning representations: enabling the visualization of layer-to-layer dynamics -->\\n  Layer Transitions\\n</h3>\\n<div id=\"div-align-representation\" class=\"\">\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-relu\\')\">\\n  ReLU Layers\\n</h4>\\n<div id=\"div-relu\" class=\"\">\\n  When the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>l</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">l^{th}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> layer is a ReLU function, the output activation is <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mi>l</mi></msup><mo>=</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo>(</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">X^{l} = ReLU(X^{l-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\">L</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>. Since ReLU does not change the dimensionality and the function is taken coordinate wise, we can animate the transition by a simple linear interpolation: for a time parameter <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo>]</mo></mrow><annotation encoding=\"application/x-tex\">t \\\\in [0,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">t</span><span class=\"mrel\">∈</span><span class=\"mopen\">[</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">]</span></span></span></span></span>,\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mrow><mo>(</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo>)</mo><mo>→</mo><mi>l</mi></mrow></msup><mo>(</mo><mi>t</mi><mo>)</mo><mo>:</mo><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo>)</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mi>t</mi><msup><mi>X</mi><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\n    X^{(l-1) \\\\to l}(t)&nbsp;:= (1-t) X^{l-1} + t X^{l}\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.938em;\"></span><span class=\"strut bottom\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mrel mtight\">→</span><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">t</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span></span>\\n</div> <!-- #div-relu -->\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-linear\\')\">\\n  Linear Layers\\n</h4>\\n<div id=\"div-linear\" class=\"\">\\n  Transitions between linear layers can seem complicated, but as we will show, this comes from choosing mismatching bases on either side of the transition. \\n  If <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mi>l</mi></msup><mo>=</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">X^{l} = X^{l-1} M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span> where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">M \\\\in \\\\mathbb{R}^{m \\\\times n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.771331em;\"></span><span class=\"strut bottom\" style=\"height:0.810431em;vertical-align:-0.0391em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">m</span><span class=\"mbin mtight\">×</span><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span> is the matrix of a linear transformation, then it has a singular value decomposition (SVD):\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>=</mo><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">M = U \\\\Sigma V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8913309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8913309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span></span>\\n  where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>U</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">U \\\\in \\\\mathbb{R}^{m \\\\times m}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.771331em;\"></span><span class=\"strut bottom\" style=\"height:0.810431em;vertical-align:-0.0391em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">m</span><span class=\"mbin mtight\">×</span><span class=\"mord mathit mtight\">m</span></span></span></span></span></span></span></span></span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>V</mi><mi>T</mi></msup><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">V^T \\\\in \\\\mathbb{R}^{n \\\\times n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.880431em;vertical-align:-0.0391em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">n</span><span class=\"mbin mtight\">×</span><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span> are orthogonal, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Σ</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\\\Sigma \\\\in \\\\mathbb{R}^{m \\\\times n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.771331em;\"></span><span class=\"strut bottom\" style=\"height:0.810431em;vertical-align:-0.0391em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Σ</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">m</span><span class=\"mbin mtight\">×</span><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span> is diagonal.\\n  For arbitrary <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>, the transformation on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">X^{l-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8491079999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></span> is a composition of a rotation (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span>), scaling (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">\\\\Sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Σ</span></span></span></span></span>) and another rotation (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>), which can look complicated. \\n  However, consider the problem of relating the Grand Tour view of layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">X^{l}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span> to that of layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">X^{l+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8491079999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">+</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></span>. The Grand Tour has a single parameter that represents the current rotation of the dataset. Since our goal is to keep the transition consistent, we notice that <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">U</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span> have essentially no significance - they are just rotations to the view that can be exactly “canceled” by changing the rotation parameter of the Grand Tour in either layer.\\n  Hence, instead of showing <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span>, we seek for the transition to animate only the effect of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">\\\\Sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Σ</span></span></span></span></span>.\\n  <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">\\\\Sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Σ</span></span></span></span></span> is a coordinate-wise scaling, so we can animate it similar to the ReLU after the proper change of basis.\\n  Given <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mi>l</mi></msup><mo>=</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">X^{l} = X^{l-1} U \\\\Sigma V^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>, we have\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msup><mi>X</mi><mi>l</mi></msup><mi>V</mi><mo>)</mo><mo>=</mo><mo>(</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>U</mi><mo>)</mo><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">\\n    (X^{l}V) = (X^{l-1}U)\\\\Sigma\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.8991079999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.149108em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mclose\">)</span><span class=\"mord mathrm\">Σ</span></span></span></span></span></span>\\n  For a time parameter <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo>]</mo></mrow><annotation encoding=\"application/x-tex\">t \\\\in [0,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">t</span><span class=\"mrel\">∈</span><span class=\"mopen\">[</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">]</span></span></span></span></span>,\\n  <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>X</mi><mrow><mo>(</mo><mi>l</mi><mo>−</mo><mn>1</mn><mo>)</mo><mo>→</mo><mi>l</mi></mrow></msup><mo>(</mo><mi>t</mi><mo>)</mo><mo>:</mo><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo>)</mo><mo>(</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>U</mi><mo>)</mo><mo>+</mo><mi>t</mi><mo>(</mo><msup><mi>X</mi><mi>l</mi></msup><mi>V</mi><mo>)</mo><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo>)</mo><mo>(</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>U</mi><mo>)</mo><mo>+</mo><mi>t</mi><mo>(</mo><msup><mi>X</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\n    X^{(l-1) \\\\to l}(t)&nbsp;:= (1-t) (X^{l-1}U) + t (X^{l}V) = (1-t) (X^{l-1}U) + t (X^{l-1} U \\\\Sigma)\\n  </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.938em;\"></span><span class=\"strut bottom\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mrel mtight\">→</span><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mclose\">)</span><span class=\"mbin\">+</span><span class=\"mord mathit\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mclose\">)</span><span class=\"mbin\">+</span><span class=\"mord mathit\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mbin mtight\">−</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mclose\">)</span></span></span></span></span></span>\\n\\n</div> <!-- #div-linear -->\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-conv\\')\">\\n  Convolutional Layers\\n</h4>\\n<div id=\"div-conv\" class=\"\">\\n  Convolutional layers can be represented as special linear layers.\\n  With a change of representation, we can animate a convolutional layer like the previous section.\\n  For 2D convolutions this change of representation involves flattening the input and output, and repeating the kernel pattern in a sparse matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">M \\\\in \\\\mathbb{R}^{m \\\\times n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.771331em;\"></span><span class=\"strut bottom\" style=\"height:0.810431em;vertical-align:-0.0391em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">∈</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">m</span><span class=\"mbin mtight\">×</span><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span>, where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">m</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> are the dimensionalities of the input and output respectively.\\n  This change of representation is only practical for a small dimensionality (e.g. up to 1000), since we need to solve SVD for linear layers.\\n  However, the singular value decomposition of multi-channel 2D convolutions can be computed efficiently <d-cite key=\"sedghi2018singular\"></d-cite>, which can be then be directly used for alignment.\\n</div> <!-- #div-conv -->\\n\\n<h4 class=\"clickable clickable-active\" onclick=\"toggle(event, \\'#div-maxpool\\')\">\\n  Max-pooling Layers\\n</h4>\\n<div id=\"div-maxpool\" class=\"\">\\n  Animating max-pooling layers is nontrivial because max-pooling is neither linear <d-footnote>A max-pooling layer is piece-wise linear</d-footnote> or coordinate-wise.\\n  We replace it by average-pooling and scaling by the ratio of the average to the max.\\n  We compute the matrix form of average-pooling and use its SVD to align the view before and after this layer. \\n  Functionally, our operations have equivalent results to max-pooling, but this introduces\\n  unexpected artifacts. For example, the max-pooling version of the vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>[</mo><mn>0</mn><mi mathvariant=\"normal\">.</mi><mn>9</mn><mo separator=\"true\">,</mo><mn>0</mn><mi mathvariant=\"normal\">.</mi><mn>9</mn><mo separator=\"true\">,</mo><mn>0</mn><mi mathvariant=\"normal\">.</mi><mn>9</mn><mo separator=\"true\">,</mo><mn>1</mn><mi mathvariant=\"normal\">.</mi><mn>0</mn><mo>]</mo></mrow><annotation encoding=\"application/x-tex\">[0.9, 0.9, 0.9, 1.0]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">[</span><span class=\"mord mathrm\">0</span><span class=\"mord mathrm\">.</span><span class=\"mord mathrm\">9</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mord mathrm\">.</span><span class=\"mord mathrm\">9</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mord mathrm\">.</span><span class=\"mord mathrm\">9</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mord mathrm\">.</span><span class=\"mord mathrm\">0</span><span class=\"mclose\">]</span></span></span></span></span> should “give no credit” to the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>0</mn><mi mathvariant=\"normal\">.</mi><mn>9</mn></mrow><annotation encoding=\"application/x-tex\">0.9</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">0</span><span class=\"mord mathrm\">.</span><span class=\"mord mathrm\">9</span></span></span></span></span> entries; our implementation, however, will\\n  attribute about 25% of the result in the downstream layer to each those coordinates.\\n</div> <!-- #div-maxpool -->\\n</div> <!-- #div-align-representation -->\\n\\n</div><!-- #div-technical-details -->\\n\\n\\n\\n<h2>Conclusion</h2>\\n\\n<p>\\n  As powerful as t-SNE and UMAP are, they often fail to offer the correspondences we need, and such correspondences can come, surprisingly, from relatively simple methods like the Grand Tour. The Grand Tour method we presented is particularly useful when direct manipulation from the user is available or desirable.\\n  We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers, and using the Grand Tour and direct manipulation to compute the final projection.\\n</p>\\n</d-article>\\n\\n\\n\\n<d-appendix>\\n  <h3>Acknowledgments</h3>\\n  <p>\\n    The utility code for WebGL under js/lib/webgl_utils/ are adapted from Angel’s computer graphics book supplementary \\n    <a href=\"https://www.cs.unm.edu/~angel/BOOK/INTERACTIVE_COMPUTER_GRAPHICS/SEVENTH_EDITION/\">here</a>.\\n  </p>\\n\\n  <h3>Discussion and Review</h3>\\n  <p>\\n    <a href=\"https://github.com/distillpub/post--grand-tour/issues/6\">Review 1 - Anonymous </a><br>\\n    <a href=\"https://github.com/distillpub/post--grand-tour/issues/7\">Review 2 - Anonymous </a><br>\\n    <a href=\"https://github.com/distillpub/post--grand-tour/issues/8\">Review 3 - Anonymous </a><br>\\n  </p>\\n\\n\\n  <!-- <h3>Author Contributions</h3>\\n  <p>\\n    <b>Research:</b> Alex developed ...\\n  </p>\\n\\n  <p>\\n    <b>Writing & Diagrams:</b> The text was initially drafted by...\\n  </p> -->\\n\\n\\n  <d-footnote-list></d-footnote-list>\\n  <d-citation-list distill-prerendered=\"true\"><style>\\nd-citation-list {\\n  contain: style;\\n}\\n\\nd-citation-list .references {\\n  grid-column: text;\\n}\\n\\nd-citation-list .references .title {\\n  font-weight: 500;\\n}\\n</style><h3 id=\"references\">References</h3><ol id=\"references-list\" class=\"references\"><li id=\"asimov1985grand\"><span class=\"title\">The grand tour: a tool for viewing multidimensional data</span>  \\u2002<a href=\"https://epubs.siam.org/doi/pdf/10.1137/0906011\">[link]</a><br>Asimov, D., 1985. SIAM journal on scientific and statistical computing, Vol 6(1), pp. 128--143. SIAM.</li><li id=\"maaten2008visualizing\"><span class=\"title\">Visualizing data using t-SNE</span>  \\u2002<a href=\"http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\">[PDF]</a><br>Maaten, L.v.d. and Hinton, G., 2008. Journal of machine learning research, Vol 9(Nov), pp. 2579--2605. </li><li id=\"mcinnes2018umap\"><span class=\"title\">Umap: Uniform manifold approximation and projection for dimension reduction</span>  \\u2002<a href=\"https://arxiv.org/pdf/1802.03426.pdf\">[PDF]</a><br>McInnes, L. and Healy, J., 2018. arXiv preprint arXiv:1802.03426. </li><li id=\"szegedy2013intriguing\"><span class=\"title\">Intriguing properties of neural networks</span> <br>Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. and Fergus, R., 2013. arXiv preprint arXiv:1312.6199. </li><li id=\"ILSVRC15\"><span class=\"title\">ImageNet Large Scale Visual Recognition Challenge</span> <br>Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C. and Fei-Fei, L., 2015. International Journal of Computer Vision (IJCV), Vol 115(3), pp. 211-252.  <a href=\"https://doi.org/10.1007/s11263-015-0816-y\" style=\"text-decoration:inherit;\">DOI: 10.1007/s11263-015-0816-y</a></li><li id=\"lipton2016mythos\"><span class=\"title\">The mythos of model interpretability</span> <br>Lipton, Z.C., 2016. arXiv preprint arXiv:1606.03490. </li><li id=\"wongsuphasawat2018visualizing\"><span class=\"title\">Visualizing dataflow graphs of deep learning models in tensorflow</span> <br>Wongsuphasawat, K., Smilkov, D., Wexler, J., Wilson, J., Mane, D., Fritz, D., Krishnan, D., Viegas, F.B. and Wattenberg, M., 2018. IEEE transactions on visualization and computer graphics, Vol 24(1), pp. 1--12. IEEE.</li><li id=\"kindlmann2014algebraic\"><span class=\"title\">An algebraic process for visualization design</span> <br>Kindlmann, G. and Scheidegger, C., 2014. IEEE transactions on visualization and computer graphics, Vol 20(12), pp. 2181--2190. IEEE.</li><li id=\"olah2017feature\"><span class=\"title\">Feature visualization</span>  \\u2002<a href=\"https://distill.pub/2017/feature-visualization/\">[link]</a><br>Olah, C., Mordvintsev, A. and Schubert, L., 2017. Distill, Vol 2(11), pp. e7. </li><li id=\"lecun2010mnist\"><span class=\"title\">MNIST handwritten digit database</span>  \\u2002<a href=\"http://yann.lecun.com/exdb/mnist/\">[link]</a><br>LeCun, Y. and Cortes, C., 2010. </li><li id=\"xiao2017fashion\"><span class=\"title\">Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms</span>  \\u2002<a href=\"https://github.com/zalandoresearch/fashion-mnist\">[link]</a><br>Xiao, H., Rasul, K. and Vollgraf, R., 2017. </li><li id=\"krizhevsky2009cifar10\"><span class=\"title\">Learning multiple layers of features from tiny images</span>  \\u2002<a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">[HTML]</a><br>Krizhevsky, A., Hinton, G. and others,, 2009. </li><li id=\"nair2010relu\"><span class=\"title\">Rectified linear units improve restricted boltzmann machines</span>  \\u2002<a href=\"https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf\">[PDF]</a><br>Nair, V. and Hinton, G.E., 2010. Proceedings of the 27th international conference on machine learning (ICML-10), pp. 807--814. </li><li id=\"rauber2016visualizing\"><span class=\"title\">Visualizing time-dependent data using dynamic t-SNE</span>  \\u2002<a href=\"http://www.cs.rug.nl/~alext/PAPERS/EuroVis16/paper.pdf\">[PDF]</a><br>Rauber, P.E., Falcao, A.X. and Telea, A.C., 2016. Proc. EuroVis Short Papers, Vol 2(5). </li><li id=\"wattenberg2016use\"><span class=\"title\">How to use t-sne effectively</span>  \\u2002<a href=\"https://distill.pub/2016/misread-tsne/\">[link]</a><br>Wattenberg, M., Viegas, F. and Johnson, I., 2016. Distill, Vol 1(10), pp. e2. </li><li id=\"austin2009svd\"><span class=\"title\">We Recommend a Singular Value Decomposition</span>  \\u2002<a href=\"http://www.ams.org/publicoutreach/feature-column/fcarc-svd\">[link]</a><br>Austin, D., 2009. </li><li id=\"sedghi2018singular\"><span class=\"title\">The singular values of convolutional layers</span>  \\u2002<a href=\"https://arxiv.org/pdf/1805.10408.pdf\">[PDF]</a><br>Sedghi, H., Gupta, V. and Long, P.M., 2018. arXiv preprint arXiv:1805.10408. </li><li id=\"goodfellow2014explaining\"><span class=\"title\">Explaining and harnessing adversarial examples</span> <br>Goodfellow, I.J., Shlens, J. and Szegedy, C., 2014. arXiv preprint arXiv:1412.6572. </li><li id=\"archambault2010animation\"><span class=\"title\">Animation, small multiples, and the effect of mental map preservation in dynamic graphs</span> <br>Archambault, D., Purchase, H. and Pinaud, B., 2010. IEEE Transactions on Visualization and Computer Graphics, Vol 17(4), pp. 539--552. IEEE.</li><li id=\"tversky2002animation\"><span class=\"title\">Animation: can it facilitate?</span> <br>Tversky, B., Morrison, J.B. and Betrancourt, M., 2002. International journal of human-computer studies, Vol 57(4), pp. 247--262. Elsevier.</li><li id=\"srivastava2015highway\"><span class=\"title\">Highway networks</span>  \\u2002<a href=\"https://arxiv.org/pdf/1505.00387.pdf\">[PDF]</a><br>Srivastava, R.K., Greff, K. and Schmidhuber, J., 2015. arXiv preprint arXiv:1505.00387. </li><li id=\"szegedy2015going\"><span class=\"title\">Going deeper with convolutions</span>  \\u2002<a href=\"https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf\">[PDF]</a><br>Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. and Rabinovich, A., 2015. Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1--9. </li></ol></d-citation-list>\\n<distill-appendix>\\n<style>\\n  distill-appendix {\\n    contain: layout style;\\n  }\\n\\n  distill-appendix .citation {\\n    font-size: 11px;\\n    line-height: 15px;\\n    border-left: 1px solid rgba(0, 0, 0, 0.1);\\n    padding-left: 18px;\\n    border: 1px solid rgba(0,0,0,0.1);\\n    background: rgba(0, 0, 0, 0.02);\\n    padding: 10px 18px;\\n    border-radius: 3px;\\n    color: rgba(150, 150, 150, 1);\\n    overflow: hidden;\\n    margin-top: -12px;\\n    white-space: pre-wrap;\\n    word-wrap: break-word;\\n  }\\n\\n  distill-appendix > * {\\n    grid-column: text;\\n  }\\n</style>\\n\\n    <h3 id=\"updates-and-corrections\">Updates and Corrections</h3>\\n    <p>\\n    If you see mistakes or want to suggest changes, please <a href=\"https://github.com/distillpub/post--grand-tour/issues/new\">create an issue on GitHub</a>. </p>\\n    \\n    <h3 id=\"reuse\">Reuse</h3>\\n    <p>Diagrams and text are licensed under Creative Commons Attribution <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY 4.0</a> with the <a class=\"github\" href=\"https://github.com/distillpub/post--grand-tour\">source available on GitHub</a>, unless noted otherwise. The figures that have been reused from other sources don’t fall under this license and can be recognized by a note in their caption: “Figure from …”.</p>\\n    \\n    <h3 id=\"citation\">Citation</h3>\\n    <p>For attribution in academic contexts, please cite this work as</p>\\n    <pre class=\"citation short\">Li, et al., \"Visualizing Neural Networks with the Grand Tour\", Distill, 2020.</pre>\\n    <p>BibTeX citation</p>\\n    <pre class=\"citation long\">@article{li2020visualizing,\\n  author = {Li, Mingwei and Zhao, Zhenge and Scheidegger, Carlos},\\n  title = {Visualizing Neural Networks with the Grand Tour},\\n  journal = {Distill},\\n  year = {2020},\\n  note = {https://distill.pub/2020/grand-tour},\\n  doi = {10.23915/distill.00025}\\n}</pre>\\n    </distill-appendix></d-appendix>\\n\\n<!-- bibliography will be inlined during Distill pipeline\\'s pre-rendering -->\\n<d-bibliography><script type=\"text/json\">[[\"nair2010relu\",{\"title\":\"Rectified linear units improve restricted boltzmann machines\",\"author\":\"Nair, Vinod and Hinton, Geoffrey E\",\"booktitle\":\"Proceedings of the 27th international conference on machine learning (ICML-10)\",\"pages\":\"807--814\",\"year\":\"2010\",\"url\":\"https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf\",\"type\":\"inproceedings\"}],[\"kim2017tcav\",{\"title\":\"Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)\",\"author\":\"Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory\",\"journal\":\"arXiv preprint arXiv:1711.11279\",\"year\":\"2017\",\"type\":\"article\"}],[\"lecun2010mnist\",{\"author\":\"LeCun, Yann and Cortes, Corinna\",\"title\":\"MNIST handwritten digit database\",\"url\":\"http://yann.lecun.com/exdb/mnist/\",\"year\":\"2010\",\"type\":\"article\"}],[\"austin2009svd\",{\"author\":\"David Austin\",\"title\":\"We Recommend a Singular Value Decomposition\",\"date\":\"2009-08\",\"year\":\"2009\",\"url\":\"http://www.ams.org/publicoutreach/feature-column/fcarc-svd\",\"type\":\"online\"}],[\"xiao2017fashion\",{\"author\":\"Han Xiao and Kashif Rasul and Roland Vollgraf\",\"title\":\"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\"date\":\"2017-08-28\",\"year\":\"2017\",\"eprintclass\":\"cs.LG\",\"eprinttype\":\"arXiv\",\"eprint\":\"cs.LG/1708.07747\",\"url\":\"https://github.com/zalandoresearch/fashion-mnist\",\"type\":\"online\"}],[\"krizhevsky2009cifar10\",{\"title\":\"Learning multiple layers of features from tiny images\",\"author\":\"Krizhevsky, Alex and Hinton, Geoffrey and others\",\"year\":\"2009\",\"institution\":\"Citeseer\",\"url\":\"https://www.cs.toronto.edu/~kriz/cifar.html\",\"type\":\"techreport\"}],[\"archambault2010animation\",{\"title\":\"Animation, small multiples, and the effect of mental map preservation in dynamic graphs\",\"author\":\"Archambault, Daniel and Purchase, Helen and Pinaud, Bruno\",\"journal\":\"IEEE Transactions on Visualization and Computer Graphics\",\"volume\":\"17\",\"number\":\"4\",\"pages\":\"539--552\",\"year\":\"2010\",\"publisher\":\"IEEE\",\"type\":\"article\"}],[\"tversky2002animation\",{\"title\":\"Animation: can it facilitate?\",\"author\":\"Tversky, Barbara and Morrison, Julie Bauer and Betrancourt, Mireille\",\"journal\":\"International journal of human-computer studies\",\"volume\":\"57\",\"number\":\"4\",\"pages\":\"247--262\",\"year\":\"2002\",\"publisher\":\"Elsevier\",\"type\":\"article\"}],[\"ILSVRC15\",{\"Author\":\"Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei\",\"Title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"Year\":\"2015\",\"journal\":\"International Journal of Computer Vision (IJCV)\",\"doi\":\"10.1007/s11263-015-0816-y\",\"volume\":\"115\",\"number\":\"3\",\"pages\":\"211-252\",\"author\":\"Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"year\":\"2015\",\"type\":\"article\"}],[\"olah2017feature\",{\"title\":\"Feature visualization\",\"author\":\"Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig\",\"journal\":\"Distill\",\"volume\":\"2\",\"number\":\"11\",\"pages\":\"e7\",\"year\":\"2017\",\"url\":\"https://distill.pub/2017/feature-visualization/\",\"type\":\"article\"}],[\"kindlmann2014algebraic\",{\"title\":\"An algebraic process for visualization design\",\"author\":\"Kindlmann, Gordon and Scheidegger, Carlos\",\"journal\":\"IEEE transactions on visualization and computer graphics\",\"volume\":\"20\",\"number\":\"12\",\"pages\":\"2181--2190\",\"year\":\"2014\",\"publisher\":\"IEEE\",\"type\":\"article\"}],[\"lee2019wide\",{\"title\":\"Wide neural networks of any depth evolve as linear models\",\"author\":\"Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey\",\"journal\":\"arXiv preprint arXiv:1902.06720\",\"year\":\"2019\",\"type\":\"article\"}],[\"lipton2016mythos\",{\"title\":\"The mythos of model interpretability\",\"author\":\"Lipton, Zachary C\",\"journal\":\"arXiv preprint arXiv:1606.03490\",\"year\":\"2016\",\"type\":\"article\"}],[\"goh2017why\",{\"author\":\"Goh, Gabriel\",\"title\":\"Why Momentum Really Works\",\"journal\":\"Distill\",\"year\":\"2017\",\"url\":\"http://distill.pub/2017/momentum\",\"doi\":\"10.23915/distill.00006\",\"type\":\"article\"}],[\"asimov1985grand\",{\"title\":\"The grand tour: a tool for viewing multidimensional data\",\"author\":\"Asimov, Daniel\",\"journal\":\"SIAM journal on scientific and statistical computing\",\"volume\":\"6\",\"number\":\"1\",\"pages\":\"128--143\",\"year\":\"1985\",\"publisher\":\"SIAM\",\"url\":\"https://epubs.siam.org/doi/pdf/10.1137/0906011\",\"type\":\"article\"}],[\"ren2017squares\",{\"title\":\"Squares: Supporting interactive performance analysis for multiclass classifiers\",\"author\":\"Ren, Donghao and Amershi, Saleema and Lee, Bongshin and Suh, Jina and Williams, Jason D\",\"journal\":\"IEEE transactions on visualization and computer graphics\",\"volume\":\"23\",\"number\":\"1\",\"pages\":\"61--70\",\"year\":\"2017\",\"publisher\":\"IEEE\",\"url\":\"https://ieeexplore.ieee.org/abstract/document/7539404/\",\"type\":\"article\"}],[\"raghu2017svcca\",{\"title\":\"Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability\",\"author\":\"Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha\",\"booktitle\":\"Advances in Neural Information Processing Systems\",\"pages\":\"6076--6085\",\"year\":\"2017\",\"url\":\"http://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability.pdf\",\"type\":\"inproceedings\"}],[\"morcos2018insights\",{\"title\":\"Insights on representational similarity in neural networks with canonical correlation\",\"author\":\"Morcos, Ari S and Raghu, Maithra and Bengio, Samy\",\"journal\":\"arXiv preprint arXiv:1806.05759\",\"year\":\"2018\",\"url\":\"https://arxiv.org/pdf/1806.05759.pdf\",\"type\":\"article\"}],[\"rauber2016visualizing\",{\"title\":\"Visualizing time-dependent data using dynamic t-SNE\",\"author\":\"Rauber, Paulo E and Falcao, Alexandre X and Telea, Alexandru C\",\"journal\":\"Proc. EuroVis Short Papers\",\"volume\":\"2\",\"number\":\"5\",\"year\":\"2016\",\"url\":\"http://www.cs.rug.nl/~alext/PAPERS/EuroVis16/paper.pdf\",\"type\":\"article\"}],[\"mcinnes2018umap\",{\"title\":\"Umap: Uniform manifold approximation and projection for dimension reduction\",\"author\":\"McInnes, Leland and Healy, John\",\"journal\":\"arXiv preprint arXiv:1802.03426\",\"year\":\"2018\",\"url\":\"https://arxiv.org/pdf/1802.03426.pdf\",\"type\":\"article\"}],[\"maaten2008visualizing\",{\"title\":\"Visualizing data using t-SNE\",\"author\":\"Maaten, Laurens van der and Hinton, Geoffrey\",\"journal\":\"Journal of machine learning research\",\"volume\":\"9\",\"number\":\"Nov\",\"pages\":\"2579--2605\",\"year\":\"2008\",\"url\":\"http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\",\"type\":\"article\"}],[\"playground\",{\"title\":\"Tensorflow Playground\",\"author\":\"Smilkov, Daniel and Carter, Shan\",\"url\":\"https://playground.tensorflow.org/\",\"type\":\"article\"}],[\"smilkov2017direct\",{\"title\":\"Direct-manipulation visualization of deep networks\",\"author\":\"Smilkov, Daniel and Carter, Shan and Sculley, D and Viegas, Fernanda B and Wattenberg, Martin\",\"journal\":\"arXiv preprint arXiv:1708.03788\",\"year\":\"2017\",\"url\":\"https://arxiv.org/pdf/1708.03788.pdf\",\"type\":\"article\"}],[\"ConvnetJS\",{\"title\":\"ConvnetJS demo: toy 2d classification with 2-layer neural network\",\"author\":\"Karpathy, Andrej\",\"url\":\"https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html\",\"type\":\"article\"}],[\"neuralnetcomputeany\",{\"title\":\"A visual proof that neural nets can compute any function\",\"author\":\"Nielsen, Michael\",\"url\":\"http://neuralnetworksanddeeplearning.com/chap4.html\",\"type\":\"article\"}],[\"harley2015isvc\",{\"title\":\"An Interactive Node-Link Visualization of Convolutional Neural Networks\",\"author\":\"Adam W Harley\",\"booktitle\":\"ISVC\",\"pages\":\"867--877\",\"year\":\"2015\",\"url\":\"http://scs.ryerson.ca/~aharley/vis/\",\"type\":\"inproceedings\"}],[\"wattenberg2016use\",{\"title\":\"How to use t-sne effectively\",\"author\":\"Wattenberg, Martin and Viegas, Fernanda and Johnson, Ian\",\"journal\":\"Distill\",\"volume\":\"1\",\"number\":\"10\",\"pages\":\"e2\",\"year\":\"2016\",\"url\":\"https://distill.pub/2016/misread-tsne/\",\"type\":\"article\"}],[\"gower2004procrustes\",{\"title\":\"Procrustes problems\",\"author\":\"Gower, John C and Dijksterhuis, Garmt B and others\",\"volume\":\"30\",\"year\":\"2004\",\"publisher\":\"Oxford University Press on Demand\",\"url\":\"http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780198510581.001.0001/acprof-9780198510581\",\"type\":\"book\"}],[\"shingel2008interpolation\",{\"title\":\"Interpolation in special orthogonal groups\",\"author\":\"Shingel, Tatiana\",\"journal\":\"IMA journal of numerical analysis\",\"volume\":\"29\",\"number\":\"3\",\"pages\":\"731--745\",\"year\":\"2008\",\"publisher\":\"Oxford University Press\",\"url\":\"https://academic.oup.com/imajna/article-abstract/29/3/731/883198\",\"type\":\"article\"}],[\"goodfellow2016deep\",{\"title\":\"Deep learning\",\"author\":\"Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron\",\"year\":\"2016\",\"publisher\":\"MIT press\",\"url\":\"https://www.deeplearningbook.org/\",\"type\":\"book\"}],[\"sedghi2018singular\",{\"title\":\"The singular values of convolutional layers\",\"author\":\"Sedghi, Hanie and Gupta, Vineet and Long, Philip M\",\"journal\":\"arXiv preprint arXiv:1805.10408\",\"year\":\"2018\",\"url\":\"https://arxiv.org/pdf/1805.10408.pdf\",\"type\":\"article\"}],[\"srivastava2015highway\",{\"title\":\"Highway networks\",\"author\":\"Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, Jurgen\",\"journal\":\"arXiv preprint arXiv:1505.00387\",\"year\":\"2015\",\"url\":\"https://arxiv.org/pdf/1505.00387.pdf\",\"type\":\"article\"}],[\"szegedy2015going\",{\"title\":\"Going deeper with convolutions\",\"author\":\"Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew\",\"booktitle\":\"Proceedings of the IEEE conference on computer vision and pattern recognition\",\"pages\":\"1--9\",\"year\":\"2015\",\"url\":\"https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf\",\"type\":\"inproceedings\"}],[\"szegedy2013intriguing\",{\"title\":\"Intriguing properties of neural networks\",\"author\":\"Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob\",\"journal\":\"arXiv preprint arXiv:1312.6199\",\"year\":\"2013\",\"type\":\"article\"}],[\"goodfellow2014explaining\",{\"title\":\"Explaining and harnessing adversarial examples\",\"author\":\"Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian\",\"journal\":\"arXiv preprint arXiv:1412.6572\",\"year\":\"2014\",\"type\":\"article\"}],[\"wongsuphasawat2018visualizing\",{\"title\":\"Visualizing dataflow graphs of deep learning models in tensorflow\",\"author\":\"Wongsuphasawat, Kanit and Smilkov, Daniel and Wexler, James and Wilson, Jimbo and Mane, Dandelion and Fritz, Doug and Krishnan, Dilip and Viegas, Fernanda B and Wattenberg, Martin\",\"journal\":\"IEEE transactions on visualization and computer graphics\",\"volume\":\"24\",\"number\":\"1\",\"pages\":\"1--12\",\"year\":\"2018\",\"publisher\":\"IEEE\",\"type\":\"article\"}]]</script></d-bibliography>\\n\\n<script type=\"text/javascript\" src=\"index.bundle.js\"></script>\\n<distill-footer>\\n<style>\\n\\n:host {\\n  color: rgba(255, 255, 255, 0.5);\\n  font-weight: 300;\\n  padding: 2rem 0;\\n  border-top: 1px solid rgba(0, 0, 0, 0.1);\\n  background-color: hsl(180, 5%, 15%); /*hsl(200, 60%, 15%);*/\\n  text-align: left;\\n  contain: content;\\n}\\n\\n.footer-container .logo svg {\\n  width: 24px;\\n  position: relative;\\n  top: 4px;\\n  margin-right: 2px;\\n}\\n\\n.footer-container .logo svg path {\\n  fill: none;\\n  stroke: rgba(255, 255, 255, 0.8);\\n  stroke-width: 3px;\\n}\\n\\n.footer-container .logo {\\n  font-size: 17px;\\n  font-weight: 200;\\n  color: rgba(255, 255, 255, 0.8);\\n  text-decoration: none;\\n  margin-right: 6px;\\n}\\n\\n.footer-container {\\n  grid-column: text;\\n}\\n\\n.footer-container .nav {\\n  font-size: 0.9em;\\n  margin-top: 1.5em;\\n}\\n\\n.footer-container .nav a {\\n  color: rgba(255, 255, 255, 0.8);\\n  margin-right: 6px;\\n  text-decoration: none;\\n}\\n\\n</style>\\n\\n<div class=\"footer-container\">\\n\\n  <a href=\"/\" class=\"logo\">\\n    <svg viewBox=\"-607 419 64 64\">\\n  <path d=\"M-573.4,478.9c-8,0-14.6-6.4-14.6-14.5s14.6-25.9,14.6-40.8c0,14.9,14.6,32.8,14.6,40.8S-565.4,478.9-573.4,478.9z\"></path>\\n</svg>\\n\\n    Distill\\n  </a> is dedicated to clear explanations of machine learning\\n\\n  <div class=\"nav\">\\n    <a href=\"https://distill.pub/about/\">About</a>\\n    <a href=\"https://distill.pub/journal/\">Submit</a>\\n    <a href=\"https://distill.pub/prize/\">Prize</a>\\n    <a href=\"https://distill.pub/archive/\">Archive</a>\\n    <a href=\"https://distill.pub/rss.xml\">RSS</a>\\n    <a href=\"https://github.com/distillpub\">GitHub</a>\\n    <a href=\"https://twitter.com/distillpub\">Twitter</a>\\n    &nbsp;&nbsp;&nbsp;&nbsp; ISSN 2476-0757\\n  </div>\\n\\n</div>\\n\\n</distill-footer><script>\\n  (function(i,s,o,g,r,a,m){i[\\'GoogleAnalyticsObject\\']=r;i[r]=i[r]||function(){\\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\\n  })(window,document,\\'script\\',\\'https://www.google-analytics.com/analytics.js\\',\\'ga\\');\\n  ga(\\'create\\', \\'UA-83741880-1\\', \\'auto\\');\\n  ga(\\'send\\', \\'pageview\\');\\n</script></body></html>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now to extract the test from the entire html code\n",
        "\n",
        "soup= BeautifulSoup(r.text, 'html.parser')\n",
        "results= soup.find_all(['p','h2'])"
      ],
      "metadata": {
        "id": "Kv0IGDZAwLrE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6gnqaDUfxIr9",
        "outputId": "f94c73d5-363e-4212-8950-aa30d17b0d26"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p></p>,\n",
              " <p class=\"author\">\n",
              " <a class=\"name\" href=\"http://hdc.cs.arizona.edu/~mwli/\">Mingwei Li</a>\n",
              " </p>,\n",
              " <p class=\"affiliation\">\n",
              " <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\n",
              " </p>,\n",
              " <p class=\"author\">\n",
              " <a class=\"name\" href=\"https://zhengezhao.wordpress.com/\">Zhenge Zhao</a>\n",
              " </p>,\n",
              " <p class=\"affiliation\">\n",
              " <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\n",
              " </p>,\n",
              " <p class=\"author\">\n",
              " <a class=\"name\" href=\"https://cscheid.net/\">Carlos Scheidegger</a>\n",
              " </p>,\n",
              " <p class=\"affiliation\">\n",
              " <a class=\"affiliation\" href=\"https://www.cs.arizona.edu/\">University of Arizona</a>\n",
              " </p>,\n",
              " <p>March 16, 2020</p>,\n",
              " <p><a href=\"https://doi.org/10.23915/distill.00025\">10.23915/distill.00025</a></p>,\n",
              " <p>\n",
              "   The Grand Tour<d-cite key=\"asimov1985grand\"></d-cite> is a classic visualization technique for high-dimensional point clouds that <em>projects</em> a high-dimensional dataset into two dimensions.\n",
              " \n",
              "   Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer.\n",
              " \n",
              "   Unlike modern nonlinear projection methods such as t-SNE<d-cite key=\"maaten2008visualizing\"></d-cite> and UMAP<d-cite key=\"mcinnes2018umap\"></d-cite>, the Grand Tour is fundamentally a <em>linear</em> method.\n",
              " \n",
              "   In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.\n",
              "   \n",
              "   Concretely, we present three use cases of interest: visualizing the training process as the network weights change, visualizing the layer-to-layer behavior as the data goes through the network and visualizing both how adversarial examples<d-cite key=\"szegedy2013intriguing\"></d-cite> are crafted and how they fool a neural network.\n",
              " </p>,\n",
              " <h2>Introduction</h2>,\n",
              " <p>\n",
              "   Deep neural networks often achieve best-in-class performance in supervised learning contests such as the ImageNet Large Scale Visual Recognition Challenge (ILSVRC)<d-cite key=\"ILSVRC15\"></d-cite>.\n",
              "   \n",
              "   Unfortunately, their decision process is notoriously hard to interpret<d-cite key=\"lipton2016mythos\"></d-cite>, and their training process is often hard to debug<d-cite key=\"wongsuphasawat2018visualizing\"></d-cite>.\n",
              "   \n",
              "   In this article, we present a method to visualize the responses of a neural network which leverages properties of deep neural networks and properties of the <em>Grand Tour</em>.\n",
              " \n",
              "   Notably, our method enables us to more directly reason about the relationship between <em>changes in the data</em> and <em>changes in the resulting visualization</em><d-cite key=\"kindlmann2014algebraic\"></d-cite>.\n",
              " \n",
              "   As we will show, this data-visual correspondence is central to the method we present, especially when compared to other non-linear projection methods like UMAP and t-SNE.\n",
              " </p>,\n",
              " <p></p>,\n",
              " <p>\n",
              "   To understand a neural network, we often try to observe its action on input examples (both real and synthesized)<d-cite key=\"olah2017feature\"></d-cite>.\n",
              "   \n",
              "   These kinds of visualizations are useful to elucidate the activation patterns of a neural network for a single example, but they might offer less insight about the relationship between different examples, different states of the network as it’s being trained, or how the data in the example flows through the different layers of a single network.\n",
              "   \n",
              "   Therefore, we instead aim to enable visualizations of the <em>context around</em> our objects of interest: what is the difference between the present training epoch and the next one? How does the classification of a network converge (or diverge) as the image is fed through the network?\n",
              " \n",
              "   Linear methods are attractive because they are particularly easy to reason about.\n",
              " \n",
              "   The Grand Tour works by generating a random, smoothly changing rotation of the dataset, and then projecting the data to the two-dimensional screen: both are linear processes.\n",
              " \n",
              "   Although deep neural networks are clearly not linear processes, they often confine their nonlinearity to a small set of operations, enabling us to still reason about their behavior.\n",
              " \n",
              "   Our proposed method better preserves context by providing more\n",
              "   consistency: it should be possible to know <em>how the visualization\n",
              "   would change, if the data had been different in a particular\n",
              "   way</em>.\n",
              " </p>,\n",
              " <h2>Working Examples</h2>,\n",
              " <p>\n",
              "   To illustrate the technique we will present, we trained deep neural\n",
              "   network models (DNNs) with 3 common image classification datasets:\n",
              "   MNIST\n",
              "   <d-footnote>\n",
              "     MNIST<d-cite key=\"lecun2010mnist\"></d-cite> contains grayscale images of 10 handwritten digits\n",
              "     <img class=\"img-center\" src=\"figs/mnist.png\" style=\"width: 70%;\"/>\n",
              "     Image credit to <a href=\"https://en.wikipedia.org/wiki/File:MnistExamples.png\">https://en.wikipedia.org/wiki/File:MnistExamples.png</a>\n",
              " </d-footnote>,\n",
              "   fashion-MNIST\n",
              "   <d-footnote>\n",
              "     Fashion-MNIST<d-cite key=\"xiao2017fashion\"></d-cite> contains grayscale images of 10 types of fashion items:\n",
              "     <img class=\"img-center\" src=\"figs/fashion-mnist.png\" style=\"width: 70%;\"/>\n",
              " <!-- Image credit to <a href=\"https://github.com/zalandoresearch/fashion-mnist\">https://github.com/zalandoresearch/fashion-mnist</a>  -->\n",
              "     Image credit to <a href=\"https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925\">https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925</a>\n",
              " </d-footnote>\n",
              " \n",
              "   and CIFAR-10\n",
              "   <d-footnote>\n",
              "     CIFAR-10<d-cite key=\"krizhevsky2009cifar10\"></d-cite> contains RGB images of 10 classes of objects\n",
              "     <img class=\"img-center\" src=\"figs/cifar-10.png\" style=\"width: 70%;\"/>\n",
              "     Image credit to <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html</a>\n",
              " </d-footnote>. \n",
              "   While our architecture is simpler and smaller than current DNNs, it’s still indicative of modern networks, and is complex enough to demonstrate both our proposed techniques and shortcomings of typical approaches.\n",
              " </p>,\n",
              " <p>\n",
              "   The following figure presents a simple functional diagram of the neural network we will use throughout the article. The neural network is a sequence of linear (both convolutional<d-footnote>\n",
              "     A convolution calculates weighted sums of regions in the input. \n",
              "     In neural networks, the learnable weights in convolutional layers are referred to as the kernel.\n",
              "     For example\n",
              "     <img class=\"img-center\" src=\"figs/conv.gif\" style=\"width:70%\"/>\n",
              "     Image credit to <a href=\"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9\">https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9</a>.<br/>\n",
              "     See also <a href=\"https://github.com/vdumoulin/conv_arithmetic\">Convolution arithmetic</a>.\n",
              "   </d-footnote> and fully-connected<d-footnote>\n",
              "     A fully-connected layer computes output neurons as weighted sum of input neurons. In matrix form, it is a matrix that linearly transforms the input vector into the output vector.\n",
              "   </d-footnote>), max-pooling, and ReLU<d-footnote>\n",
              "     First introduced by Nair and Hinton<d-cite key=\"nair2010relu\"></d-cite>, ReLU calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0,x)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span> for each entry in a vector input. Graphically, it is a hinge at the origin: <img class=\"img-center\" src=\"figs/relu.png\" style=\"width:60%\"/>\n",
              "     Image credit to <a href=\"https://pytorch.org/docs/stable/nn.html#relu\">https://pytorch.org/docs/stable/nn.html#relu</a>\n",
              " </d-footnote> layers, culminating in a softmax<d-footnote>\n",
              "     Softmax function calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>S</mi><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><msub><mi>y</mi><mi>i</mi></msub></msup></mrow><mrow><msubsup><mi mathvariant=\"normal\">Σ</mi><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><msub><mi>y</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">S(y_i)=\\frac{e^{y_i}}{\\Sigma_{j=1}^{N} e^{y_j}}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.91098em;\"></span><span class=\"strut bottom\" style=\"height:1.6268249999999997em;vertical-align:-0.7158449999999998em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.6069750000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">Σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8328928571428571em;\"><span style=\"top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mathrm mtight\">1</span></span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.46117142857142857em;\"></span></span></span></span></span><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7789785714285715em;\"><span style=\"top:-2.9714357142857146em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathit mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5091600000000001em;\"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathit mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7158449999999998em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> for each entry (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span>) in a vector input (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span>). For example, <img class=\"img-center\" src=\"figs/softmax.png\" style=\"width:75%\"/>\n",
              "     Image credit to <a href=\"https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\">https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/</a>\n",
              " </d-footnote> layer.\n",
              " </p>,\n",
              " <p>\n",
              "   Even though neural networks are capable of incredible feats of classification, deep down, they really are just pipelines of relatively simple functions.\n",
              "   For images, the input is a 2D array of scalar values for gray scale images or RGB triples for colored images.\n",
              "   When needed, one can always flatten the 2D array into an equivalent (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi><mo>⋅</mo><mi>h</mi><mo>⋅</mo><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">w \\cdot h \\cdot c</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02691em;\">w</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">h</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">c</span></span></span></span></span>) -dimensional vector.\n",
              "   Similarly, the intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen as vectors in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}^n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68889em;\"></span><span class=\"strut bottom\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span>, where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> is the number of neurons in the layer. \n",
              "   The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1.\n",
              "   This vector view of data in neural network not only allows us represent complex data in a mathematically compact form, but also hints us on how to visualize them in a better way.\n",
              " </p>,\n",
              " <p>\n",
              "   Most of the simple functions fall into two categories: they are either linear transformations of their inputs (like fully-connected layers or convolutional layers), or relatively simple non-linear functions that work component-wise (like sigmoid activations<d-footnote>\n",
              "     Sigmoid calculates <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>S</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">S(x)=\\frac{e^{x}}{e^{x}+1}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.91098em;\"></span><span class=\"strut bottom\" style=\"height:1.314311em;vertical-align:-0.403331em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.05764em;\">S</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">x</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathrm mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> for each entry (<span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span>) in a vector input. Graphically, it is an S-shaped curve.\n",
              "     <img class=\"img-center\" src=\"figs/sigmoid.png\" style=\"width:60%\"/>\n",
              "     Image credit to <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\">https://en.wikipedia.org/wiki/Sigmoid_function</a>\n",
              " </d-footnote> \n",
              "   or ReLU activations).\n",
              "   Some operations, notably max-pooling<d-footnote>\n",
              "     Max-pooling calculates maximum of a region in the input. For example\n",
              "     <!-- <img src=\"figs/maxpool.png\" style=\"width:60%\" class=\"img-center\">\n",
              "     Image credit to <a href=\"https://computersciencewiki.org/index.php/Max-pooling_/_Pooling\">https://computersciencewiki.org/index.php/Max-pooling_/_Pooling</a> -->\n",
              " <img class=\"img-center\" src=\"figs/maxpool.gif\" style=\"width:70%\"/>\n",
              "     Image credit to <a href=\"https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9\">https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9</a>\n",
              " </d-footnote> and softmax, do not fall into either categories. We will come back to this later.\n",
              " </p>,\n",
              " <p>\n",
              "   The above figure helps us look at a single image at a time; however, it does not provide much context to understand the relationship between layers, between different examples, or between different class labels. For that, researchers often turn to more sophisticated visualizations.\n",
              " </p>,\n",
              " <h2>Using Visualization to Understand DNNs</h2>,\n",
              " <p>\n",
              "   Let’s start by considering the problem of visualizing the training process of a DNN.\n",
              "   When training neural networks, we optimize parameters in the function to minimize a scalar-valued loss function, typically through some form of gradient descent.\n",
              "   We want the loss to keep decreasing, so we monitor the whole history of training and testing losses over rounds of training (or “epochs”), to make sure that the loss decreases over time. \n",
              "   The following figure shows a line plot of the training loss for the MNIST classifier.\n",
              " </p>,\n",
              " <p>\n",
              "   Although its general trend meets our expectation as the loss steadily decreases, we see something strange around epochs 14 and 21: the curve goes almost flat before starting to drop again.\n",
              "   What happened? What caused that?\n",
              " </p>,\n",
              " <p>\n",
              "   If we separate input examples by their true labels/classes and plot the <em>per-class</em> loss like above, we see that the two drops were caused by the classses 1 and 7; the model learns different classes at very different times in the training process. \n",
              "   Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7.\n",
              "   If we knew ahead of time to be looking for class-specific error rates, then this chart works well. But what if we didn’t really know what to look for?\n",
              " </p>,\n",
              " <p>\n",
              "   In that case, we could consider visualizations of neuron activations (e.g. in the last softmax layer) for <em>all</em> examples at once, looking\n",
              "   to find patterns like class-specific behavior, and other patterns besides.\n",
              "   Should there be only two neurons in that layer, a simple two-dimensional scatter plot would work.\n",
              "   However, the points in the softmax layer for our example datasets are 10 dimensional (and in larger-scale classification problems this number can be much larger).\n",
              "   We need to either show two dimensions at a time (which does not scale well as the number of possible charts grows quadratically),\n",
              "   or we can use <em>dimensionality reduction</em> to map the data into a two dimensional space and show them in a single plot. \n",
              " </p>,\n",
              " <p>\n",
              "   Modern dimensionality reduction techniques such as t-SNE and UMAP are capable of impressive feats of summarization, providing two-dimensional images where similar points tend to be clustered together very effectively.\n",
              "   However, these methods are not particularly good to understand the behavior of neuron activations at a fine scale.\n",
              "   Consider the aforementioned intriguing feature about the different learning rate that the MNIST classifier has on digit 1 and 7: the network did not learn to recognize digit 1 until epoch 14, digit 7 until epoch 21.\n",
              "   We compute t-SNE, Dynamic t-SNE<d-cite key=\"rauber2016visualizing\"></d-cite>, and UMAP projections of the epochs where the phenomenon we described happens.\n",
              "   Consider now the task of identifying this class-specific behavior during training. As a reminder, in this case, the strange behavior happens with digits 1 and 7, around epochs 14 and 21 respectively.\n",
              "   While the behavior is not particularly subtle&amp;emdash;digit goes from misclassified to correctly classified&amp;emdash; it is quite hard to notice it in any of the plots below. \n",
              "   Only on careful inspection we can notice that (for example) in the UMAP plot, the digit 1 which clustered in the bottom in epoch 13 becomes a new tentacle-like feature in epoch 14. \n",
              " </p>,\n",
              " <p>\n",
              "   One reason that non-linear embeddings fail in elucidating this phenomenon is that, for the particular change in the data, the fail the principle of <em>data-visual correspondence</em> <d-cite key=\"kindlmann2014algebraic\"></d-cite>. More concretely, the principle states that specific visualization tasks should be modeled as functions that change the data; the visualization sends this change from data to visuals, and\n",
              "   we can study the extent to which the visualization changes are easily perceptible.\n",
              "   Ideally, we want the changes in data and visualization to <em>match in magnitude</em>: a barely noticeable change in visualization should be due to the smallest possible change in data, and a salient change in visualization should reflect a significant one in data.\n",
              "   Here, a significant change happened in only a <em>subset</em> of data (e.g. all points of digit 1 from epoch 13 to 14), but <em>all</em> points in the visualization move dramatically.\n",
              "   For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms.\n",
              "   This property is not ideal for visualization because it fails the data-visual correspondence, making it hard to <em>infer</em> the underlying change in data from the change in the visualization.\n",
              " </p>,\n",
              " <p>\n",
              "   Non-linear embeddings that have non-convex objectives also tend to be sensitive to initial conditions.\n",
              "   For example, in MNIST, although the neural network starts to stabilize on epoch 30, t-SNE and UMAP still generate quite different projections between epochs 30, 31 and 32 (in fact, all the way to 99).\n",
              "   Temporal regularization techniques (such as Dynamic t-SNE) mitigate these consistency issues, but still suffer from other interpretability issues<d-cite key=\"wattenberg2016use\"></d-cite>. \n",
              " </p>,\n",
              " <p>\n",
              "   Now, let’s consider another task, that of identifying classes which the neural network tends to confuse.\n",
              "   For this example, we will use the Fashion-MNIST dataset and classifier, and consider the confusion among sandals, sneakers and ankle boots.\n",
              "   If we know ahead of time that these three classes are likely to confuse the classifier, then we can directly design an appropriate linear projection, as can be seen in the last row of the following figure (we found this particular projection using both the Grand Tour and the direct manipulation technique we later describe). The pattern in this case is quite salient, forming a triangle.\n",
              "   T-SNE, in contrast, incorrectly separates the class clusters (possibly because of an inappropriately-chosen hyperparameter).\n",
              "   UMAP successfully isolates the three classes, but even in this case it’s not possible to distinguish between three-way confusion for the classifier in epochs 5 and 10 (portrayed in a linear method by the presence of points near the center of the triangle), and multiple two-way confusions in later epochs (evidences by an “empty” center).\n",
              " </p>,\n",
              " <h2>Linear Methods to the Rescue</h2>,\n",
              " <p>\n",
              "   When given the chance, then, we should prefer methods for which changes in the data produce predictable, visually salient changes in the result, and linear dimensionality reductions often have this property.\n",
              "   Here, we revisit the linear projections described above in an interface where the user can easily navigate between different training epochs.\n",
              "   In addition, we introduce another useful capability which is only available to linear methods, that of direct manipulation.\n",
              "   Each linear projection from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> dimensions to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">2</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">2</span></span></span></span></span> dimensions can be represented by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> 2-dimensional vectors which have an intuitive interpretation: they are the vectors that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span> canonical basis vector in the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span>-dimensional space will be projected to.\n",
              "   In the context of projecting the final classification layer, this is especially simple to interpret: they are the destinations of an input that is classified with 100% confidence to any one particular class.\n",
              "   If we provide the user with the ability to change these vectors by dragging around user-interface handles, then users can intuitively set up new linear projections.\n",
              " </p>,\n",
              " <p>  \n",
              "   This setup provides additional nice properties that explain the salient patterns in the previous illustrations.\n",
              "   For example, because projections are linear and the coefficients of vectors in the classification layer sum to one, classification outputs that are halfway confident between two classes are projected to vectors that are halfway between the class handles.\n",
              " </p>,\n",
              " <p>\n",
              "   This particular property is illustrated clearly in the Fashion-MNIST example below.\n",
              "   The model confuses sandals, sneakers and ankle boots, as data points form a triangular shape in the softmax layer.\n",
              " </p>,\n",
              " <p>\n",
              "   Examples falling between classes indicate that the model has trouble distinguishing the two, such as sandals vs. sneakers, and sneakers vs. ankle boot classes. \n",
              "   Note, however, that this does not happen as much for sandals vs. ankle boots: not many examples fall between these two classes. \n",
              "   Moreover, most data points are projected close to the edge of the triangle. \n",
              "   This tells us that most confusions happen between two out of the three classes, they are really two-way confusions.\n",
              " \n",
              "   Within the same dataset, we can also see pullovers, coats and shirts filling a triangular <em>plane</em>.\n",
              "   This is different from the sandal-sneaker-ankle-boot case, as examples not only fall on the boundary of a triangle, but also in its interior: a true three-way confusion. \n",
              " \n",
              "   Similarly, in the CIFAR-10 dataset we can see confusion between dogs and cats, airplanes and ships.\n",
              "   The mixing pattern in CIFAR-10 is not as clear as in fashion-MNIST, because many more examples are misclassified.\n",
              " </p>,\n",
              " <h2>The Grand Tour</h2>,\n",
              " <p>\n",
              "   In the previous section, we took advantage of the fact that we knew which classes to visualize.\n",
              "   That meant it was easy to design linear projections for the particular tasks at hand.\n",
              "   But what if we don’t know ahead of time which projection to choose from, because we don’t quite know what to look for?\n",
              "   Principal Component Analysis (PCA) is the quintessential linear dimensionality reduction method,\n",
              "   choosing to project the data so as to preserve the most variance possible. \n",
              "   However, the distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector.<d-footnote>We are assuming a class-balanced training dataset. Nevertheless, if the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much either.</d-footnote>\n",
              "   As a result, even though PCA projections are interpretable and consistent through training epochs, the first two principal components of softmax activations are not substantially better than the third.\n",
              "   So which of them should we choose?\n",
              "   Instead of PCA, we propose to visualize this data by smoothly animating random projections, using a technique called the Grand Tour<d-cite key=\"asimov1985grand\"></d-cite>.\n",
              " </p>,\n",
              " <p>\n",
              " Starting with a random velocity, it smoothly rotates data points around the origin in high dimensional space, and then projects it down to 2D for display. \n",
              " Here are some examples of how Grand Tour acts on some (low-dimensional) objects:\n",
              " </p>,\n",
              " <p>\n",
              "   We first look at the Grand Tour of the softmax layer. \n",
              "   The softmax layer is relatively easy to understand because its axes have strong semantics. As we described earlier, the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th axis corresponds to network’s <em>confidence</em> about predicting that the given input belongs to the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th class. \n",
              " </p>,\n",
              " <p>\n",
              "   The Grand Tour of the softmax layer lets us qualitatively assess the performance of our model.\n",
              "   In the particular case of this article, since we used comparable architectures for three datasets, this also allows us to gauge the relative difficulty of classifying each dataset. \n",
              "   We can see that data points are most confidently classified for the MNIST dataset, where the digits are close to one of the ten corners of the softmax space. For Fashion-MNIST or CIFAR-10, the separation is not as clean, and more points appear <em>inside</em> the volume.\n",
              " </p>,\n",
              " <p>\n",
              "   Linear projection methods naturally give a formulation that is independent of the input points, allowing us to keep the projection fixed while the\n",
              "   data changes.\n",
              "   To recap our working example, we trained each of the neural networks for 99 epochs and recorded the entire history of neuron activations on a subset of training and testing examples. We can use the Grand Tour, then, to visualize the actual training process of these networks.\n",
              " </p>,\n",
              " <p>\n",
              "   In the beginning when the neural networks are randomly initialized, all examples are placed around the center of the softmax space, with equal weights to each class. \n",
              "   Through training, examples move to class vectors in the softmax space. The Grand Tour also lets us\n",
              "   compare visualizations of the training and testing data, giving us a qualitative assessment of over-fitting. \n",
              "   In the MNIST dataset, the trajectory of testing images through training is consistent with the training set. \n",
              "   Data points went directly toward the corner of its true class and all classes are stabilized after about 50 epochs.\n",
              "   On the other hand, in CIFAR-10 there is an <em>inconsistency</em> between the training and testing sets. Images from the testing set keep oscillating while most images from training converges to the corresponding class corner. \n",
              "   In epoch 99, we can clearly see a difference in distribution between these two sets.\n",
              "   This signals that the model overfits the training set and thus does not generalize well to the testing set. \n",
              " </p>,\n",
              " <p>\n",
              "   Given the presented techniques of the Grand Tour and direct manipulations on the axes, we can in theory visualize and manipulate any intermediate layer of a neural network by itself.  Nevertheless, this is not a very satisfying approach, for two reasons:\n",
              "   </p>,\n",
              " <p></p>,\n",
              " <p>\n",
              "   To address the first problem, we will need to pay closer attention to the way in which layers transform the data that they are given.  \n",
              "   To see how a linear transformation can be visualized in a particularly ineffective way, consider the following (very simple) weights (represented by a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span>) which take a 2-dimensional hidden layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span> and produce activations in another 2-dimensional layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>. The weights simply negate two activations in 2D:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn><mo separator=\"true\">,</mo><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\n",
              "     A = \\begin{bmatrix}\n",
              "     -1, 0 \\\\\n",
              "     0, -1\n",
              "     \\end{bmatrix}\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.45em;\"></span><span class=\"strut bottom\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span><span class=\"mrel\">=</span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord mathrm\">1</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord\">−</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></span>\n",
              "   Imagine that we wish to visualize the behavior of network as the data moves from layer to layer. One way to interpolate the source <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> and destination <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mi>A</mi><mo>(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>)</mo><mo>=</mo><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1 = A(x_0) = -x_0</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\">A</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> of this action <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> is by a simple linear interpolation\n",
              " \n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo>)</mo><mo>⋅</mo><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi><mo>⋅</mo><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mo>(</mo><mn>1</mn><mo>−</mo><mn>2</mn><mi>t</mi><mo>)</mo><mo>⋅</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">\n",
              "   x_t = (1-t) \\cdot x_0 + t \\cdot x_1 = (1-2t) \\cdot x_0    \n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">t</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathrm\">2</span><span class=\"mord mathit\">t</span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span></span>\n",
              "   for <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo>]</mo><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">t \\in [0,1].</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">t</span><span class=\"mrel\">∈</span><span class=\"mopen\">[</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">]</span><span class=\"mord mathrm\">.</span></span></span></span></span>\n",
              " \n",
              "   Effectively, this strategy reuses the linear projection coefficients from one layer to the next. This is a natural thought, since they have the same dimension.\n",
              "   However, notice the following: the transformation given by A is a simple rotation of the data. Every linear transformation of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span> could be encoded simply as a linear transformation of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>, if only that transformation operated on the negative values of the entries.\n",
              "   In addition, since the Grand Tour has a rotation itself built-in, for every configuration that gives a certain picture of the layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>, there exists a <em>different</em> configuration that would yield the same picture for layer <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>, by taking the action of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> into account.\n",
              "   In effect, the naive interpolation fails the principle of data-visual correspondence: a simple change in data (negation in 2D/180 degree rotation) results in a drastic change in visualization (all points cross the origin).\n",
              " </p>,\n",
              " <p>\n",
              "   This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations.\n",
              "   We should seek to explicitly articulate what are purely representational artifacts that we should discard, and what are the real features a visualization we should <em>distill</em> from the representation.\n",
              "   Here, we claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities.\n",
              "   As we will show, the Grand Tour is particularly attractive in this case because it is can be made to be invariant to rotations in data.\n",
              "   As a result, the rotational components in the linear transformations of a neural network will be explicitly made invisible.\n",
              " </p>,\n",
              " <p>\n",
              "   Concretely, we achieve this by taking advantage of a central theorem of linear algebra. \n",
              "   The <em>Singular Value Decomposition</em> (SVD) theorem shows that <em>any</em> linear transformation can be decomposed into a sequence of very simple operations: a rotation, a scaling, and another rotation<d-cite key=\"austin2009svd\"></d-cite>. \n",
              " \n",
              "   Applying a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">A</span></span></span></span></span> to a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span> is then equivalent to applying those simple operations: <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>A</mi><mo>=</mo><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">x A = x U \\Sigma V^T</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\">A</span><span class=\"mrel\">=</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span>.\n",
              "   But remember that the Grand Tour works by rotating the dataset and then projecting it to 2D.\n",
              "   Combined, these two facts mean that as far as the Grand Tour is concerned, visualizing a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span></span></span></span></span> is the same as visualizing <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">x U</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span>, and visualizing a vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">x U \\Sigma V^T</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8413309999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span> is the same as visualizing <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">x U \\Sigma</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span></span></span></span></span>. \n",
              "   This means that any linear transformation seen by the Grand Tour is equivalent to the transition between <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi></mrow><annotation encoding=\"application/x-tex\">x U</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>U</mi><mi mathvariant=\"normal\">Σ</mi></mrow><annotation encoding=\"application/x-tex\">x U \\Sigma</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathrm\">Σ</span></span></span></span></span> - a simple (coordinate-wise) scaling. \n",
              "   This is explicitly saying that any linear operation (whose matrix is represented in standard bases) is a scaling operation with appropriately chosen orthonormal bases on both sides.\n",
              "   So the Grand Tour provides a natural, elegant and computationally efficient way to <em>align</em> visualizations of activations separated by fully-connected (linear) layers.<d-footnote>Convolutional layers are also linear. One can instantly see that by forming the linear transformations between flattened feature maps, or by taking the circulant structure of convolutional layers directly into account<d-cite key=\"sedghi2018singular\"></d-cite></d-footnote>\n",
              " </p>,\n",
              " <p>\n",
              "   (For the following portion, we reduce the number of data points to 500 and epochs to 50, in order to reduce the amount of data transmitted in a web-based demonstration.)\n",
              "   With the linear algebra structure at hand, now we are able to trace behaviors and patterns from the softmax back to previous layers.\n",
              "   In fashion-MNIST, for example, we observe a separation of shoes (sandals, sneakers and ankle boots as a group) from all other classes in the softmax layer. \n",
              "   Tracing it back to earlier layers, we can see that this separation happened as early as <a onclick=\"lt2Figure.onscreen()\">layer 5</a>:\n",
              " </p>,\n",
              " <p>\n",
              "   As a final application scenario, we show how the Grand Tour can also elucidate the behavior of adversarial examples<d-cite key=\"szegedy2013intriguing\"></d-cite> as they are processed by a neural network.\n",
              "   For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s.\n",
              "   Previously, we either animated the training dynamics or the layer dynamics.\n",
              "   We fix a well-trained neural network, and visualize the training process of adversarial examples, since they are often themselves generated by an optimization process. Here, we used the Fast Gradient Sign method.<d-cite key=\"goodfellow2014explaining\"></d-cite>\n",
              "   Again, because the Grand Tour is a linear method, the change in the positions of the adversarial examples over time can be faithfully attributed to changes in how the neural network perceives the images, rather than potential artifacts of the visualization.\n",
              "   Let us examine how adversarial examples evolved to fool the network:\n",
              " </p>,\n",
              " <p>\n",
              "   Through this adversarial training, the network eventually claims, with high confidence, that the inputs given are all 0s.\n",
              "   If we stay in the softmax layer and slide though the adversarial training steps in the plot, we can see adversarial examples move from a high score for class 8 to a high score for class 0.\n",
              "   Although all adversarial examples are classified as the target class (digit 0s) eventually, some of them detoured somewhere close to the centroid of the space (around the 25th epoch) and then moved towards the target. \n",
              "   Comparing the actual images of the two groups, we see those that those “detouring” images tend to be noisier.\n",
              " </p>,\n",
              " <p>\n",
              "   More interesting, however, is what happens in the intermediate layers.\n",
              "   In pre-softmax, for example, we see that these <span style=\"color: #444444; font-weight: 550;\">fake 0s</span> behave differently from the <span style=\"color: #1f77b4; font-weight: 550;\">genuine 0s</span>: they live closer to the decision boundary of two classes and form a plane by themselves. \n",
              " </p>,\n",
              " <h2>Discussion</h2>,\n",
              " <p>\n",
              "   Early on, we compared several state-of-the-art dimensionality reduction techniques with the Grand Tour, showing that non-linear methods do not have as many desirable properties as the Grand Tour for understanding the behavior of neural networks. \n",
              "   However, the state-of-the-art non-linear methods come with their own strength. \n",
              "   Whenever geometry is concerned, like the case of understanding multi-way confusions in the softmax layer, linear methods are more interpretable because they preserve certain geometrical structures of data in the projection. \n",
              "   When topology is the main focus, such as when we want to cluster the data or we need dimensionality reduction for downstream models that are less sensitive to geometry, we might choose non-linear methods such as UMAP or t-SNE for they have more freedom in projecting the data, and will generally make better use of the fewer dimensions available. \n",
              " </p>,\n",
              " <p>\n",
              "   When comparing linear projections with non-linear dimensionality reductions, we used small multiples to contrast training epochs and dimensionality reduction methods.\n",
              "   The Grand Tour, on the other hand, uses a single animated view.\n",
              "   When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature, aside. \n",
              "   from specific settings such as dynamic graph drawing <d-cite key=\"archambault2010animation\"></d-cite>, or concerns about incomparable contents <d-cite key=\"tversky2002animation\"></d-cite> between small multiples and animated plots.\n",
              "   Regardless of these concerns, in our scenarios, the use of animation comes naturally from the direct manipulation and the existence of a continuum of rotations for the Grand Tour to operate in.\n",
              " </p>,\n",
              " <p>\n",
              "   In our work we have used models that are purely “sequential”, in the sense that the layers can be put in numerical ordering, and that the activations for\n",
              "   the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span></span>-th layer are a function exclusively of the activations at the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">n</span></span></span></span></span>-th layer. \n",
              "   In recent DNN architectures, however, it is common to have non-sequential parts such as highway <d-cite key=\"srivastava2015highway\"></d-cite> branches or dedicated branches for different tasks <d-cite key=\"szegedy2015going\"></d-cite>. \n",
              "   With our technique, one can visualize neuron activations on each such branch, but additional research is required to incorporate multiple branches directly.\n",
              " </p>,\n",
              " <p>\n",
              "   Modern architectures are also wide. Especially when convolutional layers are concerned, one could run into issues with scalability if we see such layers as a large sparse matrix acting on flattened multi-channel images.\n",
              "   For the sake of simplicity, in this article we brute-forced the computation of the alignment of such convolutional layers by writing out their explicit matrix representation. \n",
              "   However, the singular value decomposition of multi-channel 2D convolutions can be computed efficiently <d-cite key=\"sedghi2018singular\"></d-cite>, which can be then be directly used for alignment, as we described above.\n",
              " </p>,\n",
              " <h2 class=\"clickable\" onclick=\"toggle(event, '#div-technical-details')\"><a name=\"technical-details\"></a>\n",
              " Technical Details\n",
              " </h2>,\n",
              " <p>\n",
              "   In this section, our notational convention is that data points are represented as row vectors.\n",
              "   An entire dataset is laid out as a matrix, where each row is a data point, and each column represents a different feature/dimension.\n",
              "   As a result, when a linear transformation is applied to the data, the row vectors (and the data matrix overall) are left-multiplied by the transformation matrix.\n",
              "   This has a side benefit that when applying matrix multiplications in a chain, the formula reads from left to right and aligns with a commutative diagram.\n",
              "   For example, when a data matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span></span></span></span></span> is multiplied by a matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span> to generate <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span>, in formula we write <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>X</mi><mi>M</mi><mo>=</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">XM = Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">M</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.22222em;\">Y</span></span></span></span></span>, the letters have the same order in diagram:\n",
              " </p>,\n",
              " <p>\n",
              "   The direct manipulations we presented earlier provide explicit control over the possible projections for the data points.\n",
              "   We provide two modes: directly manipulating class axes (the “axis mode”), or directly manipulating a group of data points through their centroid (the “data point mode”).\n",
              "   Based on the dimensionality and axis semantics, as discussed in <a href=\"#layer-dynamics\">Layer Dynamics</a>, we may prefer one mode than the other.\n",
              "   \n",
              "   We will see that the axis mode is a special case of data point mode, because we can view an axis handle as a particular “fictitious” point in the dataset.\n",
              "   Because of its simplicity, we will first introduce the axis mode.\n",
              " </p>,\n",
              " <p>\n",
              "     The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle), they are signaling to the system that they wished that the corresponding\n",
              "     data point had been projected to the location where the UI element was dropped, rather than where it was dragged from.\n",
              "     In our case the overall projection is a rotation (originally determined by the Grand Tour), and an arbitrary user manipulation might not necessarily generate a new projection that is also a rotation. Our goal, then, is to find a new rotation which satisfies the user request and is close to the previous state of the Grand Tour projection, so that the resulting state satisfies the user request.\n",
              " \n",
              "   In a nutshell, when user drags the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> axis handle by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(dx, dy)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span>, we add them to the first two entries of the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of the Grand Tour matrix, and then perform <a href=\"https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\">Gram-Schmidt orthonormalization</a> on the rows of the new matrix.\n",
              "   <d-footnote>\n",
              "     Rows have to be reordered such that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row is considered first in the Gram-Schmidt procedure.\n",
              "   </d-footnote>\n",
              " </p>,\n",
              " <p>\n",
              "   Before we see in detail why this works well, let us formalize the process of the Grand Tour on a standard basis vector <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span>. \n",
              "   As shown in the diagram below, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> goes through an orthogonal Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> to produce a rotated version of itself, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>. \n",
              "   Then, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>π</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\pi_2</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> is a function that keeps only the first two entries of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> and gives the 2D coordinate of the handle to be shown in the plot, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i, y_i)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\n",
              " </p>,\n",
              " <p>\n",
              "   When user drags an axis handle on the screen canvas, they induce a delta change <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">Δ</mi><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\Delta = (dx, dy)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathrm\">Δ</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span> on the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">xy</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span>-plane. \n",
              "   The coordinate of the handle becomes:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo separator=\"true\">,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo><mo>:</mo><mo>=</mo><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i^{(new)}, y_i^{(new)}) := (x_i+dx, y_i+dy)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.321664em;vertical-align:-0.276864em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span></span>\n",
              "   Note that <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> are the first two coordinates of the axis handle in high dimensions after the Grand Tour rotation, so a delta change on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(x_i, y_i)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> induces a delta change <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\tilde{\\Delta} := (dx, dy, 0, 0, \\cdots)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"minner\">⋯</span><span class=\"mclose\">)</span></span></span></span></span> on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><msup><mo><mo>↦</mo></mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i} \\overset{\\tilde{\\Delta}}{\\mapsto} \\tilde{e_i} + \\tilde{\\Delta}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.455133em;\"></span><span class=\"strut bottom\" style=\"height:1.605133em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.455133em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">↦</span></span></span><span style=\"top:-3.7110000000000003em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">Δ</span></span></span><span style=\"top:-3.3023300000000004em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span><span class=\"mtight\">~</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.011em;\"></span></span></span></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span></span>\n",
              " </p>,\n",
              " <p>\n",
              "   To find a nearby Grand Tour rotation that respects this change, first note that <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> is exactly the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of orthogonal Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span>\n",
              " <d-footnote>\n",
              "     Recall that the convention is that vectors are in row form and linear transformations are matrices that are multiplied on the right.\n",
              "     So <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span></span> is a row vector whose <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th entry is <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">1</span></span></span></span></span> (and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.64444em;\"></span><span class=\"strut bottom\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathrm\">0</span></span></span></span></span>s elsewhere) and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><msub><mi>e</mi><mi>i</mi></msub><mo>⋅</mo><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i} := e_i \\cdot GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> is the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.65952em;\"></span><span class=\"strut bottom\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">i</span></span></span></span></span>-th row of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span>\n",
              " </d-footnote>. \n",
              "   Naturally, we want the new matrix to be the original <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> with its <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row replaced by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}+\\tilde{\\Delta}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, i.e. we should add <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">dx</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">dy</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span> to the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(i,1)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">i</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">1</span><span class=\"mclose\">)</span></span></span></span></span>-th entry and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(i,2)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">i</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">2</span><span class=\"mclose\">)</span></span></span></span></span>-th entry of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> respectively:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mo>←</mo><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT} \\leftarrow GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span>\n",
              " <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>←</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>d</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT}_{i,1} \\leftarrow GT_{i,1} + dx</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.269438em;vertical-align:-0.286108em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span></span></span></span></span></span>\n",
              " <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>←</mo><mi>G</mi><msub><mi>T</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>+</mo><mi>d</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT}_{i,2} \\leftarrow GT_{i,2} + dy</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.269438em;vertical-align:-0.286108em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mrel\">←</span><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span></span>\n",
              "   However, <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span> is not orthogonal for arbitrary <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">(dx, dy)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span>.\n",
              "   In order to find an approximation to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span> that is orthogonal, we apply <a href=\"https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\">Gram-Schmidt orthonormalization</a> on the rows of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\widetilde{GT}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:0.98333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span></span></span></span></span>, with the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row considered first in the Gram-Schmidt process:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msup><mi>T</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mtext>GramSchmidt</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">GT^{(new)} := \\textsf{GramSchmidt}(\\widetilde{GT})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.98333em;\"></span><span class=\"strut bottom\" style=\"height:1.23333em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">GramSchmidt</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\n",
              "   Note that the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row is normalized to a unit vector during the Gram-Schmidt, so the resulting position of the handle is \n",
              "   <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}^{(new)} = \\textsf{normalize}(\\tilde{e_i} + \\tilde{\\Delta})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.19576em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>\n",
              "   which may not be exactly the same as <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}+\\tilde{\\Delta}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, as the following figure shows\n",
              "   <d-footnote>\n",
              "     However, for any <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{\\Delta}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:0.9201899999999998em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, the norm of the difference is bounded above by <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">||\\tilde{\\Delta}||</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span></span></span>, as the following figure proves.\n",
              "     <img class=\"img-center\" src=\"figs/direct-manipulation-rotation-2d-proof.png\" style=\"width: 100%\"/>\n",
              " </d-footnote>\n",
              "   .\n",
              " </p>,\n",
              " <p>\n",
              "   We now explain how we directly manipulate data points. \n",
              "   Technically speaking, this method only considers one point at a time.\n",
              "   For a group of points, we compute their centroid and directly manipulate this single point with this method.\n",
              "   Thinking more carefully about the process in axis mode gives us a way to drag any single point.\n",
              "   Recall that in axis mode, we added user’s manipulation <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>:</mo><mo>=</mo><mo>(</mo><mi>d</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>d</mi><mi>y</mi><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\tilde{\\Delta} := (dx, dy, 0, 0, \\cdots)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.1701899999999998em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">x</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"mord mathrm\">0</span><span class=\"mpunct\">,</span><span class=\"minner\">⋯</span><span class=\"mclose\">)</span></span></span></span></span> to the position of the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> axis handle <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span>.\n",
              "   This induces a delta change in the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span> row of the Grand Tour matrix <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span>.\n",
              "   Next, as the first step in Gram-Schmidt, we normalized this row: \n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msubsup><mi>T</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>:</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><msub><mover accent=\"true\"><mrow><mi>G</mi><mi>T</mi></mrow><mo stretchy=\"true\">~</mo></mover><mi>i</mi></msub><mo>)</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\n",
              "     GT_i^{(new)} := \\textsf{normalize}(\\widetilde{GT}_i) = \\textsf{normalize}(\\tilde{e_i} + \\tilde{\\Delta})\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.321664em;vertical-align:-0.276864em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98333em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"svg-align\" style=\"top:-3.6833299999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span style=\"height:0.3em;\"><svg height=\"0.3em\" preserveaspectratio=\"none\" viewbox=\"0 0 1033 286\" width=\"100%\">\n",
              " <path d=\"M344 55.266c-142 0-300.638 81.316-311.5 86.418\n",
              " -8.01 3.762-22.5 10.91-23.5 5.562L1 120c-1-2-1-3-1-4 0-5 3-9 8-10l18.4-9C160.9\n",
              "  31.9 283 0 358 0c148 0 188 122 331 122s314-97 326-97c4 0 8 2 10 7l7 21.114\n",
              " c1 2.14 1 3.21 1 4.28 0 5.347-3 9.626-7 10.696l-22.3 12.622C852.6 158.372 751\n",
              "  181.476 676 181.476c-149 0-189-126.21-332-126.21z\"></path></svg></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\n",
              "   These two steps make the axis handle move from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> to <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}^{(new)} := \\textsf{normalize}(\\tilde{e_i}+\\tilde{\\Delta})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.19576em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\n",
              " </p>,\n",
              " <p>\n",
              "   Looking at the geometry of this movement, the “add-delta-then-normalize” on <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> is equivalent to a <em>rotation</em> from <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> towards <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}^{(new)}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9457599999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.0957599999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9457599999999999em;\"><span style=\"top:-3.1207599999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span>, illustrated in the figure below. \n",
              "   This geometric interpretation can be directly generalized to any arbitrary data point.\n",
              " </p>,\n",
              " <p>\n",
              "   The figure shows the case in 3D, but in higher dimensional space it is essentially the same, since the two vectors <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{e_i}+\\tilde{\\Delta}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.9201899999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.0701899999999998em;vertical-align:-0.15em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathit\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span></span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span> only span a 2-subspace.\n",
              "   Now we have a nice geometric intuition about direct manipulation: dragging a point induces a <em>simple rotation</em>\n",
              " <d-footnote><a href=\"https://en.wikipedia.org/wiki/Rotations_in_4-dimensional_Euclidean_space#Simple_rotations\">Simple rotations</a> are rotations with only one <a href=\"https://en.wikipedia.org/wiki/Plane_of_rotation#Simple_rotations\">plane of rotation</a>.</d-footnote>\n",
              "   in high dimensional space.\n",
              "   This intuition is precisely how we implemented our direct manipulation on arbitrary data points, which we will specify as below.\n",
              " </p>,\n",
              " <p>\n",
              "   Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{c}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.6678599999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span> to \n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mo>)</mo><mo>⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">/</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>+</mo><mover accent=\"true\"><mrow><mi mathvariant=\"normal\">Δ</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">\n",
              "     \\tilde{c}^{(new)} := (\\tilde{c} + \\tilde{\\Delta}) \\cdot ||\\tilde{c}|| / ||\\tilde{c} + \\tilde{\\Delta}||\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.938em;\"></span><span class=\"strut bottom\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mbin\">⋅</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">/</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">+</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9201899999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Δ</span></span></span><span style=\"top:-3.6023300000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span></span></span></span>\n",
              " </p>,\n",
              " <p>\n",
              "   First, the angle of rotation can be found by their cosine similarity:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mtext>arccos</mtext><mo>(</mo><mfrac><mrow><mo>⟨</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>⟩</mo></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>⋅</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac><mo>)</mo></mrow><annotation encoding=\"application/x-tex\"> \\theta = \\textrm{arccos}(\n",
              "     \\frac{\\langle \\tilde{c}, \\tilde{c}^{(new)} \\rangle}{||\\tilde{c}|| \\cdot ||\\tilde{c}^{(new)}||}\n",
              "   )</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.565em;\"></span><span class=\"strut bottom\" style=\"height:2.519em;vertical-align:-0.954em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">=</span><span class=\"mord text\"><span class=\"mord mathrm\">arccos</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mbin\">⋅</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mopen\">⟨</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">⟩</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></span>\n",
              "   Next, to find the matrix form of the rotation, we need a convenient basis.\n",
              "   Let <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span> be a change of (orthonormal) basis matrix in which the first two rows form the 2-subspace <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textrm{span}(\\tilde{c}, \\tilde{c}^{(new)})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>.\n",
              "   For example, we can let its first row to be <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textsf{normalize}(\\tilde{c})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, second row to be its orthonormal complement <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>normalize</mtext><mo>(</mo><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textsf{normalize}(\\tilde{c}^{(new)}_{\\perp})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.0448em;\"></span><span class=\"strut bottom\" style=\"height:1.3461079999999999em;vertical-align:-0.30130799999999996em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.398692em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2197999999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textrm{span}(\\tilde{c}, \\tilde{c}^{(new)})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, and the remaining rows complete the whole space:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>:</mo><mo>=</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>−</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>⋅</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>θ</mi><mfrac><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\n",
              "   \\tilde{c}^{(new)}_{\\perp} \n",
              "   := \\tilde{c} - ||\\tilde{c}|| \\cdot cos \\theta \\frac{\\tilde{c}^{(new)}}{||\\tilde{c}^{(new)}||}\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:1.565em;\"></span><span class=\"strut bottom\" style=\"height:2.519em;vertical-align:-0.954em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.3986920000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3013079999999999em;\"></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mbin\">−</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">c</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">s</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.565em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>\n",
              " <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi><mo>:</mo><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>⋯</mo><mtext>normalize</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>)</mo><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>⋯</mo><mtext>normalize</mtext><mo>(</mo><msubsup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo>⊥</mo><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msubsup><mo>)</mo><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi>P</mi></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\n",
              "     Q :=\n",
              "     \\begin{bmatrix}\n",
              "     \\cdots \\textsf{normalize}(\\tilde{c}) \\cdots \\\\\n",
              "     \\cdots \\textsf{normalize}(\\tilde{c}^{(new)}_{\\perp}) \\cdots \\\\\n",
              "     P\n",
              "     \\end{bmatrix}\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:2.1524em;\"></span><span class=\"strut bottom\" style=\"height:3.8048em;vertical-align:-1.6523999999999999em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1524em;\"><span style=\"top:-4.3572em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"minner\">⋯</span></span></span><span style=\"top:-2.9524em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span><span class=\"mord text\"><span class=\"mord mathsf\">normalize</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.398692em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">⊥</span></span></span></span><span style=\"top:-3.2197999999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"minner\">⋯</span></span></span><span style=\"top:-1.7524000000000002em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6523999999999999em;\"></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"></span></span></span></span></span></span></span></span></span></span></span>\n",
              "   where <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span></span></span></span></span> completes the remaining space.\n",
              " \n",
              "   Making use of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span>, we can find the matrix that rotates the plane <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textrm{span}(\\tilde{c}, \\tilde{c}^{(new)})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> by the angle <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span>:\n",
              "   <span><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ρ</mi><mo>=</mo><msup><mi>Q</mi><mi>T</mi></msup><mrow><mo fence=\"true\">[</mo><mtable><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi>cos</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi>sin</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>−</mo><mi>sin</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi>cos</mi><mi>θ</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mo>⋯</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mn>0</mn></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">⋮</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">⋮</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow><mi>I</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle=\"false\" scriptlevel=\"0\"><mrow></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mi>Q</mi><mo>=</mo><mo>:</mo><msup><mi>Q</mi><mi>T</mi></msup><msub><mi>R</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>(</mo><mi>θ</mi><mo>)</mo><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">\n",
              "     \\rho = Q^T\n",
              "     \\begin{bmatrix}\n",
              "     \\cos \\theta&amp; \\sin \\theta&amp;  0&amp;  0&amp; \\cdots\\\\\n",
              "     -\\sin \\theta&amp; \\cos \\theta&amp;  0&amp;  0&amp; \\cdots\\\\\n",
              "     0&amp; 0&amp;  \\\\ \n",
              "     \\vdots&amp; \\vdots&amp; &amp; I&amp; \\\\\n",
              "     \\end{bmatrix}\n",
              "     Q\n",
              "     =: Q^T R_{1,2}(\\theta) Q\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:3.2800000000000007em;\"></span><span class=\"strut bottom\" style=\"height:6.0600000000000005em;vertical-align:-2.7799999999999994em;\"></span><span class=\"base\"><span class=\"mord mathit\">ρ</span><span class=\"mrel\">=</span><span class=\"mord\"><span class=\"mord mathit\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.254em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-2.2049800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-2.8059800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-3.4069800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-4.00798em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎢</span></span></span><span style=\"top:-5.2540000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">cos</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mop\">sin</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">⋮</span></span></span><span style=\"top:-0.5800000000000007em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.7799999999999994em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">sin</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">cos</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">⋮</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999996em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-3.04em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span><span style=\"top:-1.7800000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999996em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">0</span></span></span><span style=\"top:-1.780000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">I</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999992em;\"></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.2800000000000007em;\"><span style=\"top:-5.44em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span></span></span><span style=\"top:-4.24em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"minner\">⋯</span></span></span><span style=\"top:-1.780000000000001em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5799999999999992em;\"></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.254em;\"><span style=\"top:-1.0499800000000006em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-2.2049800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-2.8059800000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-3.4069800000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-4.00798em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎥</span></span></span><span style=\"top:-5.2540000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.75004em;\"></span></span></span></span></span></span><span class=\"mord mathit\">Q</span><span class=\"mrel\">=</span><span class=\"mrel\">:</span><span class=\"mord\"><span class=\"mord mathit\">Q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathit mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathrm mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mord mathit\">Q</span></span></span></span></span></span>\n",
              "   The new Grand Tour matrix is the matrix product of the original <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">GT</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span> and <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\\rho</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">ρ</span></span></span></span></span>:\n",
              "   <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>G</mi><msup><mi>T</mi><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>:</mo><mo>=</mo><mi>G</mi><mi>T</mi><mo>⋅</mo><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\n",
              "     GT^{(new)} := GT \\cdot \\rho\n",
              "   </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">G</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mrel\">:</span><span class=\"mrel\">=</span><span class=\"mord mathit\">G</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">T</span><span class=\"mbin\">⋅</span><span class=\"mord mathit\">ρ</span></span></span></span></span>\n",
              "   Now we should be able to see the connection between axis mode and data point mode.\n",
              "   In data point mode, finding <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"base\"><span class=\"mord mathit\">Q</span></span></span></span></span> can be done by Gram-Schmidt: Let the first basis be <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde{c}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.6678599999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.6678599999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span></span></span></span></span>, find the orthogonal component of <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\tilde{c}^{(new)}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span> in <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mtext>span</mtext><mo>(</mo><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mrow><mi>c</mi></mrow><mo>~</mo></mover><mrow><mo>(</mo><mi>n</mi><mi>e</mi><mi>w</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\textrm{span}(\\tilde{c}, \\tilde{c}^{(new)})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.8879999999999999em;\"></span><span class=\"strut bottom\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord text\"><span class=\"mord mathrm\">span</span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathit\">c</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"margin-left:0.11112em;\"><span>~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathit mtight\">n</span><span class=\"mord mathit mtight\">e</span><span class=\"mord mathit mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>, repeatedly take a random vector, find its orthogonal component to the span of the current basis vectors and add it to the basis set. \n",
              "   In axis mode, the <span><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>i</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">i^{th}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.849108em;\"></span><span class=\"strut bottom\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathit\">i</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathit mtight\">t</span><span class=\"mord mathit mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span></span>-row-first Gram-Schmidt does the rotation and change of basis in one step.\n",
              " </p>,\n",
              " <h2>Conclusion</h2>,\n",
              " <p>\n",
              "   As powerful as t-SNE and UMAP are, they often fail to offer the correspondences we need, and such correspondences can come, surprisingly, from relatively simple methods like the Grand Tour. The Grand Tour method we presented is particularly useful when direct manipulation from the user is available or desirable.\n",
              "   We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers, and using the Grand Tour and direct manipulation to compute the final projection.\n",
              " </p>,\n",
              " <p>\n",
              "     The utility code for WebGL under js/lib/webgl_utils/ are adapted from Angel’s computer graphics book supplementary \n",
              "     <a href=\"https://www.cs.unm.edu/~angel/BOOK/INTERACTIVE_COMPUTER_GRAPHICS/SEVENTH_EDITION/\">here</a>.\n",
              "   </p>,\n",
              " <p>\n",
              " <a href=\"https://github.com/distillpub/post--grand-tour/issues/6\">Review 1 - Anonymous </a><br/>\n",
              " <a href=\"https://github.com/distillpub/post--grand-tour/issues/7\">Review 2 - Anonymous </a><br/>\n",
              " <a href=\"https://github.com/distillpub/post--grand-tour/issues/8\">Review 3 - Anonymous </a><br/>\n",
              " </p>,\n",
              " <p>\n",
              "     If you see mistakes or want to suggest changes, please <a href=\"https://github.com/distillpub/post--grand-tour/issues/new\">create an issue on GitHub</a>. </p>,\n",
              " <p>Diagrams and text are licensed under Creative Commons Attribution <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY 4.0</a> with the <a class=\"github\" href=\"https://github.com/distillpub/post--grand-tour\">source available on GitHub</a>, unless noted otherwise. The figures that have been reused from other sources don’t fall under this license and can be recognized by a note in their caption: “Figure from …”.</p>,\n",
              " <p>For attribution in academic contexts, please cite this work as</p>,\n",
              " <p>BibTeX citation</p>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=[result.text for result in results]\n",
        "ARTICLE = ' '.join(text)"
      ],
      "metadata": {
        "id": "P_V2qiWLyPtd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARTICLE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "collapsed": true,
        "id": "_0qTmScuyqET",
        "outputId": "760c0c2d-eb7e-40b5-a9d1-448926202d47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nMingwei Li\\n \\nUniversity of Arizona\\n \\nZhenge Zhao\\n \\nUniversity of Arizona\\n \\nCarlos Scheidegger\\n \\nUniversity of Arizona\\n March 16, 2020 10.23915/distill.00025 \\n  The Grand Tour is a classic visualization technique for high-dimensional point clouds that projects a high-dimensional dataset into two dimensions.\\n\\n  Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer.\\n\\n  Unlike modern nonlinear projection methods such as t-SNE and UMAP, the Grand Tour is fundamentally a linear method.\\n\\n  In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.\\n  \\n  Concretely, we present three use cases of interest: visualizing the training process as the network weights change, visualizing the layer-to-layer behavior as the data goes through the network and visualizing both how adversarial examples are crafted and how they fool a neural network.\\n Introduction \\n  Deep neural networks often achieve best-in-class performance in supervised learning contests such as the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).\\n  \\n  Unfortunately, their decision process is notoriously hard to interpret, and their training process is often hard to debug.\\n  \\n  In this article, we present a method to visualize the responses of a neural network which leverages properties of deep neural networks and properties of the Grand Tour.\\n\\n  Notably, our method enables us to more directly reason about the relationship between changes in the data and changes in the resulting visualization.\\n\\n  As we will show, this data-visual correspondence is central to the method we present, especially when compared to other non-linear projection methods like UMAP and t-SNE.\\n  \\n  To understand a neural network, we often try to observe its action on input examples (both real and synthesized).\\n  \\n  These kinds of visualizations are useful to elucidate the activation patterns of a neural network for a single example, but they might offer less insight about the relationship between different examples, different states of the network as it’s being trained, or how the data in the example flows through the different layers of a single network.\\n  \\n  Therefore, we instead aim to enable visualizations of the context around our objects of interest: what is the difference between the present training epoch and the next one? How does the classification of a network converge (or diverge) as the image is fed through the network?\\n\\n  Linear methods are attractive because they are particularly easy to reason about.\\n\\n  The Grand Tour works by generating a random, smoothly changing rotation of the dataset, and then projecting the data to the two-dimensional screen: both are linear processes.\\n\\n  Although deep neural networks are clearly not linear processes, they often confine their nonlinearity to a small set of operations, enabling us to still reason about their behavior.\\n\\n  Our proposed method better preserves context by providing more\\n  consistency: it should be possible to know how the visualization\\n  would change, if the data had been different in a particular\\n  way.\\n Working Examples \\n  To illustrate the technique we will present, we trained deep neural\\n  network models (DNNs) with 3 common image classification datasets:\\n  MNIST\\n  \\n    MNIST contains grayscale images of 10 handwritten digits\\n    \\n    Image credit to https://en.wikipedia.org/wiki/File:MnistExamples.png\\n,\\n  fashion-MNIST\\n  \\n    Fashion-MNIST contains grayscale images of 10 types of fashion items:\\n    \\n\\n    Image credit to https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925\\n\\n\\n  and CIFAR-10\\n  \\n    CIFAR-10 contains RGB images of 10 classes of objects\\n    \\n    Image credit to https://www.cs.toronto.edu/~kriz/cifar.html\\n. \\n  While our architecture is simpler and smaller than current DNNs, it’s still indicative of modern networks, and is complex enough to demonstrate both our proposed techniques and shortcomings of typical approaches.\\n \\n  The following figure presents a simple functional diagram of the neural network we will use throughout the article. The neural network is a sequence of linear (both convolutional\\n    A convolution calculates weighted sums of regions in the input. \\n    In neural networks, the learnable weights in convolutional layers are referred to as the kernel.\\n    For example\\n    \\n    Image credit to https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9.\\n    See also Convolution arithmetic.\\n   and fully-connected\\n    A fully-connected layer computes output neurons as weighted sum of input neurons. In matrix form, it is a matrix that linearly transforms the input vector into the output vector.\\n  ), max-pooling, and ReLU\\n    First introduced by Nair and Hinton, ReLU calculates f(x)=max(0,x)f(x)=max(0,x)f(x)=max(0,x) for each entry in a vector input. Graphically, it is a hinge at the origin: \\n    Image credit to https://pytorch.org/docs/stable/nn.html#relu\\n layers, culminating in a softmax\\n    Softmax function calculates S(yi)=eyiΣj=1NeyjS(y_i)=\\\\frac{e^{y_i}}{\\\\Sigma_{j=1}^{N} e^{y_j}}S(yi\\u200b)=Σj=1N\\u200beyj\\u200beyi\\u200b\\u200b for each entry (yiy_iyi\\u200b) in a vector input (yyy). For example, \\n    Image credit to https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\\n layer.\\n \\n  Even though neural networks are capable of incredible feats of classification, deep down, they really are just pipelines of relatively simple functions.\\n  For images, the input is a 2D array of scalar values for gray scale images or RGB triples for colored images.\\n  When needed, one can always flatten the 2D array into an equivalent (w⋅h⋅cw \\\\cdot h \\\\cdot cw⋅h⋅c) -dimensional vector.\\n  Similarly, the intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen as vectors in Rn\\\\mathbb{R}^nRn, where nnn is the number of neurons in the layer. \\n  The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1.\\n  This vector view of data in neural network not only allows us represent complex data in a mathematically compact form, but also hints us on how to visualize them in a better way.\\n \\n  Most of the simple functions fall into two categories: they are either linear transformations of their inputs (like fully-connected layers or convolutional layers), or relatively simple non-linear functions that work component-wise (like sigmoid activations\\n    Sigmoid calculates S(x)=exex+1S(x)=\\\\frac{e^{x}}{e^{x}+1}S(x)=ex+1ex\\u200b for each entry (xxx) in a vector input. Graphically, it is an S-shaped curve.\\n    \\n    Image credit to https://en.wikipedia.org/wiki/Sigmoid_function\\n \\n  or ReLU activations).\\n  Some operations, notably max-pooling\\n    Max-pooling calculates maximum of a region in the input. For example\\n    \\n\\n    Image credit to https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9\\n and softmax, do not fall into either categories. We will come back to this later.\\n \\n  The above figure helps us look at a single image at a time; however, it does not provide much context to understand the relationship between layers, between different examples, or between different class labels. For that, researchers often turn to more sophisticated visualizations.\\n Using Visualization to Understand DNNs \\n  Let’s start by considering the problem of visualizing the training process of a DNN.\\n  When training neural networks, we optimize parameters in the function to minimize a scalar-valued loss function, typically through some form of gradient descent.\\n  We want the loss to keep decreasing, so we monitor the whole history of training and testing losses over rounds of training (or “epochs”), to make sure that the loss decreases over time. \\n  The following figure shows a line plot of the training loss for the MNIST classifier.\\n \\n  Although its general trend meets our expectation as the loss steadily decreases, we see something strange around epochs 14 and 21: the curve goes almost flat before starting to drop again.\\n  What happened? What caused that?\\n \\n  If we separate input examples by their true labels/classes and plot the per-class loss like above, we see that the two drops were caused by the classses 1 and 7; the model learns different classes at very different times in the training process. \\n  Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7.\\n  If we knew ahead of time to be looking for class-specific error rates, then this chart works well. But what if we didn’t really know what to look for?\\n \\n  In that case, we could consider visualizations of neuron activations (e.g. in the last softmax layer) for all examples at once, looking\\n  to find patterns like class-specific behavior, and other patterns besides.\\n  Should there be only two neurons in that layer, a simple two-dimensional scatter plot would work.\\n  However, the points in the softmax layer for our example datasets are 10 dimensional (and in larger-scale classification problems this number can be much larger).\\n  We need to either show two dimensions at a time (which does not scale well as the number of possible charts grows quadratically),\\n  or we can use dimensionality reduction to map the data into a two dimensional space and show them in a single plot. \\n \\n  Modern dimensionality reduction techniques such as t-SNE and UMAP are capable of impressive feats of summarization, providing two-dimensional images where similar points tend to be clustered together very effectively.\\n  However, these methods are not particularly good to understand the behavior of neuron activations at a fine scale.\\n  Consider the aforementioned intriguing feature about the different learning rate that the MNIST classifier has on digit 1 and 7: the network did not learn to recognize digit 1 until epoch 14, digit 7 until epoch 21.\\n  We compute t-SNE, Dynamic t-SNE, and UMAP projections of the epochs where the phenomenon we described happens.\\n  Consider now the task of identifying this class-specific behavior during training. As a reminder, in this case, the strange behavior happens with digits 1 and 7, around epochs 14 and 21 respectively.\\n  While the behavior is not particularly subtle&emdash;digit goes from misclassified to correctly classified&emdash; it is quite hard to notice it in any of the plots below. \\n  Only on careful inspection we can notice that (for example) in the UMAP plot, the digit 1 which clustered in the bottom in epoch 13 becomes a new tentacle-like feature in epoch 14. \\n \\n  One reason that non-linear embeddings fail in elucidating this phenomenon is that, for the particular change in the data, the fail the principle of data-visual correspondence . More concretely, the principle states that specific visualization tasks should be modeled as functions that change the data; the visualization sends this change from data to visuals, and\\n  we can study the extent to which the visualization changes are easily perceptible.\\n  Ideally, we want the changes in data and visualization to match in magnitude: a barely noticeable change in visualization should be due to the smallest possible change in data, and a salient change in visualization should reflect a significant one in data.\\n  Here, a significant change happened in only a subset of data (e.g. all points of digit 1 from epoch 13 to 14), but all points in the visualization move dramatically.\\n  For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms.\\n  This property is not ideal for visualization because it fails the data-visual correspondence, making it hard to infer the underlying change in data from the change in the visualization.\\n \\n  Non-linear embeddings that have non-convex objectives also tend to be sensitive to initial conditions.\\n  For example, in MNIST, although the neural network starts to stabilize on epoch 30, t-SNE and UMAP still generate quite different projections between epochs 30, 31 and 32 (in fact, all the way to 99).\\n  Temporal regularization techniques (such as Dynamic t-SNE) mitigate these consistency issues, but still suffer from other interpretability issues. \\n \\n  Now, let’s consider another task, that of identifying classes which the neural network tends to confuse.\\n  For this example, we will use the Fashion-MNIST dataset and classifier, and consider the confusion among sandals, sneakers and ankle boots.\\n  If we know ahead of time that these three classes are likely to confuse the classifier, then we can directly design an appropriate linear projection, as can be seen in the last row of the following figure (we found this particular projection using both the Grand Tour and the direct manipulation technique we later describe). The pattern in this case is quite salient, forming a triangle.\\n  T-SNE, in contrast, incorrectly separates the class clusters (possibly because of an inappropriately-chosen hyperparameter).\\n  UMAP successfully isolates the three classes, but even in this case it’s not possible to distinguish between three-way confusion for the classifier in epochs 5 and 10 (portrayed in a linear method by the presence of points near the center of the triangle), and multiple two-way confusions in later epochs (evidences by an “empty” center).\\n Linear Methods to the Rescue \\n  When given the chance, then, we should prefer methods for which changes in the data produce predictable, visually salient changes in the result, and linear dimensionality reductions often have this property.\\n  Here, we revisit the linear projections described above in an interface where the user can easily navigate between different training epochs.\\n  In addition, we introduce another useful capability which is only available to linear methods, that of direct manipulation.\\n  Each linear projection from nnn dimensions to 222 dimensions can be represented by nnn 2-dimensional vectors which have an intuitive interpretation: they are the vectors that the nnn canonical basis vector in the nnn-dimensional space will be projected to.\\n  In the context of projecting the final classification layer, this is especially simple to interpret: they are the destinations of an input that is classified with 100% confidence to any one particular class.\\n  If we provide the user with the ability to change these vectors by dragging around user-interface handles, then users can intuitively set up new linear projections.\\n   \\n  This setup provides additional nice properties that explain the salient patterns in the previous illustrations.\\n  For example, because projections are linear and the coefficients of vectors in the classification layer sum to one, classification outputs that are halfway confident between two classes are projected to vectors that are halfway between the class handles.\\n \\n  This particular property is illustrated clearly in the Fashion-MNIST example below.\\n  The model confuses sandals, sneakers and ankle boots, as data points form a triangular shape in the softmax layer.\\n \\n  Examples falling between classes indicate that the model has trouble distinguishing the two, such as sandals vs. sneakers, and sneakers vs. ankle boot classes. \\n  Note, however, that this does not happen as much for sandals vs. ankle boots: not many examples fall between these two classes. \\n  Moreover, most data points are projected close to the edge of the triangle. \\n  This tells us that most confusions happen between two out of the three classes, they are really two-way confusions.\\n\\n  Within the same dataset, we can also see pullovers, coats and shirts filling a triangular plane.\\n  This is different from the sandal-sneaker-ankle-boot case, as examples not only fall on the boundary of a triangle, but also in its interior: a true three-way confusion. \\n\\n  Similarly, in the CIFAR-10 dataset we can see confusion between dogs and cats, airplanes and ships.\\n  The mixing pattern in CIFAR-10 is not as clear as in fashion-MNIST, because many more examples are misclassified.\\n The Grand Tour \\n  In the previous section, we took advantage of the fact that we knew which classes to visualize.\\n  That meant it was easy to design linear projections for the particular tasks at hand.\\n  But what if we don’t know ahead of time which projection to choose from, because we don’t quite know what to look for?\\n  Principal Component Analysis (PCA) is the quintessential linear dimensionality reduction method,\\n  choosing to project the data so as to preserve the most variance possible. \\n  However, the distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector.We are assuming a class-balanced training dataset. Nevertheless, if the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much either.\\n  As a result, even though PCA projections are interpretable and consistent through training epochs, the first two principal components of softmax activations are not substantially better than the third.\\n  So which of them should we choose?\\n  Instead of PCA, we propose to visualize this data by smoothly animating random projections, using a technique called the Grand Tour.\\n \\nStarting with a random velocity, it smoothly rotates data points around the origin in high dimensional space, and then projects it down to 2D for display. \\nHere are some examples of how Grand Tour acts on some (low-dimensional) objects:\\n \\n  We first look at the Grand Tour of the softmax layer. \\n  The softmax layer is relatively easy to understand because its axes have strong semantics. As we described earlier, the iii-th axis corresponds to network’s confidence about predicting that the given input belongs to the iii-th class. \\n \\n  The Grand Tour of the softmax layer lets us qualitatively assess the performance of our model.\\n  In the particular case of this article, since we used comparable architectures for three datasets, this also allows us to gauge the relative difficulty of classifying each dataset. \\n  We can see that data points are most confidently classified for the MNIST dataset, where the digits are close to one of the ten corners of the softmax space. For Fashion-MNIST or CIFAR-10, the separation is not as clean, and more points appear inside the volume.\\n \\n  Linear projection methods naturally give a formulation that is independent of the input points, allowing us to keep the projection fixed while the\\n  data changes.\\n  To recap our working example, we trained each of the neural networks for 99 epochs and recorded the entire history of neuron activations on a subset of training and testing examples. We can use the Grand Tour, then, to visualize the actual training process of these networks.\\n \\n  In the beginning when the neural networks are randomly initialized, all examples are placed around the center of the softmax space, with equal weights to each class. \\n  Through training, examples move to class vectors in the softmax space. The Grand Tour also lets us\\n  compare visualizations of the training and testing data, giving us a qualitative assessment of over-fitting. \\n  In the MNIST dataset, the trajectory of testing images through training is consistent with the training set. \\n  Data points went directly toward the corner of its true class and all classes are stabilized after about 50 epochs.\\n  On the other hand, in CIFAR-10 there is an inconsistency between the training and testing sets. Images from the testing set keep oscillating while most images from training converges to the corresponding class corner. \\n  In epoch 99, we can clearly see a difference in distribution between these two sets.\\n  This signals that the model overfits the training set and thus does not generalize well to the testing set. \\n \\n  Given the presented techniques of the Grand Tour and direct manipulations on the axes, we can in theory visualize and manipulate any intermediate layer of a neural network by itself.  Nevertheless, this is not a very satisfying approach, for two reasons:\\n    \\n  To address the first problem, we will need to pay closer attention to the way in which layers transform the data that they are given.  \\n  To see how a linear transformation can be visualized in a particularly ineffective way, consider the following (very simple) weights (represented by a matrix AAA) which take a 2-dimensional hidden layer kkk and produce activations in another 2-dimensional layer k+1k+1k+1. The weights simply negate two activations in 2D:\\n  A=[−1,00,−1]\\n    A = \\\\begin{bmatrix}\\n    -1, 0 \\\\\\\\\\n    0, -1\\n    \\\\end{bmatrix}\\n  A=[−1,00,−1\\u200b]\\n  Imagine that we wish to visualize the behavior of network as the data moves from layer to layer. One way to interpolate the source x0x_0x0\\u200b and destination x1=A(x0)=−x0x_1 = A(x_0) = -x_0x1\\u200b=A(x0\\u200b)=−x0\\u200b of this action AAA is by a simple linear interpolation\\n\\n  xt=(1−t)⋅x0+t⋅x1=(1−2t)⋅x0\\n  x_t = (1-t) \\\\cdot x_0 + t \\\\cdot x_1 = (1-2t) \\\\cdot x_0    \\n  xt\\u200b=(1−t)⋅x0\\u200b+t⋅x1\\u200b=(1−2t)⋅x0\\u200b\\n  for t∈[0,1].t \\\\in [0,1].t∈[0,1].\\n\\n  Effectively, this strategy reuses the linear projection coefficients from one layer to the next. This is a natural thought, since they have the same dimension.\\n  However, notice the following: the transformation given by A is a simple rotation of the data. Every linear transformation of the layer k+1k+1k+1 could be encoded simply as a linear transformation of the layer kkk, if only that transformation operated on the negative values of the entries.\\n  In addition, since the Grand Tour has a rotation itself built-in, for every configuration that gives a certain picture of the layer kkk, there exists a different configuration that would yield the same picture for layer k+1k+1k+1, by taking the action of AAA into account.\\n  In effect, the naive interpolation fails the principle of data-visual correspondence: a simple change in data (negation in 2D/180 degree rotation) results in a drastic change in visualization (all points cross the origin).\\n \\n  This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations.\\n  We should seek to explicitly articulate what are purely representational artifacts that we should discard, and what are the real features a visualization we should distill from the representation.\\n  Here, we claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities.\\n  As we will show, the Grand Tour is particularly attractive in this case because it is can be made to be invariant to rotations in data.\\n  As a result, the rotational components in the linear transformations of a neural network will be explicitly made invisible.\\n \\n  Concretely, we achieve this by taking advantage of a central theorem of linear algebra. \\n  The Singular Value Decomposition (SVD) theorem shows that any linear transformation can be decomposed into a sequence of very simple operations: a rotation, a scaling, and another rotation. \\n\\n  Applying a matrix AAA to a vector xxx is then equivalent to applying those simple operations: xA=xUΣVTx A = x U \\\\Sigma V^TxA=xUΣVT.\\n  But remember that the Grand Tour works by rotating the dataset and then projecting it to 2D.\\n  Combined, these two facts mean that as far as the Grand Tour is concerned, visualizing a vector xxx is the same as visualizing xUx UxU, and visualizing a vector xUΣVTx U \\\\Sigma V^TxUΣVT is the same as visualizing xUΣx U \\\\SigmaxUΣ. \\n  This means that any linear transformation seen by the Grand Tour is equivalent to the transition between xUx UxU and xUΣx U \\\\SigmaxUΣ - a simple (coordinate-wise) scaling. \\n  This is explicitly saying that any linear operation (whose matrix is represented in standard bases) is a scaling operation with appropriately chosen orthonormal bases on both sides.\\n  So the Grand Tour provides a natural, elegant and computationally efficient way to align visualizations of activations separated by fully-connected (linear) layers.Convolutional layers are also linear. One can instantly see that by forming the linear transformations between flattened feature maps, or by taking the circulant structure of convolutional layers directly into account\\n \\n  (For the following portion, we reduce the number of data points to 500 and epochs to 50, in order to reduce the amount of data transmitted in a web-based demonstration.)\\n  With the linear algebra structure at hand, now we are able to trace behaviors and patterns from the softmax back to previous layers.\\n  In fashion-MNIST, for example, we observe a separation of shoes (sandals, sneakers and ankle boots as a group) from all other classes in the softmax layer. \\n  Tracing it back to earlier layers, we can see that this separation happened as early as layer 5:\\n \\n  As a final application scenario, we show how the Grand Tour can also elucidate the behavior of adversarial examples as they are processed by a neural network.\\n  For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s.\\n  Previously, we either animated the training dynamics or the layer dynamics.\\n  We fix a well-trained neural network, and visualize the training process of adversarial examples, since they are often themselves generated by an optimization process. Here, we used the Fast Gradient Sign method.\\n  Again, because the Grand Tour is a linear method, the change in the positions of the adversarial examples over time can be faithfully attributed to changes in how the neural network perceives the images, rather than potential artifacts of the visualization.\\n  Let us examine how adversarial examples evolved to fool the network:\\n \\n  Through this adversarial training, the network eventually claims, with high confidence, that the inputs given are all 0s.\\n  If we stay in the softmax layer and slide though the adversarial training steps in the plot, we can see adversarial examples move from a high score for class 8 to a high score for class 0.\\n  Although all adversarial examples are classified as the target class (digit 0s) eventually, some of them detoured somewhere close to the centroid of the space (around the 25th epoch) and then moved towards the target. \\n  Comparing the actual images of the two groups, we see those that those “detouring” images tend to be noisier.\\n \\n  More interesting, however, is what happens in the intermediate layers.\\n  In pre-softmax, for example, we see that these fake 0s behave differently from the genuine 0s: they live closer to the decision boundary of two classes and form a plane by themselves. \\n Discussion \\n  Early on, we compared several state-of-the-art dimensionality reduction techniques with the Grand Tour, showing that non-linear methods do not have as many desirable properties as the Grand Tour for understanding the behavior of neural networks. \\n  However, the state-of-the-art non-linear methods come with their own strength. \\n  Whenever geometry is concerned, like the case of understanding multi-way confusions in the softmax layer, linear methods are more interpretable because they preserve certain geometrical structures of data in the projection. \\n  When topology is the main focus, such as when we want to cluster the data or we need dimensionality reduction for downstream models that are less sensitive to geometry, we might choose non-linear methods such as UMAP or t-SNE for they have more freedom in projecting the data, and will generally make better use of the fewer dimensions available. \\n \\n  When comparing linear projections with non-linear dimensionality reductions, we used small multiples to contrast training epochs and dimensionality reduction methods.\\n  The Grand Tour, on the other hand, uses a single animated view.\\n  When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature, aside. \\n  from specific settings such as dynamic graph drawing , or concerns about incomparable contents  between small multiples and animated plots.\\n  Regardless of these concerns, in our scenarios, the use of animation comes naturally from the direct manipulation and the existence of a continuum of rotations for the Grand Tour to operate in.\\n \\n  In our work we have used models that are purely “sequential”, in the sense that the layers can be put in numerical ordering, and that the activations for\\n  the n+1n+1n+1-th layer are a function exclusively of the activations at the nnn-th layer. \\n  In recent DNN architectures, however, it is common to have non-sequential parts such as highway  branches or dedicated branches for different tasks . \\n  With our technique, one can visualize neuron activations on each such branch, but additional research is required to incorporate multiple branches directly.\\n \\n  Modern architectures are also wide. Especially when convolutional layers are concerned, one could run into issues with scalability if we see such layers as a large sparse matrix acting on flattened multi-channel images.\\n  For the sake of simplicity, in this article we brute-forced the computation of the alignment of such convolutional layers by writing out their explicit matrix representation. \\n  However, the singular value decomposition of multi-channel 2D convolutions can be computed efficiently , which can be then be directly used for alignment, as we described above.\\n \\nTechnical Details\\n \\n  In this section, our notational convention is that data points are represented as row vectors.\\n  An entire dataset is laid out as a matrix, where each row is a data point, and each column represents a different feature/dimension.\\n  As a result, when a linear transformation is applied to the data, the row vectors (and the data matrix overall) are left-multiplied by the transformation matrix.\\n  This has a side benefit that when applying matrix multiplications in a chain, the formula reads from left to right and aligns with a commutative diagram.\\n  For example, when a data matrix XXX is multiplied by a matrix MMM to generate YYY, in formula we write XM=YXM = YXM=Y, the letters have the same order in diagram:\\n \\n  The direct manipulations we presented earlier provide explicit control over the possible projections for the data points.\\n  We provide two modes: directly manipulating class axes (the “axis mode”), or directly manipulating a group of data points through their centroid (the “data point mode”).\\n  Based on the dimensionality and axis semantics, as discussed in Layer Dynamics, we may prefer one mode than the other.\\n  \\n  We will see that the axis mode is a special case of data point mode, because we can view an axis handle as a particular “fictitious” point in the dataset.\\n  Because of its simplicity, we will first introduce the axis mode.\\n \\n    The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle), they are signaling to the system that they wished that the corresponding\\n    data point had been projected to the location where the UI element was dropped, rather than where it was dragged from.\\n    In our case the overall projection is a rotation (originally determined by the Grand Tour), and an arbitrary user manipulation might not necessarily generate a new projection that is also a rotation. Our goal, then, is to find a new rotation which satisfies the user request and is close to the previous state of the Grand Tour projection, so that the resulting state satisfies the user request.\\n\\n  In a nutshell, when user drags the ithi^{th}ith axis handle by (dx,dy)(dx, dy)(dx,dy), we add them to the first two entries of the ithi^{th}ith row of the Grand Tour matrix, and then perform Gram-Schmidt orthonormalization on the rows of the new matrix.\\n  \\n    Rows have to be reordered such that the ithi^{th}ith row is considered first in the Gram-Schmidt procedure.\\n  \\n \\n  Before we see in detail why this works well, let us formalize the process of the Grand Tour on a standard basis vector eie_iei\\u200b. \\n  As shown in the diagram below, eie_iei\\u200b goes through an orthogonal Grand Tour matrix GTGTGT to produce a rotated version of itself, ei~\\\\tilde{e_i}ei\\u200b~\\u200b. \\n  Then, π2\\\\pi_2π2\\u200b is a function that keeps only the first two entries of ei~\\\\tilde{e_i}ei\\u200b~\\u200b and gives the 2D coordinate of the handle to be shown in the plot, (xi,yi)(x_i, y_i)(xi\\u200b,yi\\u200b).\\n \\n  When user drags an axis handle on the screen canvas, they induce a delta change Δ=(dx,dy)\\\\Delta = (dx, dy)Δ=(dx,dy) on the xyxyxy-plane. \\n  The coordinate of the handle becomes:\\n  (xi(new),yi(new)):=(xi+dx,yi+dy)(x_i^{(new)}, y_i^{(new)})\\xa0:= (x_i+dx, y_i+dy)(xi(new)\\u200b,yi(new)\\u200b):=(xi\\u200b+dx,yi\\u200b+dy)\\n  Note that xix_ixi\\u200b and yiy_iyi\\u200b are the first two coordinates of the axis handle in high dimensions after the Grand Tour rotation, so a delta change on (xi,yi)(x_i, y_i)(xi\\u200b,yi\\u200b) induces a delta change Δ~:=(dx,dy,0,0,⋯)\\\\tilde{\\\\Delta}\\xa0:= (dx, dy, 0, 0, \\\\cdots)Δ~:=(dx,dy,0,0,⋯) on ei~\\\\tilde{e_i}ei\\u200b~\\u200b:\\n  ei~↦Δ~ei~+Δ~\\\\tilde{e_i} \\\\overset{\\\\tilde{\\\\Delta}}{\\\\mapsto} \\\\tilde{e_i} + \\\\tilde{\\\\Delta}ei\\u200b~\\u200b↦Δ~\\u200bei\\u200b~\\u200b+Δ~\\n \\n  To find a nearby Grand Tour rotation that respects this change, first note that ei~\\\\tilde{e_i}ei\\u200b~\\u200b is exactly the ithi^{th}ith row of orthogonal Grand Tour matrix GTGTGT\\n\\n    Recall that the convention is that vectors are in row form and linear transformations are matrices that are multiplied on the right.\\n    So eie_iei\\u200b is a row vector whose iii-th entry is 111 (and 000s elsewhere) and ei~:=ei⋅GT\\\\tilde{e_i}\\xa0:= e_i \\\\cdot GTei\\u200b~\\u200b:=ei\\u200b⋅GT is the iii-th row of GTGTGT\\n. \\n  Naturally, we want the new matrix to be the original GTGTGT with its ithi^{th}ith row replaced by ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~, i.e. we should add dxdxdx and dydydy to the (i,1)(i,1)(i,1)-th entry and (i,2)(i,2)(i,2)-th entry of GTGTGT respectively:\\n  GT~←GT\\\\widetilde{GT} \\\\leftarrow GTGT\\n←GT\\nGT~i,1←GTi,1+dx\\\\widetilde{GT}_{i,1} \\\\leftarrow GT_{i,1} + dxGT\\ni,1\\u200b←GTi,1\\u200b+dx\\nGT~i,2←GTi,2+dy\\\\widetilde{GT}_{i,2} \\\\leftarrow GT_{i,2} + dyGT\\ni,2\\u200b←GTi,2\\u200b+dy\\n  However, GT~\\\\widetilde{GT}GT\\n is not orthogonal for arbitrary (dx,dy)(dx, dy)(dx,dy).\\n  In order to find an approximation to GT~\\\\widetilde{GT}GT\\n that is orthogonal, we apply Gram-Schmidt orthonormalization on the rows of GT~\\\\widetilde{GT}GT\\n, with the ithi^{th}ith row considered first in the Gram-Schmidt process:\\n  GT(new):=GramSchmidt(GT~)GT^{(new)}\\xa0:= \\\\textsf{GramSchmidt}(\\\\widetilde{GT})GT(new):=GramSchmidt(GT\\n)\\n  Note that the ithi^{th}ith row is normalized to a unit vector during the Gram-Schmidt, so the resulting position of the handle is \\n  ei~(new)=normalize(ei~+Δ~)\\\\tilde{e_i}^{(new)} = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})ei\\u200b~\\u200b(new)=normalize(ei\\u200b~\\u200b+Δ~)\\n  which may not be exactly the same as ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~, as the following figure shows\\n  \\n    However, for any Δ~\\\\tilde{\\\\Delta}Δ~, the norm of the difference is bounded above by ∣∣Δ~∣∣||\\\\tilde{\\\\Delta}||∣∣Δ~∣∣, as the following figure proves.\\n    \\n\\n \\xa0.\\n \\n  We now explain how we directly manipulate data points. \\n  Technically speaking, this method only considers one point at a time.\\n  For a group of points, we compute their centroid and directly manipulate this single point with this method.\\n  Thinking more carefully about the process in axis mode gives us a way to drag any single point.\\n  Recall that in axis mode, we added user’s manipulation Δ~:=(dx,dy,0,0,⋯)\\\\tilde{\\\\Delta}\\xa0:= (dx, dy, 0, 0, \\\\cdots)Δ~:=(dx,dy,0,0,⋯) to the position of the ithi^{th}ith axis handle ei~\\\\tilde{e_i}ei\\u200b~\\u200b.\\n  This induces a delta change in the ithi^{th}ith row of the Grand Tour matrix GTGTGT.\\n  Next, as the first step in Gram-Schmidt, we normalized this row: \\n  GTi(new):=normalize(GT~i)=normalize(ei~+Δ~)\\n    GT_i^{(new)}\\xa0:= \\\\textsf{normalize}(\\\\widetilde{GT}_i) = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})\\n  GTi(new)\\u200b:=normalize(GT\\ni\\u200b)=normalize(ei\\u200b~\\u200b+Δ~)\\n  These two steps make the axis handle move from ei~\\\\tilde{e_i}ei\\u200b~\\u200b to ei~(new):=normalize(ei~+Δ~)\\\\tilde{e_i}^{(new)}\\xa0:= \\\\textsf{normalize}(\\\\tilde{e_i}+\\\\tilde{\\\\Delta})ei\\u200b~\\u200b(new):=normalize(ei\\u200b~\\u200b+Δ~).\\n \\n  Looking at the geometry of this movement, the “add-delta-then-normalize” on ei~\\\\tilde{e_i}ei\\u200b~\\u200b is equivalent to a rotation from ei~\\\\tilde{e_i}ei\\u200b~\\u200b towards ei~(new)\\\\tilde{e_i}^{(new)}ei\\u200b~\\u200b(new), illustrated in the figure below. \\n  This geometric interpretation can be directly generalized to any arbitrary data point.\\n \\n  The figure shows the case in 3D, but in higher dimensional space it is essentially the same, since the two vectors ei~\\\\tilde{e_i}ei\\u200b~\\u200b and ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~ only span a 2-subspace.\\n  Now we have a nice geometric intuition about direct manipulation: dragging a point induces a simple rotation\\nSimple rotations are rotations with only one plane of rotation.\\n  in high dimensional space.\\n  This intuition is precisely how we implemented our direct manipulation on arbitrary data points, which we will specify as below.\\n \\n  Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points c~\\\\tilde{c}c~ to \\n  c~(new):=(c~+Δ~)⋅∣∣c~∣∣/∣∣c~+Δ~∣∣\\n    \\\\tilde{c}^{(new)}\\xa0:= (\\\\tilde{c} + \\\\tilde{\\\\Delta}) \\\\cdot ||\\\\tilde{c}|| / ||\\\\tilde{c} + \\\\tilde{\\\\Delta}||\\n  c~(new):=(c~+Δ~)⋅∣∣c~∣∣/∣∣c~+Δ~∣∣\\n \\n  First, the angle of rotation can be found by their cosine similarity:\\n  θ=arccos(⟨c~,c~(new)⟩∣∣c~∣∣⋅∣∣c~(new)∣∣) \\\\theta = \\\\textrm{arccos}(\\n    \\\\frac{\\\\langle \\\\tilde{c}, \\\\tilde{c}^{(new)} \\\\rangle}{||\\\\tilde{c}|| \\\\cdot ||\\\\tilde{c}^{(new)}||}\\n  )θ=arccos(∣∣c~∣∣⋅∣∣c~(new)∣∣⟨c~,c~(new)⟩\\u200b)\\n  Next, to find the matrix form of the rotation, we need a convenient basis.\\n  Let QQQ be a change of (orthonormal) basis matrix in which the first two rows form the 2-subspace span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)).\\n  For example, we can let its first row to be normalize(c~)\\\\textsf{normalize}(\\\\tilde{c})normalize(c~), second row to be its orthonormal complement normalize(c~⊥(new))\\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp})normalize(c~⊥(new)\\u200b) in span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)), and the remaining rows complete the whole space:\\n  c~⊥(new):=c~−∣∣c~∣∣⋅cosθc~(new)∣∣c~(new)∣∣\\n  \\\\tilde{c}^{(new)}_{\\\\perp} \\n \\xa0:= \\\\tilde{c} - ||\\\\tilde{c}|| \\\\cdot cos \\\\theta \\\\frac{\\\\tilde{c}^{(new)}}{||\\\\tilde{c}^{(new)}||}\\n  c~⊥(new)\\u200b:=c~−∣∣c~∣∣⋅cosθ∣∣c~(new)∣∣c~(new)\\u200b\\nQ:=[⋯normalize(c~)⋯⋯normalize(c~⊥(new))⋯P]\\n    Q\\xa0:=\\n    \\\\begin{bmatrix}\\n    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}) \\\\cdots \\\\\\\\\\n    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp}) \\\\cdots \\\\\\\\\\n    P\\n    \\\\end{bmatrix}\\n  Q:=⎣⎡\\u200b⋯normalize(c~)⋯⋯normalize(c~⊥(new)\\u200b)⋯P\\u200b⎦⎤\\u200b\\n  where PPP completes the remaining space.\\n\\n  Making use of QQQ, we can find the matrix that rotates the plane span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)) by the angle θ\\\\thetaθ:\\n  ρ=QT[cosθsinθ00⋯−sinθcosθ00⋯00⋮⋮I]Q=:QTR1,2(θ)Q\\n    \\\\rho = Q^T\\n    \\\\begin{bmatrix}\\n    \\\\cos \\\\theta& \\\\sin \\\\theta&  0&  0& \\\\cdots\\\\\\\\\\n    -\\\\sin \\\\theta& \\\\cos \\\\theta&  0&  0& \\\\cdots\\\\\\\\\\n    0& 0&  \\\\\\\\ \\n    \\\\vdots& \\\\vdots& & I& \\\\\\\\\\n    \\\\end{bmatrix}\\n    Q\\n    =: Q^T R_{1,2}(\\\\theta) Q\\n  ρ=QT⎣⎢⎢⎢⎢⎡\\u200bcosθ−sinθ0⋮\\u200bsinθcosθ0⋮\\u200b00\\u200b00I\\u200b⋯⋯\\u200b⎦⎥⎥⎥⎥⎤\\u200bQ=:QTR1,2\\u200b(θ)Q\\n  The new Grand Tour matrix is the matrix product of the original GTGTGT and ρ\\\\rhoρ:\\n  GT(new):=GT⋅ρ\\n    GT^{(new)}\\xa0:= GT \\\\cdot \\\\rho\\n  GT(new):=GT⋅ρ\\n  Now we should be able to see the connection between axis mode and data point mode.\\n  In data point mode, finding QQQ can be done by Gram-Schmidt: Let the first basis be c~\\\\tilde{c}c~, find the orthogonal component of c~(new)\\\\tilde{c}^{(new)}c~(new) in span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)), repeatedly take a random vector, find its orthogonal component to the span of the current basis vectors and add it to the basis set. \\n  In axis mode, the ithi^{th}ith-row-first Gram-Schmidt does the rotation and change of basis in one step.\\n Conclusion \\n  As powerful as t-SNE and UMAP are, they often fail to offer the correspondences we need, and such correspondences can come, surprisingly, from relatively simple methods like the Grand Tour. The Grand Tour method we presented is particularly useful when direct manipulation from the user is available or desirable.\\n  We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers, and using the Grand Tour and direct manipulation to compute the final projection.\\n \\n    The utility code for WebGL under js/lib/webgl_utils/ are adapted from Angel’s computer graphics book supplementary \\n    here.\\n   \\nReview 1 - Anonymous \\nReview 2 - Anonymous \\nReview 3 - Anonymous \\n \\n    If you see mistakes or want to suggest changes, please create an issue on GitHub.  Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.0 with the source available on GitHub, unless noted otherwise. The figures that have been reused from other sources don’t fall under this license and can be recognized by a note in their caption: “Figure from …”. For attribution in academic contexts, please cite this work as BibTeX citation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk Text"
      ],
      "metadata": {
        "id": "pAIKhUqny3YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_chunk = 500"
      ],
      "metadata": {
        "id": "dyNAbBBZ0Mpw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since the summarizer may not be able to take a large amount of text together\n",
        "#we chunk the text\n",
        "\n",
        "ARTICLE = ARTICLE.replace('.', '.<eos>')\n",
        "ARTICLE = ARTICLE.replace('?', '?<eos>')\n",
        "ARTICLE = ARTICLE.replace('!', '!<eos>')\n",
        "ARTICLE = ARTICLE.replace('\\n', '')\n",
        "sentences = ARTICLE.split('<eos>')"
      ],
      "metadata": {
        "id": "uSnWqZCAywuA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tC241KyEzV6g",
        "outputId": "5a310756-735c-4950-cc03-8dd44dca22b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Mingwei Li University of Arizona Zhenge Zhao University of Arizona Carlos Scheidegger University of Arizona March 16, 2020 10.',\n",
              " '23915/distill.',\n",
              " '00025   The Grand Tour is a classic visualization technique for high-dimensional point clouds that projects a high-dimensional dataset into two dimensions.',\n",
              " '  Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer.',\n",
              " '  Unlike modern nonlinear projection methods such as t-SNE and UMAP, the Grand Tour is fundamentally a linear method.',\n",
              " '  In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.',\n",
              " '    Concretely, we present three use cases of interest: visualizing the training process as the network weights change, visualizing the layer-to-layer behavior as the data goes through the network and visualizing both how adversarial examples are crafted and how they fool a neural network.',\n",
              " ' Introduction   Deep neural networks often achieve best-in-class performance in supervised learning contests such as the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).',\n",
              " '    Unfortunately, their decision process is notoriously hard to interpret, and their training process is often hard to debug.',\n",
              " '    In this article, we present a method to visualize the responses of a neural network which leverages properties of deep neural networks and properties of the Grand Tour.',\n",
              " '  Notably, our method enables us to more directly reason about the relationship between changes in the data and changes in the resulting visualization.',\n",
              " '  As we will show, this data-visual correspondence is central to the method we present, especially when compared to other non-linear projection methods like UMAP and t-SNE.',\n",
              " '    To understand a neural network, we often try to observe its action on input examples (both real and synthesized).',\n",
              " '    These kinds of visualizations are useful to elucidate the activation patterns of a neural network for a single example, but they might offer less insight about the relationship between different examples, different states of the network as it’s being trained, or how the data in the example flows through the different layers of a single network.',\n",
              " '    Therefore, we instead aim to enable visualizations of the context around our objects of interest: what is the difference between the present training epoch and the next one?',\n",
              " ' How does the classification of a network converge (or diverge) as the image is fed through the network?',\n",
              " '  Linear methods are attractive because they are particularly easy to reason about.',\n",
              " '  The Grand Tour works by generating a random, smoothly changing rotation of the dataset, and then projecting the data to the two-dimensional screen: both are linear processes.',\n",
              " '  Although deep neural networks are clearly not linear processes, they often confine their nonlinearity to a small set of operations, enabling us to still reason about their behavior.',\n",
              " '  Our proposed method better preserves context by providing more  consistency: it should be possible to know how the visualization  would change, if the data had been different in a particular  way.',\n",
              " ' Working Examples   To illustrate the technique we will present, we trained deep neural  network models (DNNs) with 3 common image classification datasets:  MNIST      MNIST contains grayscale images of 10 handwritten digits        Image credit to https://en.',\n",
              " 'wikipedia.',\n",
              " 'org/wiki/File:MnistExamples.',\n",
              " 'png,  fashion-MNIST      Fashion-MNIST contains grayscale images of 10 types of fashion items:        Image credit to https://towardsdatascience.',\n",
              " 'com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925  and CIFAR-10      CIFAR-10 contains RGB images of 10 classes of objects        Image credit to https://www.',\n",
              " 'cs.',\n",
              " 'toronto.',\n",
              " 'edu/~kriz/cifar.',\n",
              " 'html.',\n",
              " '   While our architecture is simpler and smaller than current DNNs, it’s still indicative of modern networks, and is complex enough to demonstrate both our proposed techniques and shortcomings of typical approaches.',\n",
              " '   The following figure presents a simple functional diagram of the neural network we will use throughout the article.',\n",
              " ' The neural network is a sequence of linear (both convolutional    A convolution calculates weighted sums of regions in the input.',\n",
              " '     In neural networks, the learnable weights in convolutional layers are referred to as the kernel.',\n",
              " '    For example        Image credit to https://towardsdatascience.',\n",
              " 'com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9.',\n",
              " '    See also Convolution arithmetic.',\n",
              " '   and fully-connected    A fully-connected layer computes output neurons as weighted sum of input neurons.',\n",
              " ' In matrix form, it is a matrix that linearly transforms the input vector into the output vector.',\n",
              " '  ), max-pooling, and ReLU    First introduced by Nair and Hinton, ReLU calculates f(x)=max(0,x)f(x)=max(0,x)f(x)=max(0,x) for each entry in a vector input.',\n",
              " ' Graphically, it is a hinge at the origin:     Image credit to https://pytorch.',\n",
              " 'org/docs/stable/nn.',\n",
              " 'html#relu layers, culminating in a softmax    Softmax function calculates S(yi)=eyiΣj=1NeyjS(y_i)=\\\\frac{e^{y_i}}{\\\\Sigma_{j=1}^{N} e^{y_j}}S(yi\\u200b)=Σj=1N\\u200beyj\\u200beyi\\u200b\\u200b for each entry (yiy_iyi\\u200b) in a vector input (yyy).',\n",
              " ' For example,     Image credit to https://ljvmiranda921.',\n",
              " 'github.',\n",
              " 'io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/ layer.',\n",
              " '   Even though neural networks are capable of incredible feats of classification, deep down, they really are just pipelines of relatively simple functions.',\n",
              " '  For images, the input is a 2D array of scalar values for gray scale images or RGB triples for colored images.',\n",
              " '  When needed, one can always flatten the 2D array into an equivalent (w⋅h⋅cw \\\\cdot h \\\\cdot cw⋅h⋅c) -dimensional vector.',\n",
              " '  Similarly, the intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen as vectors in Rn\\\\mathbb{R}^nRn, where nnn is the number of neurons in the layer.',\n",
              " '   The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1.',\n",
              " '  This vector view of data in neural network not only allows us represent complex data in a mathematically compact form, but also hints us on how to visualize them in a better way.',\n",
              " '   Most of the simple functions fall into two categories: they are either linear transformations of their inputs (like fully-connected layers or convolutional layers), or relatively simple non-linear functions that work component-wise (like sigmoid activations    Sigmoid calculates S(x)=exex+1S(x)=\\\\frac{e^{x}}{e^{x}+1}S(x)=ex+1ex\\u200b for each entry (xxx) in a vector input.',\n",
              " ' Graphically, it is an S-shaped curve.',\n",
              " '        Image credit to https://en.',\n",
              " 'wikipedia.',\n",
              " 'org/wiki/Sigmoid_function   or ReLU activations).',\n",
              " '  Some operations, notably max-pooling    Max-pooling calculates maximum of a region in the input.',\n",
              " ' For example        Image credit to https://towardsdatascience.',\n",
              " 'com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9 and softmax, do not fall into either categories.',\n",
              " ' We will come back to this later.',\n",
              " '   The above figure helps us look at a single image at a time; however, it does not provide much context to understand the relationship between layers, between different examples, or between different class labels.',\n",
              " ' For that, researchers often turn to more sophisticated visualizations.',\n",
              " ' Using Visualization to Understand DNNs   Let’s start by considering the problem of visualizing the training process of a DNN.',\n",
              " '  When training neural networks, we optimize parameters in the function to minimize a scalar-valued loss function, typically through some form of gradient descent.',\n",
              " '  We want the loss to keep decreasing, so we monitor the whole history of training and testing losses over rounds of training (or “epochs”), to make sure that the loss decreases over time.',\n",
              " '   The following figure shows a line plot of the training loss for the MNIST classifier.',\n",
              " '   Although its general trend meets our expectation as the loss steadily decreases, we see something strange around epochs 14 and 21: the curve goes almost flat before starting to drop again.',\n",
              " '  What happened?',\n",
              " ' What caused that?',\n",
              " '   If we separate input examples by their true labels/classes and plot the per-class loss like above, we see that the two drops were caused by the classses 1 and 7; the model learns different classes at very different times in the training process.',\n",
              " '   Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7.',\n",
              " '  If we knew ahead of time to be looking for class-specific error rates, then this chart works well.',\n",
              " ' But what if we didn’t really know what to look for?',\n",
              " '   In that case, we could consider visualizations of neuron activations (e.',\n",
              " 'g.',\n",
              " ' in the last softmax layer) for all examples at once, looking  to find patterns like class-specific behavior, and other patterns besides.',\n",
              " '  Should there be only two neurons in that layer, a simple two-dimensional scatter plot would work.',\n",
              " '  However, the points in the softmax layer for our example datasets are 10 dimensional (and in larger-scale classification problems this number can be much larger).',\n",
              " '  We need to either show two dimensions at a time (which does not scale well as the number of possible charts grows quadratically),  or we can use dimensionality reduction to map the data into a two dimensional space and show them in a single plot.',\n",
              " '    Modern dimensionality reduction techniques such as t-SNE and UMAP are capable of impressive feats of summarization, providing two-dimensional images where similar points tend to be clustered together very effectively.',\n",
              " '  However, these methods are not particularly good to understand the behavior of neuron activations at a fine scale.',\n",
              " '  Consider the aforementioned intriguing feature about the different learning rate that the MNIST classifier has on digit 1 and 7: the network did not learn to recognize digit 1 until epoch 14, digit 7 until epoch 21.',\n",
              " '  We compute t-SNE, Dynamic t-SNE, and UMAP projections of the epochs where the phenomenon we described happens.',\n",
              " '  Consider now the task of identifying this class-specific behavior during training.',\n",
              " ' As a reminder, in this case, the strange behavior happens with digits 1 and 7, around epochs 14 and 21 respectively.',\n",
              " '  While the behavior is not particularly subtle&emdash;digit goes from misclassified to correctly classified&emdash; it is quite hard to notice it in any of the plots below.',\n",
              " '   Only on careful inspection we can notice that (for example) in the UMAP plot, the digit 1 which clustered in the bottom in epoch 13 becomes a new tentacle-like feature in epoch 14.',\n",
              " '    One reason that non-linear embeddings fail in elucidating this phenomenon is that, for the particular change in the data, the fail the principle of data-visual correspondence .',\n",
              " ' More concretely, the principle states that specific visualization tasks should be modeled as functions that change the data; the visualization sends this change from data to visuals, and  we can study the extent to which the visualization changes are easily perceptible.',\n",
              " '  Ideally, we want the changes in data and visualization to match in magnitude: a barely noticeable change in visualization should be due to the smallest possible change in data, and a salient change in visualization should reflect a significant one in data.',\n",
              " '  Here, a significant change happened in only a subset of data (e.',\n",
              " 'g.',\n",
              " ' all points of digit 1 from epoch 13 to 14), but all points in the visualization move dramatically.',\n",
              " '  For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms.',\n",
              " '  This property is not ideal for visualization because it fails the data-visual correspondence, making it hard to infer the underlying change in data from the change in the visualization.',\n",
              " '   Non-linear embeddings that have non-convex objectives also tend to be sensitive to initial conditions.',\n",
              " '  For example, in MNIST, although the neural network starts to stabilize on epoch 30, t-SNE and UMAP still generate quite different projections between epochs 30, 31 and 32 (in fact, all the way to 99).',\n",
              " '  Temporal regularization techniques (such as Dynamic t-SNE) mitigate these consistency issues, but still suffer from other interpretability issues.',\n",
              " '    Now, let’s consider another task, that of identifying classes which the neural network tends to confuse.',\n",
              " '  For this example, we will use the Fashion-MNIST dataset and classifier, and consider the confusion among sandals, sneakers and ankle boots.',\n",
              " '  If we know ahead of time that these three classes are likely to confuse the classifier, then we can directly design an appropriate linear projection, as can be seen in the last row of the following figure (we found this particular projection using both the Grand Tour and the direct manipulation technique we later describe).',\n",
              " ' The pattern in this case is quite salient, forming a triangle.',\n",
              " '  T-SNE, in contrast, incorrectly separates the class clusters (possibly because of an inappropriately-chosen hyperparameter).',\n",
              " '  UMAP successfully isolates the three classes, but even in this case it’s not possible to distinguish between three-way confusion for the classifier in epochs 5 and 10 (portrayed in a linear method by the presence of points near the center of the triangle), and multiple two-way confusions in later epochs (evidences by an “empty” center).',\n",
              " ' Linear Methods to the Rescue   When given the chance, then, we should prefer methods for which changes in the data produce predictable, visually salient changes in the result, and linear dimensionality reductions often have this property.',\n",
              " '  Here, we revisit the linear projections described above in an interface where the user can easily navigate between different training epochs.',\n",
              " '  In addition, we introduce another useful capability which is only available to linear methods, that of direct manipulation.',\n",
              " '  Each linear projection from nnn dimensions to 222 dimensions can be represented by nnn 2-dimensional vectors which have an intuitive interpretation: they are the vectors that the nnn canonical basis vector in the nnn-dimensional space will be projected to.',\n",
              " '  In the context of projecting the final classification layer, this is especially simple to interpret: they are the destinations of an input that is classified with 100% confidence to any one particular class.',\n",
              " '  If we provide the user with the ability to change these vectors by dragging around user-interface handles, then users can intuitively set up new linear projections.',\n",
              " '     This setup provides additional nice properties that explain the salient patterns in the previous illustrations.',\n",
              " '  For example, because projections are linear and the coefficients of vectors in the classification layer sum to one, classification outputs that are halfway confident between two classes are projected to vectors that are halfway between the class handles.',\n",
              " '   This particular property is illustrated clearly in the Fashion-MNIST example below.',\n",
              " '  The model confuses sandals, sneakers and ankle boots, as data points form a triangular shape in the softmax layer.',\n",
              " '   Examples falling between classes indicate that the model has trouble distinguishing the two, such as sandals vs.',\n",
              " ' sneakers, and sneakers vs.',\n",
              " ' ankle boot classes.',\n",
              " '   Note, however, that this does not happen as much for sandals vs.',\n",
              " ' ankle boots: not many examples fall between these two classes.',\n",
              " '   Moreover, most data points are projected close to the edge of the triangle.',\n",
              " '   This tells us that most confusions happen between two out of the three classes, they are really two-way confusions.',\n",
              " '  Within the same dataset, we can also see pullovers, coats and shirts filling a triangular plane.',\n",
              " '  This is different from the sandal-sneaker-ankle-boot case, as examples not only fall on the boundary of a triangle, but also in its interior: a true three-way confusion.',\n",
              " '   Similarly, in the CIFAR-10 dataset we can see confusion between dogs and cats, airplanes and ships.',\n",
              " '  The mixing pattern in CIFAR-10 is not as clear as in fashion-MNIST, because many more examples are misclassified.',\n",
              " ' The Grand Tour   In the previous section, we took advantage of the fact that we knew which classes to visualize.',\n",
              " '  That meant it was easy to design linear projections for the particular tasks at hand.',\n",
              " '  But what if we don’t know ahead of time which projection to choose from, because we don’t quite know what to look for?',\n",
              " '  Principal Component Analysis (PCA) is the quintessential linear dimensionality reduction method,  choosing to project the data so as to preserve the most variance possible.',\n",
              " '   However, the distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector.',\n",
              " 'We are assuming a class-balanced training dataset.',\n",
              " ' Nevertheless, if the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much either.',\n",
              " '  As a result, even though PCA projections are interpretable and consistent through training epochs, the first two principal components of softmax activations are not substantially better than the third.',\n",
              " '  So which of them should we choose?',\n",
              " '  Instead of PCA, we propose to visualize this data by smoothly animating random projections, using a technique called the Grand Tour.',\n",
              " ' Starting with a random velocity, it smoothly rotates data points around the origin in high dimensional space, and then projects it down to 2D for display.',\n",
              " ' Here are some examples of how Grand Tour acts on some (low-dimensional) objects:   We first look at the Grand Tour of the softmax layer.',\n",
              " '   The softmax layer is relatively easy to understand because its axes have strong semantics.',\n",
              " ' As we described earlier, the iii-th axis corresponds to network’s confidence about predicting that the given input belongs to the iii-th class.',\n",
              " '    The Grand Tour of the softmax layer lets us qualitatively assess the performance of our model.',\n",
              " '  In the particular case of this article, since we used comparable architectures for three datasets, this also allows us to gauge the relative difficulty of classifying each dataset.',\n",
              " '   We can see that data points are most confidently classified for the MNIST dataset, where the digits are close to one of the ten corners of the softmax space.',\n",
              " ' For Fashion-MNIST or CIFAR-10, the separation is not as clean, and more points appear inside the volume.',\n",
              " '   Linear projection methods naturally give a formulation that is independent of the input points, allowing us to keep the projection fixed while the  data changes.',\n",
              " '  To recap our working example, we trained each of the neural networks for 99 epochs and recorded the entire history of neuron activations on a subset of training and testing examples.',\n",
              " ' We can use the Grand Tour, then, to visualize the actual training process of these networks.',\n",
              " '   In the beginning when the neural networks are randomly initialized, all examples are placed around the center of the softmax space, with equal weights to each class.',\n",
              " '   Through training, examples move to class vectors in the softmax space.',\n",
              " ' The Grand Tour also lets us  compare visualizations of the training and testing data, giving us a qualitative assessment of over-fitting.',\n",
              " '   In the MNIST dataset, the trajectory of testing images through training is consistent with the training set.',\n",
              " '   Data points went directly toward the corner of its true class and all classes are stabilized after about 50 epochs.',\n",
              " '  On the other hand, in CIFAR-10 there is an inconsistency between the training and testing sets.',\n",
              " ' Images from the testing set keep oscillating while most images from training converges to the corresponding class corner.',\n",
              " '   In epoch 99, we can clearly see a difference in distribution between these two sets.',\n",
              " '  This signals that the model overfits the training set and thus does not generalize well to the testing set.',\n",
              " '    Given the presented techniques of the Grand Tour and direct manipulations on the axes, we can in theory visualize and manipulate any intermediate layer of a neural network by itself.',\n",
              " '  Nevertheless, this is not a very satisfying approach, for two reasons:      To address the first problem, we will need to pay closer attention to the way in which layers transform the data that they are given.',\n",
              " '    To see how a linear transformation can be visualized in a particularly ineffective way, consider the following (very simple) weights (represented by a matrix AAA) which take a 2-dimensional hidden layer kkk and produce activations in another 2-dimensional layer k+1k+1k+1.',\n",
              " ' The weights simply negate two activations in 2D:  A=[−1,00,−1]    A = \\\\begin{bmatrix}    -1, 0 \\\\\\\\    0, -1    \\\\end{bmatrix}  A=[−1,00,−1\\u200b]  Imagine that we wish to visualize the behavior of network as the data moves from layer to layer.',\n",
              " ' One way to interpolate the source x0x_0x0\\u200b and destination x1=A(x0)=−x0x_1 = A(x_0) = -x_0x1\\u200b=A(x0\\u200b)=−x0\\u200b of this action AAA is by a simple linear interpolation  xt=(1−t)⋅x0+t⋅x1=(1−2t)⋅x0  x_t = (1-t) \\\\cdot x_0 + t \\\\cdot x_1 = (1-2t) \\\\cdot x_0      xt\\u200b=(1−t)⋅x0\\u200b+t⋅x1\\u200b=(1−2t)⋅x0\\u200b  for t∈[0,1].',\n",
              " 't \\\\in [0,1].',\n",
              " 't∈[0,1].',\n",
              " '  Effectively, this strategy reuses the linear projection coefficients from one layer to the next.',\n",
              " ' This is a natural thought, since they have the same dimension.',\n",
              " '  However, notice the following: the transformation given by A is a simple rotation of the data.',\n",
              " ' Every linear transformation of the layer k+1k+1k+1 could be encoded simply as a linear transformation of the layer kkk, if only that transformation operated on the negative values of the entries.',\n",
              " '  In addition, since the Grand Tour has a rotation itself built-in, for every configuration that gives a certain picture of the layer kkk, there exists a different configuration that would yield the same picture for layer k+1k+1k+1, by taking the action of AAA into account.',\n",
              " '  In effect, the naive interpolation fails the principle of data-visual correspondence: a simple change in data (negation in 2D/180 degree rotation) results in a drastic change in visualization (all points cross the origin).',\n",
              " '   This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations.',\n",
              " '  We should seek to explicitly articulate what are purely representational artifacts that we should discard, and what are the real features a visualization we should distill from the representation.',\n",
              " '  Here, we claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities.',\n",
              " '  As we will show, the Grand Tour is particularly attractive in this case because it is can be made to be invariant to rotations in data.',\n",
              " '  As a result, the rotational components in the linear transformations of a neural network will be explicitly made invisible.',\n",
              " '   Concretely, we achieve this by taking advantage of a central theorem of linear algebra.',\n",
              " '   The Singular Value Decomposition (SVD) theorem shows that any linear transformation can be decomposed into a sequence of very simple operations: a rotation, a scaling, and another rotation.',\n",
              " '   Applying a matrix AAA to a vector xxx is then equivalent to applying those simple operations: xA=xUΣVTx A = x U \\\\Sigma V^TxA=xUΣVT.',\n",
              " '  But remember that the Grand Tour works by rotating the dataset and then projecting it to 2D.',\n",
              " '  Combined, these two facts mean that as far as the Grand Tour is concerned, visualizing a vector xxx is the same as visualizing xUx UxU, and visualizing a vector xUΣVTx U \\\\Sigma V^TxUΣVT is the same as visualizing xUΣx U \\\\SigmaxUΣ.',\n",
              " '   This means that any linear transformation seen by the Grand Tour is equivalent to the transition between xUx UxU and xUΣx U \\\\SigmaxUΣ - a simple (coordinate-wise) scaling.',\n",
              " '   This is explicitly saying that any linear operation (whose matrix is represented in standard bases) is a scaling operation with appropriately chosen orthonormal bases on both sides.',\n",
              " '  So the Grand Tour provides a natural, elegant and computationally efficient way to align visualizations of activations separated by fully-connected (linear) layers.',\n",
              " 'Convolutional layers are also linear.',\n",
              " ' One can instantly see that by forming the linear transformations between flattened feature maps, or by taking the circulant structure of convolutional layers directly into account   (For the following portion, we reduce the number of data points to 500 and epochs to 50, in order to reduce the amount of data transmitted in a web-based demonstration.',\n",
              " ')  With the linear algebra structure at hand, now we are able to trace behaviors and patterns from the softmax back to previous layers.',\n",
              " '  In fashion-MNIST, for example, we observe a separation of shoes (sandals, sneakers and ankle boots as a group) from all other classes in the softmax layer.',\n",
              " '   Tracing it back to earlier layers, we can see that this separation happened as early as layer 5:   As a final application scenario, we show how the Grand Tour can also elucidate the behavior of adversarial examples as they are processed by a neural network.',\n",
              " '  For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s.',\n",
              " '  Previously, we either animated the training dynamics or the layer dynamics.',\n",
              " '  We fix a well-trained neural network, and visualize the training process of adversarial examples, since they are often themselves generated by an optimization process.',\n",
              " ' Here, we used the Fast Gradient Sign method.',\n",
              " '  Again, because the Grand Tour is a linear method, the change in the positions of the adversarial examples over time can be faithfully attributed to changes in how the neural network perceives the images, rather than potential artifacts of the visualization.',\n",
              " '  Let us examine how adversarial examples evolved to fool the network:   Through this adversarial training, the network eventually claims, with high confidence, that the inputs given are all 0s.',\n",
              " '  If we stay in the softmax layer and slide though the adversarial training steps in the plot, we can see adversarial examples move from a high score for class 8 to a high score for class 0.',\n",
              " '  Although all adversarial examples are classified as the target class (digit 0s) eventually, some of them detoured somewhere close to the centroid of the space (around the 25th epoch) and then moved towards the target.',\n",
              " '   Comparing the actual images of the two groups, we see those that those “detouring” images tend to be noisier.',\n",
              " '   More interesting, however, is what happens in the intermediate layers.',\n",
              " '  In pre-softmax, for example, we see that these fake 0s behave differently from the genuine 0s: they live closer to the decision boundary of two classes and form a plane by themselves.',\n",
              " '  Discussion   Early on, we compared several state-of-the-art dimensionality reduction techniques with the Grand Tour, showing that non-linear methods do not have as many desirable properties as the Grand Tour for understanding the behavior of neural networks.',\n",
              " '   However, the state-of-the-art non-linear methods come with their own strength.',\n",
              " '   Whenever geometry is concerned, like the case of understanding multi-way confusions in the softmax layer, linear methods are more interpretable because they preserve certain geometrical structures of data in the projection.',\n",
              " '   When topology is the main focus, such as when we want to cluster the data or we need dimensionality reduction for downstream models that are less sensitive to geometry, we might choose non-linear methods such as UMAP or t-SNE for they have more freedom in projecting the data, and will generally make better use of the fewer dimensions available.',\n",
              " '    When comparing linear projections with non-linear dimensionality reductions, we used small multiples to contrast training epochs and dimensionality reduction methods.',\n",
              " '  The Grand Tour, on the other hand, uses a single animated view.',\n",
              " '  When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature, aside.',\n",
              " '   from specific settings such as dynamic graph drawing , or concerns about incomparable contents  between small multiples and animated plots.',\n",
              " '  Regardless of these concerns, in our scenarios, the use of animation comes naturally from the direct manipulation and the existence of a continuum of rotations for the Grand Tour to operate in.',\n",
              " '   In our work we have used models that are purely “sequential”, in the sense that the layers can be put in numerical ordering, and that the activations for  the n+1n+1n+1-th layer are a function exclusively of the activations at the nnn-th layer.',\n",
              " '   In recent DNN architectures, however, it is common to have non-sequential parts such as highway  branches or dedicated branches for different tasks .',\n",
              " '   With our technique, one can visualize neuron activations on each such branch, but additional research is required to incorporate multiple branches directly.',\n",
              " '   Modern architectures are also wide.',\n",
              " ' Especially when convolutional layers are concerned, one could run into issues with scalability if we see such layers as a large sparse matrix acting on flattened multi-channel images.',\n",
              " '  For the sake of simplicity, in this article we brute-forced the computation of the alignment of such convolutional layers by writing out their explicit matrix representation.',\n",
              " '   However, the singular value decomposition of multi-channel 2D convolutions can be computed efficiently , which can be then be directly used for alignment, as we described above.',\n",
              " ' Technical Details   In this section, our notational convention is that data points are represented as row vectors.',\n",
              " '  An entire dataset is laid out as a matrix, where each row is a data point, and each column represents a different feature/dimension.',\n",
              " '  As a result, when a linear transformation is applied to the data, the row vectors (and the data matrix overall) are left-multiplied by the transformation matrix.',\n",
              " '  This has a side benefit that when applying matrix multiplications in a chain, the formula reads from left to right and aligns with a commutative diagram.',\n",
              " '  For example, when a data matrix XXX is multiplied by a matrix MMM to generate YYY, in formula we write XM=YXM = YXM=Y, the letters have the same order in diagram:   The direct manipulations we presented earlier provide explicit control over the possible projections for the data points.',\n",
              " '  We provide two modes: directly manipulating class axes (the “axis mode”), or directly manipulating a group of data points through their centroid (the “data point mode”).',\n",
              " '  Based on the dimensionality and axis semantics, as discussed in Layer Dynamics, we may prefer one mode than the other.',\n",
              " '    We will see that the axis mode is a special case of data point mode, because we can view an axis handle as a particular “fictitious” point in the dataset.',\n",
              " '  Because of its simplicity, we will first introduce the axis mode.',\n",
              " '     The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle), they are signaling to the system that they wished that the corresponding    data point had been projected to the location where the UI element was dropped, rather than where it was dragged from.',\n",
              " '    In our case the overall projection is a rotation (originally determined by the Grand Tour), and an arbitrary user manipulation might not necessarily generate a new projection that is also a rotation.',\n",
              " ' Our goal, then, is to find a new rotation which satisfies the user request and is close to the previous state of the Grand Tour projection, so that the resulting state satisfies the user request.',\n",
              " '  In a nutshell, when user drags the ithi^{th}ith axis handle by (dx,dy)(dx, dy)(dx,dy), we add them to the first two entries of the ithi^{th}ith row of the Grand Tour matrix, and then perform Gram-Schmidt orthonormalization on the rows of the new matrix.',\n",
              " '      Rows have to be reordered such that the ithi^{th}ith row is considered first in the Gram-Schmidt procedure.',\n",
              " '     Before we see in detail why this works well, let us formalize the process of the Grand Tour on a standard basis vector eie_iei\\u200b.',\n",
              " '   As shown in the diagram below, eie_iei\\u200b goes through an orthogonal Grand Tour matrix GTGTGT to produce a rotated version of itself, ei~\\\\tilde{e_i}ei\\u200b~\\u200b.',\n",
              " '   Then, π2\\\\pi_2π2\\u200b is a function that keeps only the first two entries of ei~\\\\tilde{e_i}ei\\u200b~\\u200b and gives the 2D coordinate of the handle to be shown in the plot, (xi,yi)(x_i, y_i)(xi\\u200b,yi\\u200b).',\n",
              " '   When user drags an axis handle on the screen canvas, they induce a delta change Δ=(dx,dy)\\\\Delta = (dx, dy)Δ=(dx,dy) on the xyxyxy-plane.',\n",
              " '   The coordinate of the handle becomes:  (xi(new),yi(new)):=(xi+dx,yi+dy)(x_i^{(new)}, y_i^{(new)})\\xa0:= (x_i+dx, y_i+dy)(xi(new)\\u200b,yi(new)\\u200b):=(xi\\u200b+dx,yi\\u200b+dy)  Note that xix_ixi\\u200b and yiy_iyi\\u200b are the first two coordinates of the axis handle in high dimensions after the Grand Tour rotation, so a delta change on (xi,yi)(x_i, y_i)(xi\\u200b,yi\\u200b) induces a delta change Δ~:=(dx,dy,0,0,⋯)\\\\tilde{\\\\Delta}\\xa0:= (dx, dy, 0, 0, \\\\cdots)Δ~:=(dx,dy,0,0,⋯) on ei~\\\\tilde{e_i}ei\\u200b~\\u200b:  ei~↦Δ~ei~+Δ~\\\\tilde{e_i} \\\\overset{\\\\tilde{\\\\Delta}}{\\\\mapsto} \\\\tilde{e_i} + \\\\tilde{\\\\Delta}ei\\u200b~\\u200b↦Δ~\\u200bei\\u200b~\\u200b+Δ~   To find a nearby Grand Tour rotation that respects this change, first note that ei~\\\\tilde{e_i}ei\\u200b~\\u200b is exactly the ithi^{th}ith row of orthogonal Grand Tour matrix GTGTGT    Recall that the convention is that vectors are in row form and linear transformations are matrices that are multiplied on the right.',\n",
              " '    So eie_iei\\u200b is a row vector whose iii-th entry is 111 (and 000s elsewhere) and ei~:=ei⋅GT\\\\tilde{e_i}\\xa0:= e_i \\\\cdot GTei\\u200b~\\u200b:=ei\\u200b⋅GT is the iii-th row of GTGTGT.',\n",
              " '   Naturally, we want the new matrix to be the original GTGTGT with its ithi^{th}ith row replaced by ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~, i.',\n",
              " 'e.',\n",
              " ' we should add dxdxdx and dydydy to the (i,1)(i,1)(i,1)-th entry and (i,2)(i,2)(i,2)-th entry of GTGTGT respectively:  GT~←GT\\\\widetilde{GT} \\\\leftarrow GTGT←GTGT~i,1←GTi,1+dx\\\\widetilde{GT}_{i,1} \\\\leftarrow GT_{i,1} + dxGTi,1\\u200b←GTi,1\\u200b+dxGT~i,2←GTi,2+dy\\\\widetilde{GT}_{i,2} \\\\leftarrow GT_{i,2} + dyGTi,2\\u200b←GTi,2\\u200b+dy  However, GT~\\\\widetilde{GT}GT is not orthogonal for arbitrary (dx,dy)(dx, dy)(dx,dy).',\n",
              " '  In order to find an approximation to GT~\\\\widetilde{GT}GT that is orthogonal, we apply Gram-Schmidt orthonormalization on the rows of GT~\\\\widetilde{GT}GT, with the ithi^{th}ith row considered first in the Gram-Schmidt process:  GT(new):=GramSchmidt(GT~)GT^{(new)}\\xa0:= \\\\textsf{GramSchmidt}(\\\\widetilde{GT})GT(new):=GramSchmidt(GT)  Note that the ithi^{th}ith row is normalized to a unit vector during the Gram-Schmidt, so the resulting position of the handle is   ei~(new)=normalize(ei~+Δ~)\\\\tilde{e_i}^{(new)} = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})ei\\u200b~\\u200b(new)=normalize(ei\\u200b~\\u200b+Δ~)  which may not be exactly the same as ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~, as the following figure shows      However, for any Δ~\\\\tilde{\\\\Delta}Δ~, the norm of the difference is bounded above by ∣∣Δ~∣∣||\\\\tilde{\\\\Delta}||∣∣Δ~∣∣, as the following figure proves.',\n",
              " '     \\xa0.',\n",
              " '   We now explain how we directly manipulate data points.',\n",
              " '   Technically speaking, this method only considers one point at a time.',\n",
              " '  For a group of points, we compute their centroid and directly manipulate this single point with this method.',\n",
              " '  Thinking more carefully about the process in axis mode gives us a way to drag any single point.',\n",
              " '  Recall that in axis mode, we added user’s manipulation Δ~:=(dx,dy,0,0,⋯)\\\\tilde{\\\\Delta}\\xa0:= (dx, dy, 0, 0, \\\\cdots)Δ~:=(dx,dy,0,0,⋯) to the position of the ithi^{th}ith axis handle ei~\\\\tilde{e_i}ei\\u200b~\\u200b.',\n",
              " '  This induces a delta change in the ithi^{th}ith row of the Grand Tour matrix GTGTGT.',\n",
              " '  Next, as the first step in Gram-Schmidt, we normalized this row:   GTi(new):=normalize(GT~i)=normalize(ei~+Δ~)    GT_i^{(new)}\\xa0:= \\\\textsf{normalize}(\\\\widetilde{GT}_i) = \\\\textsf{normalize}(\\\\tilde{e_i} + \\\\tilde{\\\\Delta})  GTi(new)\\u200b:=normalize(GTi\\u200b)=normalize(ei\\u200b~\\u200b+Δ~)  These two steps make the axis handle move from ei~\\\\tilde{e_i}ei\\u200b~\\u200b to ei~(new):=normalize(ei~+Δ~)\\\\tilde{e_i}^{(new)}\\xa0:= \\\\textsf{normalize}(\\\\tilde{e_i}+\\\\tilde{\\\\Delta})ei\\u200b~\\u200b(new):=normalize(ei\\u200b~\\u200b+Δ~).',\n",
              " '   Looking at the geometry of this movement, the “add-delta-then-normalize” on ei~\\\\tilde{e_i}ei\\u200b~\\u200b is equivalent to a rotation from ei~\\\\tilde{e_i}ei\\u200b~\\u200b towards ei~(new)\\\\tilde{e_i}^{(new)}ei\\u200b~\\u200b(new), illustrated in the figure below.',\n",
              " '   This geometric interpretation can be directly generalized to any arbitrary data point.',\n",
              " '   The figure shows the case in 3D, but in higher dimensional space it is essentially the same, since the two vectors ei~\\\\tilde{e_i}ei\\u200b~\\u200b and ei~+Δ~\\\\tilde{e_i}+\\\\tilde{\\\\Delta}ei\\u200b~\\u200b+Δ~ only span a 2-subspace.',\n",
              " '  Now we have a nice geometric intuition about direct manipulation: dragging a point induces a simple rotationSimple rotations are rotations with only one plane of rotation.',\n",
              " '  in high dimensional space.',\n",
              " '  This intuition is precisely how we implemented our direct manipulation on arbitrary data points, which we will specify as below.',\n",
              " '   Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points c~\\\\tilde{c}c~ to   c~(new):=(c~+Δ~)⋅∣∣c~∣∣/∣∣c~+Δ~∣∣    \\\\tilde{c}^{(new)}\\xa0:= (\\\\tilde{c} + \\\\tilde{\\\\Delta}) \\\\cdot ||\\\\tilde{c}|| / ||\\\\tilde{c} + \\\\tilde{\\\\Delta}||  c~(new):=(c~+Δ~)⋅∣∣c~∣∣/∣∣c~+Δ~∣∣   First, the angle of rotation can be found by their cosine similarity:  θ=arccos(⟨c~,c~(new)⟩∣∣c~∣∣⋅∣∣c~(new)∣∣) \\\\theta = \\\\textrm{arccos}(    \\\\frac{\\\\langle \\\\tilde{c}, \\\\tilde{c}^{(new)} \\\\rangle}{||\\\\tilde{c}|| \\\\cdot ||\\\\tilde{c}^{(new)}||}  )θ=arccos(∣∣c~∣∣⋅∣∣c~(new)∣∣⟨c~,c~(new)⟩\\u200b)  Next, to find the matrix form of the rotation, we need a convenient basis.',\n",
              " '  Let QQQ be a change of (orthonormal) basis matrix in which the first two rows form the 2-subspace span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)).',\n",
              " '  For example, we can let its first row to be normalize(c~)\\\\textsf{normalize}(\\\\tilde{c})normalize(c~), second row to be its orthonormal complement normalize(c~⊥(new))\\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp})normalize(c~⊥(new)\\u200b) in span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)), and the remaining rows complete the whole space:  c~⊥(new):=c~−∣∣c~∣∣⋅cosθc~(new)∣∣c~(new)∣∣  \\\\tilde{c}^{(new)}_{\\\\perp}  \\xa0:= \\\\tilde{c} - ||\\\\tilde{c}|| \\\\cdot cos \\\\theta \\\\frac{\\\\tilde{c}^{(new)}}{||\\\\tilde{c}^{(new)}||}  c~⊥(new)\\u200b:=c~−∣∣c~∣∣⋅cosθ∣∣c~(new)∣∣c~(new)\\u200bQ:=[⋯normalize(c~)⋯⋯normalize(c~⊥(new))⋯P]    Q\\xa0:=    \\\\begin{bmatrix}    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}) \\\\cdots \\\\\\\\    \\\\cdots \\\\textsf{normalize}(\\\\tilde{c}^{(new)}_{\\\\perp}) \\\\cdots \\\\\\\\    P    \\\\end{bmatrix}  Q:=⎣⎡\\u200b⋯normalize(c~)⋯⋯normalize(c~⊥(new)\\u200b)⋯P\\u200b⎦⎤\\u200b  where PPP completes the remaining space.',\n",
              " '  Making use of QQQ, we can find the matrix that rotates the plane span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)) by the angle θ\\\\thetaθ:  ρ=QT[cosθsinθ00⋯−sinθcosθ00⋯00⋮⋮I]Q=:QTR1,2(θ)Q    \\\\rho = Q^T    \\\\begin{bmatrix}    \\\\cos \\\\theta& \\\\sin \\\\theta&  0&  0& \\\\cdots\\\\\\\\    -\\\\sin \\\\theta& \\\\cos \\\\theta&  0&  0& \\\\cdots\\\\\\\\    0& 0&  \\\\\\\\     \\\\vdots& \\\\vdots& & I& \\\\\\\\    \\\\end{bmatrix}    Q    =: Q^T R_{1,2}(\\\\theta) Q  ρ=QT⎣⎢⎢⎢⎢⎡\\u200bcosθ−sinθ0⋮\\u200bsinθcosθ0⋮\\u200b00\\u200b00I\\u200b⋯⋯\\u200b⎦⎥⎥⎥⎥⎤\\u200bQ=:QTR1,2\\u200b(θ)Q  The new Grand Tour matrix is the matrix product of the original GTGTGT and ρ\\\\rhoρ:  GT(new):=GT⋅ρ    GT^{(new)}\\xa0:= GT \\\\cdot \\\\rho  GT(new):=GT⋅ρ  Now we should be able to see the connection between axis mode and data point mode.',\n",
              " '  In data point mode, finding QQQ can be done by Gram-Schmidt: Let the first basis be c~\\\\tilde{c}c~, find the orthogonal component of c~(new)\\\\tilde{c}^{(new)}c~(new) in span(c~,c~(new))\\\\textrm{span}(\\\\tilde{c}, \\\\tilde{c}^{(new)})span(c~,c~(new)), repeatedly take a random vector, find its orthogonal component to the span of the current basis vectors and add it to the basis set.',\n",
              " '   In axis mode, the ithi^{th}ith-row-first Gram-Schmidt does the rotation and change of basis in one step.',\n",
              " ' Conclusion   As powerful as t-SNE and UMAP are, they often fail to offer the correspondences we need, and such correspondences can come, surprisingly, from relatively simple methods like the Grand Tour.',\n",
              " ' The Grand Tour method we presented is particularly useful when direct manipulation from the user is available or desirable.',\n",
              " '  We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers, and using the Grand Tour and direct manipulation to compute the final projection.',\n",
              " '     The utility code for WebGL under js/lib/webgl_utils/ are adapted from Angel’s computer graphics book supplementary     here.',\n",
              " '   Review 1 - Anonymous Review 2 - Anonymous Review 3 - Anonymous      If you see mistakes or want to suggest changes, please create an issue on GitHub.',\n",
              " '  Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.',\n",
              " '0 with the source available on GitHub, unless noted otherwise.',\n",
              " ' The figures that have been reused from other sources don’t fall under this license and can be recognized by a note in their caption: “Figure from …”.',\n",
              " ' For attribution in academic contexts, please cite this work as BibTeX citation']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ARTICLE.split('<eos>')\n",
        "current_chunk = 0\n",
        "chunks = []\n",
        "for sentence in sentences:\n",
        "    if len(chunks) == current_chunk + 1:\n",
        "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
        "            chunks[current_chunk].extend(sentence.split(' '))\n",
        "        else:\n",
        "            current_chunk += 1\n",
        "            chunks.append(sentence.split(' '))\n",
        "    else:\n",
        "        print(current_chunk)\n",
        "        chunks.append(sentence.split(' '))\n",
        "\n",
        "for chunk_id in range(len(chunks)):\n",
        "    chunks[chunk_id] = ' '.join(chunks[chunk_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_wLMLLYzXYN",
        "outputId": "f4f3edd5-bf29-4da3-8921-94b236fe6532"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "6HwF51080I4Q",
        "outputId": "abc1eb63-3d06-4007-9566-a93f01a19e78"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Mingwei Li University of Arizona Zhenge Zhao University of Arizona Carlos Scheidegger University of Arizona March 16, 2020 10. 23915/distill. 00025   The Grand Tour is a classic visualization technique for high-dimensional point clouds that projects a high-dimensional dataset into two dimensions.   Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer.   Unlike modern nonlinear projection methods such as t-SNE and UMAP, the Grand Tour is fundamentally a linear method.   In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.     Concretely, we present three use cases of interest: visualizing the training process as the network weights change, visualizing the layer-to-layer behavior as the data goes through the network and visualizing both how adversarial examples are crafted and how they fool a neural network.  Introduction   Deep neural networks often achieve best-in-class performance in supervised learning contests such as the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).     Unfortunately, their decision process is notoriously hard to interpret, and their training process is often hard to debug.     In this article, we present a method to visualize the responses of a neural network which leverages properties of deep neural networks and properties of the Grand Tour.   Notably, our method enables us to more directly reason about the relationship between changes in the data and changes in the resulting visualization.   As we will show, this data-visual correspondence is central to the method we present, especially when compared to other non-linear projection methods like UMAP and t-SNE.     To understand a neural network, we often try to observe its action on input examples (both real and synthesized).     These kinds of visualizations are useful to elucidate the activation patterns of a neural network for a single example, but they might offer less insight about the relationship between different examples, different states of the network as it’s being trained, or how the data in the example flows through the different layers of a single network.     Therefore, we instead aim to enable visualizations of the context around our objects of interest: what is the difference between the present training epoch and the next one?  How does the classification of a network converge (or diverge) as the image is fed through the network?   Linear methods are attractive because they are particularly easy to reason about.   The Grand Tour works by generating a random, smoothly changing rotation of the dataset, and then projecting the data to the two-dimensional screen: both are linear processes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks[-2].split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0l-TQZr0VRd",
        "outputId": "a590b8b8-cfec-49dd-8dd5-5a177afe32f9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "462"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV_vNEgmz00f",
        "outputId": "056eb0f6-b768-4e60-f347-c6ac1828d4af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks[-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vtorEMD2XD3",
        "outputId": "b555564e-3602-4c91-e523-01fcc422626b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3309"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summerization"
      ],
      "metadata": {
        "id": "U2NvxFtN0KRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res= summerizer(chunks, max_length=120, min_length=30, do_sample=False)\n",
        "#could make it shorter by changing the max length parameter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "7o1nPIAB0JU5",
        "outputId": "5bf8f2f5-acce-4977-cdba-bb7bec81d6fd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-876210dd4684>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msummerizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#could make it shorter by changing the max length parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \"\"\"\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         if (\n\u001b[1;32m    169\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1255\u001b[0m             )\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         )\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"encoder_outputs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1746\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    113\u001b[0m         ).expand(bsz, -1)\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary library\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "# Assuming 'chunks' is a list of text strings,\n",
        "# and 'summerizer' is a SummarizationPipeline instance.\n",
        "\n",
        "# Check if the tokenizer is defined in the summerizer pipeline\n",
        "if hasattr(summerizer, \"tokenizer\"):\n",
        "  tokenizer = summerizer.tokenizer\n",
        "else:\n",
        "  # If not, instantiate a new tokenizer based on the model used in the pipeline\n",
        "  model_name = summerizer.model.config.name_or_path  # Get the model name from the pipeline\n",
        "  tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Process each chunk individually to avoid exceeding maximum sequence length:\n",
        "processed_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Tokenize the chunk and truncate if necessary\n",
        "    inputs = tokenizer(chunk, return_tensors=\"pt\", max_length=150, truncation=True)\n",
        "\n",
        "    # Decode the tokens back to text\n",
        "    processed_chunk = tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)\n",
        "\n",
        "    # Add the processed chunk to the list\n",
        "    processed_chunks.append(processed_chunk)\n",
        "\n",
        "# Now call the summarizer with the processed chunks:\n",
        "res = summerizer(processed_chunks, max_length=150, min_length=30, do_sample=False)"
      ],
      "metadata": {
        "id": "fj5CXsqp3kKz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scyClT0o0Uoa",
        "outputId": "644fe233-0084-467c-8b66-05f001629ac9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW8vhOHG4fLf",
        "outputId": "5914680f-9713-4ca5-9335-9b2eaf248972"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' The Grand Tour is a classic visualization technique for high-dimensional point clouds . Unlike modern nonlinear projection methods such as t-SNE and UMAP, it is fundamentally a linear method . We show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to us .'},\n",
              " {'summary_text': ' Deep neural networks often confine their nonlinearity to a small set of operations . Our proposed method better preserves context by providing more consistency . It should be possible to know how the visualization  would change, if the data had been different in a particular way .'},\n",
              " {'summary_text': ' The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1 . The intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen in Rn\\\\mathbb{R}^nRn, where nnn is the number of neurons in the layer .'},\n",
              " {'summary_text': ' Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7 . If we knew ahead of time to be looking for class-specific error rates, this chart works well .'},\n",
              " {'summary_text': ' A significant change happened in only a subset of data, but all points in the visualization move dramatically . For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms .'},\n",
              " {'summary_text': ' Each linear projection from nnn dimensions to 222 dimensions can be represented by nnn 2-dimensional vectors . These are the destinations of an input that is classified with 100% confidence to any one particular class . Users can intuitively set up new linear projections by dragging around user-interface handles .'},\n",
              " {'summary_text': ' The distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector . If the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much .'},\n",
              " {'summary_text': ' Images from the testing set keep oscillating while most images from training converges to the corresponding class corner . In epoch 99, we can clearly see a difference in distribution between these two sets . This signals that the model overfits the training set .'},\n",
              " {'summary_text': ' We claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities . This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations .'},\n",
              " {'summary_text': ' We show how the Grand Tour can also elucidate the behavior of adversarial examples as they are processed by a neural network . For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s .'},\n",
              " {'summary_text': ' The Grand Tour uses a single animated view . When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature .'},\n",
              " {'summary_text': ' The axis mode is a special case of data point mode . The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle) they are signaling to the system that they wished that the corresponding data point had been projected to the location where the UI element was dropped, rather than where it was dragged .'},\n",
              " {'summary_text': ' eie_iei\\u200b is a row vector whose ii-th entry is 111 (and 000s elsewhere) and ei~:=ei⋅GT\\\\tilde{e_i}\\xa0:= e_i \\\\cdot GTei\\u200b~~\\u200b: =ei\\u200b’s ‘i’ is the i-th row of GTGTGT .'},\n",
              " {'summary_text': '   Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points c~\\\\tilde{c}c~ to   c~(new):=(c~+Δ~)\\xa0:= (c~) + \\\\tilde {c} +   + \\xa0c~ (c) +  c)'},\n",
              " {'summary_text': ' We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers . Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.0 .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output to text file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3T27B5Db1xWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=' '.join([ summ['summary_text'] for summ in res])"
      ],
      "metadata": {
        "id": "gSk6ywta0YfM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Pc1eLvKt4iSJ",
        "outputId": "27d048af-f0f8-4427-b1b8-38ab4c77e207"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The Grand Tour is a classic visualization technique for high-dimensional point clouds . Unlike modern nonlinear projection methods such as t-SNE and UMAP, it is fundamentally a linear method . We show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to us .  Deep neural networks often confine their nonlinearity to a small set of operations . Our proposed method better preserves context by providing more consistency . It should be possible to know how the visualization  would change, if the data had been different in a particular way .  The softmax, for example, can be seen as a 10-vector whose values are positive real numbers that sum up to 1 . The intermediate values after any one of the functions in composition, or activations of neurons after a layer, can also be seen in Rn\\\\mathbb{R}^nRn, where nnn is the number of neurons in the layer .  Although the network learns to recognize digits 0, 2, 3, 4, 5, 6, 8 and 9 early on, it is not until epoch 14 that it starts successfully recognizing digit 1, or until epoch 21 that it recognizes digit 7 . If we knew ahead of time to be looking for class-specific error rates, this chart works well .  A significant change happened in only a subset of data, but all points in the visualization move dramatically . For both UMAP and t-SNE, the position of each single point depends non-trivially on the whole data distribution in such embedding algorithms .  Each linear projection from nnn dimensions to 222 dimensions can be represented by nnn 2-dimensional vectors . These are the destinations of an input that is classified with 100% confidence to any one particular class . Users can intuitively set up new linear projections by dragging around user-interface handles .  The distribution of data in softmax layers often has similar variance along many axis directions, because each axis concentrates a similar number of examples around the class vector . If the training dataset is not balanced, PCA will prefer dimensions with more examples, which might not be help much .  Images from the testing set keep oscillating while most images from training converges to the corresponding class corner . In epoch 99, we can clearly see a difference in distribution between these two sets . This signals that the model overfits the training set .  We claim that rotational factors in linear transformations of neural networks are significantly less important than other factors such as scalings and nonlinearities . This observation points to a more general strategy: when designing a visualization, we should be as explicit as possible about which parts of the input (or process) we seek to capture in our visualizations .  We show how the Grand Tour can also elucidate the behavior of adversarial examples as they are processed by a neural network . For this illustration, we use the MNIST dataset, and we adversarially add perturbations to 89 digit 8s to fool the network into thinking they are 0s .  The Grand Tour uses a single animated view . When comparing small multiples and animations, there is no general consensus on which one is better than the other in the literature .  The axis mode is a special case of data point mode . The implied semantics of direct manipulation is that when a user drags an UI element (in this case, an axis handle) they are signaling to the system that they wished that the corresponding data point had been projected to the location where the UI element was dropped, rather than where it was dragged .  eie_iei\\u200b is a row vector whose ii-th entry is 111 (and 000s elsewhere) and ei~:=ei⋅GT\\\\tilde{e_i}\\xa0:= e_i \\\\cdot GTei\\u200b~~\\u200b: =ei\\u200b’s ‘i’ is the i-th row of GTGTGT .    Generalizing this observation from axis handle to arbitrary data point, we want to find the rotation that moves the centroid of a selected subset of data points c~\\\\tilde{c}c~ to   c~(new):=(c~+Δ~)\\xa0:= (c~) + \\\\tilde {c} +   + \\xa0c~ (c) +  c)  We believe that it might be possible to design methods that highlight the best of both worlds, using non-linear dimensionality reduction to create intermediate, relatively low-dimensional representations of the activation layers . Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.0 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('blogSummaru.txt', 'w') as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "27ujc9Wr13Uc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGK517KA4YVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}